{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 천이과정 학습 코드\n",
    "본 Jupyter notebook은 UAM 스케일 기체의 천이과정을 학습시키는 코드입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch as th\n",
    "import time\n",
    "import Transition_Training_8_discrete_simple as TT8d\n",
    "import importlib\n",
    "from stable_baselines3 import SAC\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transition_Training_8_discrete_yuc** 파일을 수정하고 다시 불러올 경우, 아래의 셀을 실행시킵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(TT8d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파일 이름 생성\n",
    "아래 함수를 실행시킨 시점을 기준으로 파일 이름을 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename():\n",
    "    year = str(datetime.today().year)\n",
    "    month = str(datetime.today().month).zfill(2)\n",
    "    day = str(datetime.today().day).zfill(2)\n",
    "    hour = str(datetime.today().hour).zfill(2)\n",
    "    minute = str(datetime.today().minute).zfill(2)\n",
    "    second = str(datetime.today().second).zfill(2)\n",
    "\n",
    "    filename = f'train_result_{year}-{month}-{day}_{hour}{minute}{second}'\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 생성\n",
    "처음부터 모델을 학습 시킬 경우, 아래의 셀을 실행시킵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel environments\n",
    "env = TT8d.TiltrotorTransitionTraining()\n",
    "policy_kwargs = dict(activation_fn=th.nn.ReLU, net_arch=dict(pi=[256,256,256], qf=[128,128]))\n",
    "model = SAC(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, verbose=1, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 불러오기\n",
    "기존에 학습된 모델이 있다면 불러와서 전이학습을 시킬 수도 있습니다.  \n",
    "아래의 셀을 실행시켜 모델을 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TT8d.TiltrotorTransitionTraining()\n",
    "model = SAC.load(r'./model/train_result_2023-07-13_224219.zip', env = env, device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습시키기\n",
    "아래의 코드를 동작시켜 모델을 학습시킵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "maximum_eps = 1000\n",
    "maximum_timestep = 30000\n",
    "\n",
    "best_reward = 0\n",
    "\n",
    "result_filename = get_filename()\n",
    "with open(f'./results/{result_filename}.txt', 'w') as file:\n",
    "    for eps in range(maximum_eps):\n",
    "        obs = env.reset()\n",
    "        model.learn(total_timesteps=maximum_timestep, log_interval=100)\n",
    "        for k in range(maximum_timestep):\n",
    "            action, _states = model.predict(obs, deterministic=True)\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            env.render()\n",
    "            if done:\n",
    "                log = f\"episode: {eps}\\nepisode was finished at timestep: {k}\\nreward: {reward}\\n========================================\"\n",
    "                print(log)\n",
    "                file.write(f'{log}\\n')\n",
    "\n",
    "                break\n",
    "        # 이번 학습 결과가 기존 학습 결과보다 좋다면 저장\n",
    "        if reward > best_reward:\n",
    "            best_reward = reward\n",
    "            model.save(f'./model/{result_filename}')\n",
    "\n",
    "model.save(f'./model/{result_filename}_last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 시연\n",
    "학습이 마무리된 후, 아래의 셀을 실행시켜 모델 학습 결과를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "\n",
    "for k in range(3000):\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    #print(action)\n",
    "    env.render()\n",
    "    if done:\n",
    "      obs = env.reset()\n",
    "\n",
    "print(model.policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TT8d.TiltrotorTransitionTraining()\n",
    "model = SAC.load(r'./model/train_result_2023-07-13_224219.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5)\n",
    "obs = env.reset()\n",
    "\n",
    "for k in range(1000):\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    #print(action)\n",
    "    env.render()\n",
    "    if done:\n",
    "      obs = env.reset()\n",
    "\n",
    "print(model.policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
