{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 천이과정 학습 코드\n",
    "본 Jupyter notebook은 UAM 스케일 기체의 천이과정을 학습시키는 코드입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andy/anaconda3/envs/boom/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import torch as th\n",
    "import time\n",
    "import Transition_Training_8_discrete_simple as TT8d\n",
    "import importlib\n",
    "from stable_baselines3 import SAC\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transition_Training_8_discrete_yuc** 파일을 수정하고 다시 불러올 경우, 아래의 셀을 실행시킵니다."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 11,
=======
   "execution_count": 7,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Transition_Training_8_discrete_simple' from '/home/andy/Documents/GitHub/KADA-UAM-RL/code/Transition_Training_8_discrete_simple.py'>"
      ]
     },
<<<<<<< Updated upstream
     "execution_count": 11,
=======
     "execution_count": 7,
>>>>>>> Stashed changes
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(TT8d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파일 이름 생성\n",
    "아래 함수를 실행시킨 시점을 기준으로 파일 이름을 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename():\n",
    "    year = str(datetime.today().year)\n",
    "    month = str(datetime.today().month).zfill(2)\n",
    "    day = str(datetime.today().day).zfill(2)\n",
    "    hour = str(datetime.today().hour).zfill(2)\n",
    "    minute = str(datetime.today().minute).zfill(2)\n",
    "    second = str(datetime.today().second).zfill(2)\n",
    "\n",
    "    filename = f'train_result_{year}-{month}-{day}_{hour}{minute}{second}'\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 생성\n",
    "처음부터 모델을 학습 시킬 경우, 아래의 셀을 실행시킵니다.  \n",
    "이전에 학습시킨 모델을 불러와 전이학습을 시키려면 [모델 불러오기](#모델-불러오기) 셀을 확인하세요"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
<<<<<<< Updated upstream
     "ename": "FileNotFoundError",
     "evalue": "No file 'F:\\YJLEE's code\\image/Background.png' found in working directory '/home/andy/Documents/GitHub/KADA-UAM-RL/code'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Parallel environments\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m env \u001b[39m=\u001b[39m TT8d\u001b[39m.\u001b[39;49mTiltrotorTransitionTraining()\n\u001b[1;32m      3\u001b[0m policy_kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(activation_fn\u001b[39m=\u001b[39mth\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mReLU, net_arch\u001b[39m=\u001b[39m\u001b[39mdict\u001b[39m(pi\u001b[39m=\u001b[39m[\u001b[39m256\u001b[39m,\u001b[39m256\u001b[39m,\u001b[39m256\u001b[39m], qf\u001b[39m=\u001b[39m[\u001b[39m128\u001b[39m,\u001b[39m128\u001b[39m]))\n\u001b[1;32m      4\u001b[0m model \u001b[39m=\u001b[39m SAC(\u001b[39m\"\u001b[39m\u001b[39mMlpPolicy\u001b[39m\u001b[39m\"\u001b[39m, env, policy_kwargs\u001b[39m=\u001b[39mpolicy_kwargs, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, device\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/KADA-UAM-RL/code/Transition_Training_8_discrete_simple.py:16\u001b[0m, in \u001b[0;36mTiltrotorTransitionTraining.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 16\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_render([\u001b[39m1000\u001b[39;49m,\u001b[39m500\u001b[39;49m])\n\u001b[1;32m     18\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_DB(\n\u001b[1;32m     19\u001b[0m                 [\u001b[39m0.5\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0.003\u001b[39m,\u001b[39m0.1512\u001b[39m,\u001b[39m0.9997\u001b[39m,\u001b[39m0.1512\u001b[39m,\u001b[39m0.8544\u001b[39m,\u001b[39m0.32\u001b[39m,\u001b[39m23\u001b[39m],\n\u001b[1;32m     20\u001b[0m                 \u001b[39m# [cg_x,  cg_z,    f_p_x,    f_p_z, r_p_x, r_p_z, S, cbar, elev_max]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[39m# [m, Iyy, g]\u001b[39;00m\n\u001b[1;32m     39\u001b[0m                 )\n\u001b[1;32m     41\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservation_space \u001b[39m=\u001b[39m spaces\u001b[39m.\u001b[39mBox(np\u001b[39m.\u001b[39mfinfo(np\u001b[39m.\u001b[39mfloat32)\u001b[39m.\u001b[39mmin, np\u001b[39m.\u001b[39mfinfo(np\u001b[39m.\u001b[39mfloat32)\u001b[39m.\u001b[39mmax, shape\u001b[39m=\u001b[39m(\u001b[39m11\u001b[39m,), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/Documents/GitHub/KADA-UAM-RL/code/Transition_Training_8_discrete_simple.py:52\u001b[0m, in \u001b[0;36mTiltrotorTransitionTraining.set_render\u001b[0;34m(self, window_size)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow_size \u001b[39m=\u001b[39m window_size\n\u001b[1;32m     50\u001b[0m img_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mF:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mYJLEE\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms code\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 52\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackground \u001b[39m=\u001b[39m pygame\u001b[39m.\u001b[39;49mimage\u001b[39m.\u001b[39;49mload(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mimg_path\u001b[39m}\u001b[39;49;00m\u001b[39m/Background.png\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m     54\u001b[0m \u001b[39m# self.background = pygame.image.load(os.path.join(\"C:/Users/ds040/OneDrive - konkuk.ac.kr/Teams/RL/Transition-Train/images/Background.png\"))\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvehicle \u001b[39m=\u001b[39m pygame\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mload(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mimg_path\u001b[39m}\u001b[39;00m\u001b[39m/vehicle.png\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No file 'F:\\YJLEE's code\\image/Background.png' found in working directory '/home/andy/Documents/GitHub/KADA-UAM-RL/code'."
=======
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andy/anaconda3/envs/boom/lib/python3.8/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
>>>>>>> Stashed changes
     ]
    }
   ],
>>>>>>> Stashed changes
   "source": [
    "# Parallel environments\n",
    "env = TT8d.TiltrotorTransitionTraining()\n",
    "policy_kwargs = dict(activation_fn=th.nn.ReLU, net_arch=dict(pi=[256,256,256], qf=[128,128]))\n",
    "model = SAC(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, verbose=1, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 불러오기\n",
    "기존에 학습된 모델이 있다면 불러와서 전이학습을 시킬 수도 있습니다.  \n",
    "아래의 셀을 실행시켜 모델을 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 9,
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cck18\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "env = TT8d.TiltrotorTransitionTraining()\n",
    "model = SAC.load(r'./model/train_result_2023-07-25_225825_last.zip', env = env, device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습시키기\n",
    "아래의 코드를 동작시켜 모델을 학습시킵니다."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 10,
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
<<<<<<< Updated upstream
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m eps \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(maximum_eps):\n\u001b[0;32m      9\u001b[0m     obs \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mreset()\n\u001b[1;32m---> 10\u001b[0m     model\u001b[39m.\u001b[39;49mlearn(total_timesteps\u001b[39m=\u001b[39;49mmaximum_timestep, log_interval\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n\u001b[0;32m     11\u001b[0m     \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(maximum_timestep):\n\u001b[0;32m     12\u001b[0m         action, _states \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(obs, deterministic\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\cck18\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\sac\\sac.py:307\u001b[0m, in \u001b[0;36mSAC.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[0;32m    299\u001b[0m     \u001b[39mself\u001b[39m: SelfSAC,\n\u001b[0;32m    300\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    305\u001b[0m     progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    306\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m SelfSAC:\n\u001b[1;32m--> 307\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mlearn(\n\u001b[0;32m    308\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[0;32m    309\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[0;32m    310\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[0;32m    311\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[0;32m    312\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[0;32m    313\u001b[0m         progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m    314\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\cck18\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:312\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    309\u001b[0m callback\u001b[39m.\u001b[39mon_training_start(\u001b[39mlocals\u001b[39m(), \u001b[39mglobals\u001b[39m())\n\u001b[0;32m    311\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 312\u001b[0m     rollout \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollect_rollouts(\n\u001b[0;32m    313\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv,\n\u001b[0;32m    314\u001b[0m         train_freq\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_freq,\n\u001b[0;32m    315\u001b[0m         action_noise\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maction_noise,\n\u001b[0;32m    316\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[0;32m    317\u001b[0m         learning_starts\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlearning_starts,\n\u001b[0;32m    318\u001b[0m         replay_buffer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreplay_buffer,\n\u001b[0;32m    319\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[0;32m    320\u001b[0m     )\n\u001b[0;32m    322\u001b[0m     \u001b[39mif\u001b[39;00m rollout\u001b[39m.\u001b[39mcontinue_training \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cck18\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:544\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[0;32m    541\u001b[0m actions, buffer_actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sample_action(learning_starts, action_noise, env\u001b[39m.\u001b[39mnum_envs)\n\u001b[0;32m    543\u001b[0m \u001b[39m# Rescale and perform action\u001b[39;00m\n\u001b[1;32m--> 544\u001b[0m new_obs, rewards, dones, infos \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(actions)\n\u001b[0;32m    546\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mnum_envs\n\u001b[0;32m    547\u001b[0m num_collected_steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\cck18\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:197\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[39mStep the environments with the given action\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \n\u001b[0;32m    193\u001b[0m \u001b[39m:param actions: the action\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[39m:return: observation, reward, done, information\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_async(actions)\n\u001b[1;32m--> 197\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep_wait()\n",
      "File \u001b[1;32mc:\\Users\\cck18\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:58\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep_wait\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m     56\u001b[0m     \u001b[39m# Avoid circular imports\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     \u001b[39mfor\u001b[39;00m env_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_envs):\n\u001b[1;32m---> 58\u001b[0m         obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_infos[env_idx] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menvs[env_idx]\u001b[39m.\u001b[39;49mstep(\n\u001b[0;32m     59\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactions[env_idx]\n\u001b[0;32m     60\u001b[0m         )\n\u001b[0;32m     61\u001b[0m         \u001b[39m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[0;32m     62\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_dones[env_idx] \u001b[39m=\u001b[39m terminated \u001b[39mor\u001b[39;00m truncated\n",
      "File \u001b[1;32mc:\\Users\\cck18\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\monitor.py:94\u001b[0m, in \u001b[0;36mMonitor.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneeds_reset:\n\u001b[0;32m     93\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTried to step environment that needs reset\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 94\u001b[0m observation, reward, terminated, truncated, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m     95\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrewards\u001b[39m.\u001b[39mappend(\u001b[39mfloat\u001b[39m(reward))\n\u001b[0;32m     96\u001b[0m \u001b[39mif\u001b[39;00m terminated \u001b[39mor\u001b[39;00m truncated:\n",
      "File \u001b[1;32mc:\\Users\\cck18\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shimmy\\openai_gym_compatibility.py:257\u001b[0m, in \u001b[0;36mGymV21CompatibilityV0.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action: ActType) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mtuple\u001b[39m[Any, \u001b[39mfloat\u001b[39m, \u001b[39mbool\u001b[39m, \u001b[39mbool\u001b[39m, \u001b[39mdict\u001b[39m]:\n\u001b[0;32m    249\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Steps through the environment.\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \n\u001b[0;32m    251\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[39m        (observation, reward, terminated, truncated, info)\u001b[39;00m\n\u001b[0;32m    256\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 257\u001b[0m     obs, reward, done, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgym_env\u001b[39m.\u001b[39mstep(action)\n\u001b[0;32m    259\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrender_mode \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    260\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrender()\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 4)"
=======
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 3.8      |\n",
      "|    ep_rew_mean     | -15.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 5        |\n",
      "|    time_elapsed    | 64       |\n",
      "|    total_timesteps | 380      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.16     |\n",
      "|    critic_loss     | 736      |\n",
      "|    ent_coef        | 0.919    |\n",
      "|    ent_coef_loss   | -0.538   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 279      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.13     |\n",
      "|    ep_rew_mean     | 7.69     |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 4        |\n",
      "|    time_elapsed    | 121      |\n",
      "|    total_timesteps | 493      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.858   |\n",
      "|    critic_loss     | 320      |\n",
      "|    ent_coef        | 0.892    |\n",
      "|    ent_coef_loss   | -0.607   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 392      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.05     |\n",
      "|    ep_rew_mean     | 7.24     |\n",
      "| time/              |          |\n",
      "|    episodes        | 300      |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 177      |\n",
      "|    total_timesteps | 598      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.9     |\n",
      "|    critic_loss     | 251      |\n",
      "|    ent_coef        | 0.871    |\n",
      "|    ent_coef_loss   | -0.627   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 497      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.03     |\n",
      "|    ep_rew_mean     | 7.16     |\n",
      "| time/              |          |\n",
      "|    episodes        | 400      |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 234      |\n",
      "|    total_timesteps | 701      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.09    |\n",
      "|    critic_loss     | 260      |\n",
      "|    ent_coef        | 0.852    |\n",
      "|    ent_coef_loss   | -0.619   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 600      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.12     |\n",
      "|    ep_rew_mean     | 7.84     |\n",
      "| time/              |          |\n",
      "|    episodes        | 500      |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 296      |\n",
      "|    total_timesteps | 813      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.18    |\n",
      "|    critic_loss     | 240      |\n",
      "|    ent_coef        | 0.83     |\n",
      "|    ent_coef_loss   | -0.877   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 712      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.44     |\n",
      "|    ep_rew_mean     | 7.2      |\n",
      "| time/              |          |\n",
      "|    episodes        | 600      |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 355      |\n",
      "|    total_timesteps | 957      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.95    |\n",
      "|    critic_loss     | 411      |\n",
      "|    ent_coef        | 0.797    |\n",
      "|    ent_coef_loss   | -1.23    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 856      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 8.14     |\n",
      "|    ep_rew_mean     | -65.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 700      |\n",
      "|    fps             | 4        |\n",
      "|    time_elapsed    | 409      |\n",
      "|    total_timesteps | 1771     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.76     |\n",
      "|    critic_loss     | 572      |\n",
      "|    ent_coef        | 0.641    |\n",
      "|    ent_coef_loss   | -1.46    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 1670     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 17.5     |\n",
      "|    ep_rew_mean     | -233     |\n",
      "| time/              |          |\n",
      "|    episodes        | 800      |\n",
      "|    fps             | 7        |\n",
      "|    time_elapsed    | 478      |\n",
      "|    total_timesteps | 3520     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 38.4     |\n",
      "|    critic_loss     | 746      |\n",
      "|    ent_coef        | 0.401    |\n",
      "|    ent_coef_loss   | -3.01    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 3419     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 13.2     |\n",
      "|    ep_rew_mean     | -222     |\n",
      "| time/              |          |\n",
      "|    episodes        | 900      |\n",
      "|    fps             | 8        |\n",
      "|    time_elapsed    | 541      |\n",
      "|    total_timesteps | 4840     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 81.6     |\n",
      "|    critic_loss     | 2.08e+03 |\n",
      "|    ent_coef        | 0.31     |\n",
      "|    ent_coef_loss   | -1.8     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 4739     |\n",
      "---------------------------------\n",
      "episode: 0\n",
      "episode was finished at timestep: 14\n",
      "reward: -77.55526907517277\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.007781892352634006\n",
      "reward_2: -10\n",
      "reward_3: 1.0500000000000003\n",
      "reward_4: 0.030599834242084397\n",
      "reward_5: 0.9618582603590622\n",
      "reward_6: 0.23015209817886362\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 3.6      |\n",
      "|    ep_rew_mean     | 10.2     |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 6        |\n",
      "|    time_elapsed    | 59       |\n",
      "|    total_timesteps | 360      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 105      |\n",
      "|    critic_loss     | 2.42e+03 |\n",
      "|    ent_coef        | 0.288    |\n",
      "|    ent_coef_loss   | -1.12    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 5159     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.01     |\n",
      "|    ep_rew_mean     | 7.1      |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 4        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 461      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 104      |\n",
      "|    critic_loss     | 2.18e+03 |\n",
      "|    ent_coef        | 0.285    |\n",
      "|    ent_coef_loss   | -0.466   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 5260     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | 7.12     |\n",
      "| time/              |          |\n",
      "|    episodes        | 300      |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 172      |\n",
      "|    total_timesteps | 561      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 86.3     |\n",
      "|    critic_loss     | 2.3e+03  |\n",
      "|    ent_coef        | 0.284    |\n",
      "|    ent_coef_loss   | 0.652    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 5360     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.03     |\n",
      "|    ep_rew_mean     | 7.1      |\n",
      "| time/              |          |\n",
      "|    episodes        | 400      |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 233      |\n",
      "|    total_timesteps | 664      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 95       |\n",
      "|    critic_loss     | 2.37e+03 |\n",
      "|    ent_coef        | 0.284    |\n",
      "|    ent_coef_loss   | 1.59     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 5463     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | 6.8      |\n",
      "| time/              |          |\n",
      "|    episodes        | 500      |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 294      |\n",
      "|    total_timesteps | 764      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 93.3     |\n",
      "|    critic_loss     | 1.87e+03 |\n",
      "|    ent_coef        | 0.284    |\n",
      "|    ent_coef_loss   | -0.597   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 5563     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.01     |\n",
      "|    ep_rew_mean     | 7.12     |\n",
      "| time/              |          |\n",
      "|    episodes        | 600      |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 358      |\n",
      "|    total_timesteps | 865      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 99       |\n",
      "|    critic_loss     | 1.89e+03 |\n",
      "|    ent_coef        | 0.283    |\n",
      "|    ent_coef_loss   | -0.522   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 5664     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.01     |\n",
      "|    ep_rew_mean     | 6.9      |\n",
      "| time/              |          |\n",
      "|    episodes        | 700      |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 413      |\n",
      "|    total_timesteps | 966      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 91.4     |\n",
      "|    critic_loss     | 1.74e+03 |\n",
      "|    ent_coef        | 0.283    |\n",
      "|    ent_coef_loss   | 0.918    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 5765     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | 6.45     |\n",
      "| time/              |          |\n",
      "|    episodes        | 800      |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 465      |\n",
      "|    total_timesteps | 1066     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 94       |\n",
      "|    critic_loss     | 2.08e+03 |\n",
      "|    ent_coef        | 0.284    |\n",
      "|    ent_coef_loss   | 0.876    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 5865     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | 6.7      |\n",
      "| time/              |          |\n",
      "|    episodes        | 900      |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 518      |\n",
      "|    total_timesteps | 1166     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 90.5     |\n",
      "|    critic_loss     | 3.46e+03 |\n",
      "|    ent_coef        | 0.284    |\n",
      "|    ent_coef_loss   | 0.271    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 5965     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | 6.75     |\n",
      "| time/              |          |\n",
      "|    episodes        | 1000     |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 575      |\n",
      "|    total_timesteps | 1266     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 75.1     |\n",
      "|    critic_loss     | 2.05e+03 |\n",
      "|    ent_coef        | 0.285    |\n",
      "|    ent_coef_loss   | -0.0668  |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 6065     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | 7.04     |\n",
      "| time/              |          |\n",
      "|    episodes        | 1100     |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 637      |\n",
      "|    total_timesteps | 1366     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 84.7     |\n",
      "|    critic_loss     | 3.02e+03 |\n",
      "|    ent_coef        | 0.285    |\n",
      "|    ent_coef_loss   | -0.618   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 6165     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.01     |\n",
      "|    ep_rew_mean     | 7.04     |\n",
      "| time/              |          |\n",
      "|    episodes        | 1200     |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 693      |\n",
      "|    total_timesteps | 1467     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 67.3     |\n",
      "|    critic_loss     | 1.86e+03 |\n",
      "|    ent_coef        | 0.285    |\n",
      "|    ent_coef_loss   | 0.303    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 6266     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | 7.06     |\n",
      "| time/              |          |\n",
      "|    episodes        | 1300     |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 756      |\n",
      "|    total_timesteps | 1567     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 85       |\n",
      "|    critic_loss     | 2.05e+03 |\n",
      "|    ent_coef        | 0.285    |\n",
      "|    ent_coef_loss   | 0.284    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 6366     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.01     |\n",
      "|    ep_rew_mean     | 7.14     |\n",
      "| time/              |          |\n",
      "|    episodes        | 1400     |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 817      |\n",
      "|    total_timesteps | 1668     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 81.7     |\n",
      "|    critic_loss     | 1.51e+03 |\n",
      "|    ent_coef        | 0.284    |\n",
      "|    ent_coef_loss   | -0.0632  |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 6467     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | 7.09     |\n",
      "| time/              |          |\n",
      "|    episodes        | 1500     |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 875      |\n",
      "|    total_timesteps | 1768     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 75.2     |\n",
      "|    critic_loss     | 1.69e+03 |\n",
      "|    ent_coef        | 0.288    |\n",
      "|    ent_coef_loss   | 0.297    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 6567     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | 7.06     |\n",
      "| time/              |          |\n",
      "|    episodes        | 1600     |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 927      |\n",
      "|    total_timesteps | 1868     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 66.4     |\n",
      "|    critic_loss     | 1.76e+03 |\n",
      "|    ent_coef        | 0.289    |\n",
      "|    ent_coef_loss   | 0.216    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 6667     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | 7.08     |\n",
      "| time/              |          |\n",
      "|    episodes        | 1700     |\n",
      "|    fps             | 1        |\n",
      "|    time_elapsed    | 984      |\n",
      "|    total_timesteps | 1968     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 53.7     |\n",
      "|    critic_loss     | 696      |\n",
      "|    ent_coef        | 0.294    |\n",
      "|    ent_coef_loss   | 0.79     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 6767     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | 7.07     |\n",
      "| time/              |          |\n",
      "|    episodes        | 1800     |\n",
      "|    fps             | 1        |\n",
      "|    time_elapsed    | 1048     |\n",
      "|    total_timesteps | 2068     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 63.4     |\n",
      "|    critic_loss     | 1.4e+03  |\n",
      "|    ent_coef        | 0.299    |\n",
      "|    ent_coef_loss   | 0.341    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 6867     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.02     |\n",
      "|    ep_rew_mean     | 6.84     |\n",
      "| time/              |          |\n",
      "|    episodes        | 1900     |\n",
      "|    fps             | 1        |\n",
      "|    time_elapsed    | 1108     |\n",
      "|    total_timesteps | 2170     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 58.7     |\n",
      "|    critic_loss     | 1.5e+03  |\n",
      "|    ent_coef        | 0.298    |\n",
      "|    ent_coef_loss   | -0.3     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 6969     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.22     |\n",
      "|    ep_rew_mean     | 8.52     |\n",
      "| time/              |          |\n",
      "|    episodes        | 2000     |\n",
      "|    fps             | 1        |\n",
      "|    time_elapsed    | 1171     |\n",
      "|    total_timesteps | 2292     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 73.4     |\n",
      "|    critic_loss     | 2.61e+03 |\n",
      "|    ent_coef        | 0.295    |\n",
      "|    ent_coef_loss   | -0.127   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 7091     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.12     |\n",
      "|    ep_rew_mean     | 7.51     |\n",
      "| time/              |          |\n",
      "|    episodes        | 2100     |\n",
      "|    fps             | 1        |\n",
      "|    time_elapsed    | 1229     |\n",
      "|    total_timesteps | 2404     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 62.1     |\n",
      "|    critic_loss     | 1.45e+03 |\n",
      "|    ent_coef        | 0.29     |\n",
      "|    ent_coef_loss   | -0.767   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 7203     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.67     |\n",
      "|    ep_rew_mean     | 11.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 2200     |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 1284     |\n",
      "|    total_timesteps | 2571     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 57.5     |\n",
      "|    critic_loss     | 1.28e+03 |\n",
      "|    ent_coef        | 0.282    |\n",
      "|    ent_coef_loss   | -0.344   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 7370     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.23     |\n",
      "|    ep_rew_mean     | 8.54     |\n",
      "| time/              |          |\n",
      "|    episodes        | 2300     |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 1342     |\n",
      "|    total_timesteps | 2694     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 52.2     |\n",
      "|    critic_loss     | 1.16e+03 |\n",
      "|    ent_coef        | 0.28     |\n",
      "|    ent_coef_loss   | -0.983   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 7493     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 4.95     |\n",
      "|    ep_rew_mean     | 40       |\n",
      "| time/              |          |\n",
      "|    episodes        | 2400     |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 1405     |\n",
      "|    total_timesteps | 3189     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 46.8     |\n",
      "|    critic_loss     | 721      |\n",
      "|    ent_coef        | 0.299    |\n",
      "|    ent_coef_loss   | 1.31     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 7988     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 7.21     |\n",
      "|    ep_rew_mean     | 51.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 2500     |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 1470     |\n",
      "|    total_timesteps | 3910     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 35.4     |\n",
      "|    critic_loss     | 952      |\n",
      "|    ent_coef        | 0.396    |\n",
      "|    ent_coef_loss   | 1.09     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 8709     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 7.82     |\n",
      "|    ep_rew_mean     | 55.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 2600     |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 1524     |\n",
      "|    total_timesteps | 4692     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 22.9     |\n",
      "|    critic_loss     | 703      |\n",
      "|    ent_coef        | 0.498    |\n",
      "|    ent_coef_loss   | 0.414    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 9491     |\n",
      "---------------------------------\n",
      "episode: 1\n",
      "episode was finished at timestep: 4\n",
      "reward: 7.796079522522203\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0010006156232621934\n",
      "reward_2: 0.6941519129834484\n",
      "reward_3: 0.39999999999999997\n",
      "reward_4: -0.0018324245149749173\n",
      "reward_5: 0.9984629801370065\n",
      "reward_6: 0.2600079169273376\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 9.48     |\n",
      "|    ep_rew_mean     | 61.8     |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 14       |\n",
      "|    time_elapsed    | 67       |\n",
      "|    total_timesteps | 948      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 17.2     |\n",
      "|    critic_loss     | 700      |\n",
      "|    ent_coef        | 0.534    |\n",
      "|    ent_coef_loss   | -0.303   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 10647    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 14.4     |\n",
      "|    ep_rew_mean     | 120      |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 18       |\n",
      "|    time_elapsed    | 130      |\n",
      "|    total_timesteps | 2387     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 11.3     |\n",
      "|    critic_loss     | 613      |\n",
      "|    ent_coef        | 0.5      |\n",
      "|    ent_coef_loss   | 0.321    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 12086    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.8     |\n",
      "|    ep_rew_mean     | 180      |\n",
      "| time/              |          |\n",
      "|    episodes        | 300      |\n",
      "|    fps             | 22       |\n",
      "|    time_elapsed    | 198      |\n",
      "|    total_timesteps | 4566     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -10.6    |\n",
      "|    critic_loss     | 516      |\n",
      "|    ent_coef        | 0.531    |\n",
      "|    ent_coef_loss   | 0.106    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 14265    |\n",
      "---------------------------------\n",
      "episode: 2\n",
      "episode was finished at timestep: 15\n",
      "reward: 7.3235563364764795\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.005035589138666789\n",
      "reward_2: 0.647023093136886\n",
      "reward_3: 1.3500000000000005\n",
      "reward_4: 0.006311375955488074\n",
      "reward_5: 0.9506977041576248\n",
      "reward_6: 0.1510384687185291\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 16.5     |\n",
      "|    ep_rew_mean     | 129      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 25       |\n",
      "|    time_elapsed    | 64       |\n",
      "|    total_timesteps | 1654     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -32      |\n",
      "|    critic_loss     | 406      |\n",
      "|    ent_coef        | 0.567    |\n",
      "|    ent_coef_loss   | 0.0817   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 16253    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 20.4     |\n",
      "|    ep_rew_mean     | 169      |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 27       |\n",
      "|    time_elapsed    | 134      |\n",
      "|    total_timesteps | 3692     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -46.3    |\n",
      "|    critic_loss     | 381      |\n",
      "|    ent_coef        | 0.586    |\n",
      "|    ent_coef_loss   | 0.326    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 18291    |\n",
      "---------------------------------\n",
      "episode: 3\n",
      "episode was finished at timestep: 16\n",
      "reward: 9.748665096929614\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0045609209272596575\n",
      "reward_2: 0.9454908745049181\n",
      "reward_3: 0.9000000000000002\n",
      "reward_4: 0.005988720972718084\n",
      "reward_5: 0.9683314952324164\n",
      "reward_6: 0.17293775880336748\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 16.3     |\n",
      "|    ep_rew_mean     | 119      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 23       |\n",
      "|    time_elapsed    | 68       |\n",
      "|    total_timesteps | 1634     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -62.4    |\n",
      "|    critic_loss     | 425      |\n",
      "|    ent_coef        | 0.534    |\n",
      "|    ent_coef_loss   | -0.148   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 21133    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 17.3     |\n",
      "|    ep_rew_mean     | 132      |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 24       |\n",
      "|    time_elapsed    | 135      |\n",
      "|    total_timesteps | 3361     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -61.4    |\n",
      "|    critic_loss     | 759      |\n",
      "|    ent_coef        | 0.504    |\n",
      "|    ent_coef_loss   | -0.0163  |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 22860    |\n",
      "---------------------------------\n",
      "episode: 4\n",
      "episode was finished at timestep: 9\n",
      "reward: 7.761400104479967\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0046260343657599555\n",
      "reward_2: 0.6974844738868872\n",
      "reward_3: 0.8500000000000002\n",
      "reward_4: 0.00015487047988955283\n",
      "reward_5: 0.97928317707354\n",
      "reward_6: 0.20551487350463882\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 14.6     |\n",
      "|    ep_rew_mean     | 103      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 24       |\n",
      "|    time_elapsed    | 59       |\n",
      "|    total_timesteps | 1455     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -67.9    |\n",
      "|    critic_loss     | 471      |\n",
      "|    ent_coef        | 0.45     |\n",
      "|    ent_coef_loss   | 0.186    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 25854    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 18.1     |\n",
      "|    ep_rew_mean     | 143      |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 25       |\n",
      "|    time_elapsed    | 130      |\n",
      "|    total_timesteps | 3270     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -63.4    |\n",
      "|    critic_loss     | 525      |\n",
      "|    ent_coef        | 0.467    |\n",
      "|    ent_coef_loss   | 0.135    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 27669    |\n",
      "---------------------------------\n",
      "episode: 5\n",
      "episode was finished at timestep: 11\n",
      "reward: 7.63187808601273\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.00019105871518452963\n",
      "reward_2: 0.6801957539610161\n",
      "reward_3: 0.8500000000000002\n",
      "reward_4: -0.0003269432929936045\n",
      "reward_5: 0.98370138229716\n",
      "reward_6: 0.20930394375324246\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 14.1     |\n",
      "|    ep_rew_mean     | 101      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 22       |\n",
      "|    time_elapsed    | 61       |\n",
      "|    total_timesteps | 1412     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -66.7    |\n",
      "|    critic_loss     | 412      |\n",
      "|    ent_coef        | 0.367    |\n",
      "|    ent_coef_loss   | -0.753   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 30711    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 15.5     |\n",
      "|    ep_rew_mean     | 119      |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 22       |\n",
      "|    time_elapsed    | 130      |\n",
      "|    total_timesteps | 2960     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -63.6    |\n",
      "|    critic_loss     | 289      |\n",
      "|    ent_coef        | 0.313    |\n",
      "|    ent_coef_loss   | -0.211   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 32259    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 16.7     |\n",
      "|    ep_rew_mean     | 127      |\n",
      "| time/              |          |\n",
      "|    episodes        | 300      |\n",
      "|    fps             | 23       |\n",
      "|    time_elapsed    | 194      |\n",
      "|    total_timesteps | 4628     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -69.9    |\n",
      "|    critic_loss     | 428      |\n",
      "|    ent_coef        | 0.264    |\n",
      "|    ent_coef_loss   | -1.2     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 33927    |\n",
      "---------------------------------\n",
      "episode: 6\n",
      "episode was finished at timestep: 15\n",
      "reward: 7.660893019058652\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.003972603877385458\n",
      "reward_2: 0.6781482423679799\n",
      "reward_3: 0.9000000000000002\n",
      "reward_4: 0.0074643084793029855\n",
      "reward_5: 0.9817633863714741\n",
      "reward_6: 0.19808182978630073\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 18.6     |\n",
      "|    ep_rew_mean     | 129      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 28       |\n",
      "|    time_elapsed    | 64       |\n",
      "|    total_timesteps | 1856     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -67.4    |\n",
      "|    critic_loss     | 258      |\n",
      "|    ent_coef        | 0.261    |\n",
      "|    ent_coef_loss   | 0.465    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 36055    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 24.2     |\n",
      "|    ep_rew_mean     | 194      |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 31       |\n",
      "|    time_elapsed    | 136      |\n",
      "|    total_timesteps | 4281     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -82.8    |\n",
      "|    critic_loss     | 408      |\n",
      "|    ent_coef        | 0.311    |\n",
      "|    ent_coef_loss   | -0.359   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 38480    |\n",
      "---------------------------------\n",
      "episode: 7\n",
      "episode was finished at timestep: 24\n",
      "reward: 9.47641036265704\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.004448292652765909\n",
      "reward_2: 0.9123570297127644\n",
      "reward_3: 1.5000000000000007\n",
      "reward_4: 0.007007838188775395\n",
      "reward_5: 0.9363178018115383\n",
      "reward_6: 0.18942191028594935\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 20.8     |\n",
      "|    ep_rew_mean     | 133      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 31       |\n",
      "|    time_elapsed    | 65       |\n",
      "|    total_timesteps | 2079     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -81.2    |\n",
      "|    critic_loss     | 545      |\n",
      "|    ent_coef        | 0.295    |\n",
      "|    ent_coef_loss   | -0.717   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 41178    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 19.8     |\n",
      "|    ep_rew_mean     | 157      |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 30       |\n",
      "|    time_elapsed    | 133      |\n",
      "|    total_timesteps | 4055     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -80.5    |\n",
      "|    critic_loss     | 289      |\n",
      "|    ent_coef        | 0.244    |\n",
      "|    ent_coef_loss   | -0.472   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 43154    |\n",
      "---------------------------------\n",
      "episode: 8\n",
      "episode was finished at timestep: 12\n",
      "reward: -77.94896099423866\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.00011759863959418403\n",
      "reward_2: -10\n",
      "reward_3: 1.0000000000000002\n",
      "reward_4: -0.0051644144269072\n",
      "reward_5: 0.9526352856491617\n",
      "reward_6: 0.13970330083370208\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 18.2     |\n",
      "|    ep_rew_mean     | 129      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 28       |\n",
      "|    time_elapsed    | 63       |\n",
      "|    total_timesteps | 1823     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -63.7    |\n",
      "|    critic_loss     | 322      |\n",
      "|    ent_coef        | 0.217    |\n",
      "|    ent_coef_loss   | -0.337   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 45822    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 19.8     |\n",
      "|    ep_rew_mean     | 158      |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 30       |\n",
      "|    time_elapsed    | 122      |\n",
      "|    total_timesteps | 3804     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -72.5    |\n",
      "|    critic_loss     | 335      |\n",
      "|    ent_coef        | 0.215    |\n",
      "|    ent_coef_loss   | -0.205   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 47803    |\n",
      "---------------------------------\n",
      "episode: 9\n",
      "episode was finished at timestep: 6\n",
      "reward: 7.015681507091156\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.008426698711183336\n",
      "reward_2: 0.621140187254267\n",
      "reward_3: 1.1000000000000003\n",
      "reward_4: -0.006942828566469927\n",
      "reward_5: 0.9575270925220508\n",
      "reward_6: 0.1528555771112443\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 15.7     |\n",
      "|    ep_rew_mean     | 113      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 23       |\n",
      "|    time_elapsed    | 67       |\n",
      "|    total_timesteps | 1565     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -74.6    |\n",
      "|    critic_loss     | 222      |\n",
      "|    ent_coef        | 0.205    |\n",
      "|    ent_coef_loss   | -0.545   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 50464    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.1     |\n",
      "|    ep_rew_mean     | 175      |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 26       |\n",
      "|    time_elapsed    | 137      |\n",
      "|    total_timesteps | 3678     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -73.5    |\n",
      "|    critic_loss     | 207      |\n",
      "|    ent_coef        | 0.192    |\n",
      "|    ent_coef_loss   | 0.332    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 52577    |\n",
      "---------------------------------\n",
      "episode: 10\n",
      "episode was finished at timestep: 19\n",
      "reward: 8.393063482992904\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.004565879371431139\n",
      "reward_2: 0.7642472747449983\n",
      "reward_3: 1.1000000000000003\n",
      "reward_4: 0.017383164738931072\n",
      "reward_5: 0.9679300287251216\n",
      "reward_6: 0.17650915110111243\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 17.3     |\n",
      "|    ep_rew_mean     | 124      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 25       |\n",
      "|    time_elapsed    | 69       |\n",
      "|    total_timesteps | 1733     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -73.2    |\n",
      "|    critic_loss     | 116      |\n",
      "|    ent_coef        | 0.177    |\n",
      "|    ent_coef_loss   | 0.112    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 55532    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.2     |\n",
      "|    ep_rew_mean     | 174      |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 28       |\n",
      "|    time_elapsed    | 136      |\n",
      "|    total_timesteps | 3854     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -86.2    |\n",
      "|    critic_loss     | 145      |\n",
      "|    ent_coef        | 0.167    |\n",
      "|    ent_coef_loss   | -1.3     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 57653    |\n",
      "---------------------------------\n",
      "episode: 11\n",
      "episode was finished at timestep: 15\n",
      "reward: 10.132510366846311\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.007792582114537557\n",
      "reward_2: 0.9907450150501219\n",
      "reward_3: 0.9500000000000003\n",
      "reward_4: 0.00853105473741806\n",
      "reward_5: 0.9715996480270289\n",
      "reward_6: 0.174368075966835\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 17.6     |\n",
      "|    ep_rew_mean     | 130      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 27       |\n",
      "|    time_elapsed    | 64       |\n",
      "|    total_timesteps | 1763     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -79.3    |\n",
      "|    critic_loss     | 273      |\n",
      "|    ent_coef        | 0.176    |\n",
      "|    ent_coef_loss   | 0.517    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 60462    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.5     |\n",
      "|    ep_rew_mean     | 171      |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 29       |\n",
      "|    time_elapsed    | 134      |\n",
      "|    total_timesteps | 3911     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -84.6    |\n",
      "|    critic_loss     | 215      |\n",
      "|    ent_coef        | 0.163    |\n",
      "|    ent_coef_loss   | -1.04    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 62610    |\n",
      "---------------------------------\n",
      "episode: 12\n",
      "episode was finished at timestep: 5\n",
      "reward: 9.798020878071537\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0011576063103146024\n",
      "reward_2: 0.9263612709257885\n",
      "reward_3: 1.1000000000000003\n",
      "reward_4: 0.02460684601444413\n",
      "reward_5: 0.9742739734961956\n",
      "reward_6: 0.21701290869712841\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 16.2     |\n",
      "|    ep_rew_mean     | 123      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 24       |\n",
      "|    time_elapsed    | 64       |\n",
      "|    total_timesteps | 1619     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -78.7    |\n",
      "|    critic_loss     | 235      |\n",
      "|    ent_coef        | 0.145    |\n",
      "|    ent_coef_loss   | 1.08     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 65218    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 20.5     |\n",
      "|    ep_rew_mean     | 161      |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 26       |\n",
      "|    time_elapsed    | 135      |\n",
      "|    total_timesteps | 3665     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -86.5    |\n",
      "|    critic_loss     | 243      |\n",
      "|    ent_coef        | 0.133    |\n",
      "|    ent_coef_loss   | -0.638   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 67264    |\n",
      "---------------------------------\n",
      "episode: 13\n",
      "episode was finished at timestep: 16\n",
      "reward: 10.26881305891846\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -3.2364659839206275e-05\n",
      "reward_2: 0.980075261864944\n",
      "reward_3: 1.0000000000000002\n",
      "reward_4: 0.020867060245905834\n",
      "reward_5: 0.9943593152218361\n",
      "reward_6: 0.26681419813633\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 15.6     |\n",
      "|    ep_rew_mean     | 109      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 24       |\n",
      "|    time_elapsed    | 63       |\n",
      "|    total_timesteps | 1559     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -83.2    |\n",
      "|    critic_loss     | 168      |\n",
      "|    ent_coef        | 0.131    |\n",
      "|    ent_coef_loss   | -0.357   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 70058    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.3     |\n",
      "|    ep_rew_mean     | 179      |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 29       |\n",
      "|    time_elapsed    | 128      |\n",
      "|    total_timesteps | 3793     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -80.7    |\n",
      "|    critic_loss     | 84.4     |\n",
      "|    ent_coef        | 0.133    |\n",
      "|    ent_coef_loss   | 0.208    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 72292    |\n",
      "---------------------------------\n",
      "episode: 14\n",
      "episode was finished at timestep: 12\n",
      "reward: 9.891802780141003\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0029415176974402534\n",
      "reward_2: 0.9606633262996445\n",
      "reward_3: 1.0000000000000002\n",
      "reward_4: 0.006669231795988963\n",
      "reward_5: 0.9745095834402225\n",
      "reward_6: 0.18144091629981973\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 19.6     |\n",
      "|    ep_rew_mean     | 148      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 26       |\n",
      "|    time_elapsed    | 73       |\n",
      "|    total_timesteps | 1961     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -79.6    |\n",
      "|    critic_loss     | 204      |\n",
      "|    ent_coef        | 0.144    |\n",
      "|    ent_coef_loss   | -0.372   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 75360    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 24.6     |\n",
      "|    ep_rew_mean     | 191      |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 32       |\n",
      "|    time_elapsed    | 134      |\n",
      "|    total_timesteps | 4424     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -84.4    |\n",
      "|    critic_loss     | 231      |\n",
      "|    ent_coef        | 0.173    |\n",
      "|    ent_coef_loss   | -0.443   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 77823    |\n",
      "---------------------------------\n",
      "episode: 15\n",
      "episode was finished at timestep: 5\n",
      "reward: 9.933836363499648\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.000782469908396403\n",
      "reward_2: 0.942281983332317\n",
      "reward_3: 1.4000000000000006\n",
      "reward_4: 0.03475074889157043\n",
      "reward_5: 0.9592600646046114\n",
      "reward_6: 0.15891024434566492\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 24.7     |\n",
      "|    ep_rew_mean     | 148      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 32       |\n",
      "|    time_elapsed    | 75       |\n",
      "|    total_timesteps | 2473     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.2    |\n",
      "|    critic_loss     | 190      |\n",
      "|    ent_coef        | 0.159    |\n",
      "|    ent_coef_loss   | -1.52    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 80772    |\n",
      "---------------------------------\n",
      "episode: 16\n",
      "episode was finished at timestep: 23\n",
      "reward: 9.52716759200013\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.00983224974738227\n",
      "reward_2: 0.9086227096325011\n",
      "reward_3: 1.2500000000000004\n",
      "reward_4: 0.026686496750696592\n",
      "reward_5: 0.9379644955433167\n",
      "reward_6: 0.11639502847194705\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 24.5     |\n",
      "|    ep_rew_mean     | 132      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 37       |\n",
      "|    time_elapsed    | 65       |\n",
      "|    total_timesteps | 2452     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -86.8    |\n",
      "|    critic_loss     | 346      |\n",
      "|    ent_coef        | 0.146    |\n",
      "|    ent_coef_loss   | 1.05     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 85651    |\n",
      "---------------------------------\n",
      "episode: 17\n",
      "episode was finished at timestep: 11\n",
      "reward: 9.560306433207128\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.00021986828909979927\n",
      "reward_2: 0.8768084387518893\n",
      "reward_3: 1.5000000000000007\n",
      "reward_4: 0.05365681829909193\n",
      "reward_5: 0.9354337318160919\n",
      "reward_6: 0.18117051327228528\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.8     |\n",
      "|    ep_rew_mean     | 101      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 29       |\n",
      "|    time_elapsed    | 73       |\n",
      "|    total_timesteps | 2181     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -81.4    |\n",
      "|    critic_loss     | 190      |\n",
      "|    ent_coef        | 0.169    |\n",
      "|    ent_coef_loss   | 0.0517   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 90280    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 26.9     |\n",
      "|    ep_rew_mean     | 67.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 35       |\n",
      "|    time_elapsed    | 136      |\n",
      "|    total_timesteps | 4872     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -85.7    |\n",
      "|    critic_loss     | 228      |\n",
      "|    ent_coef        | 0.183    |\n",
      "|    ent_coef_loss   | -0.302   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 92971    |\n",
      "---------------------------------\n",
      "episode: 18\n",
      "episode was finished at timestep: 5\n",
      "reward: -77.63229997345658\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0032523810863494874\n",
      "reward_2: -10\n",
      "reward_3: 1.4500000000000006\n",
      "reward_4: 0.042455275605188664\n",
      "reward_5: 0.8962505058103127\n",
      "reward_6: 0.1348663636445998\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.2     |\n",
      "|    ep_rew_mean     | 101      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 29       |\n",
      "|    time_elapsed    | 71       |\n",
      "|    total_timesteps | 2121     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -92.5    |\n",
      "|    critic_loss     | 471      |\n",
      "|    ent_coef        | 0.192    |\n",
      "|    ent_coef_loss   | 0.0257   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 95120    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 26.9     |\n",
      "|    ep_rew_mean     | 95.2     |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 33       |\n",
      "|    time_elapsed    | 141      |\n",
      "|    total_timesteps | 4808     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -84.5    |\n",
      "|    critic_loss     | 285      |\n",
      "|    ent_coef        | 0.209    |\n",
      "|    ent_coef_loss   | -0.171   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 97807    |\n",
      "---------------------------------\n",
      "episode: 19\n",
      "episode was finished at timestep: 4\n",
      "reward: 9.97451550910143\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.010080789195166693\n",
      "reward_2: 0.954550515150444\n",
      "reward_3: 1.3500000000000005\n",
      "reward_4: 0.01805527714531877\n",
      "reward_5: 0.9846590277472288\n",
      "reward_6: 0.21891093218326574\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23.6     |\n",
      "|    ep_rew_mean     | 94.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 35       |\n",
      "|    time_elapsed    | 67       |\n",
      "|    total_timesteps | 2363     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -80.1    |\n",
      "|    critic_loss     | 362      |\n",
      "|    ent_coef        | 0.295    |\n",
      "|    ent_coef_loss   | 0.625    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 100262   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 25.7     |\n",
      "|    ep_rew_mean     | 134      |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 35       |\n",
      "|    time_elapsed    | 140      |\n",
      "|    total_timesteps | 4930     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -82.1    |\n",
      "|    critic_loss     | 215      |\n",
      "|    ent_coef        | 0.285    |\n",
      "|    ent_coef_loss   | -0.65    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 102829   |\n",
      "---------------------------------\n",
      "episode: 20\n",
      "episode was finished at timestep: 13\n",
      "reward: 9.304454980498573\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.008668127987119887\n",
      "reward_2: 0.8753404480558175\n",
      "reward_3: 1.4500000000000006\n",
      "reward_4: 0.017605792439644573\n",
      "reward_5: 0.9627636612129239\n",
      "reward_6: 0.20659618997573892\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 20.1     |\n",
      "|    ep_rew_mean     | 131      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 28       |\n",
      "|    time_elapsed    | 71       |\n",
      "|    total_timesteps | 2006     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -72.1    |\n",
      "|    critic_loss     | 228      |\n",
      "|    ent_coef        | 0.227    |\n",
      "|    ent_coef_loss   | 0.749    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 104805   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.2     |\n",
      "|    ep_rew_mean     | 162      |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 36       |\n",
      "|    time_elapsed    | 135      |\n",
      "|    total_timesteps | 4928     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -76.2    |\n",
      "|    critic_loss     | 227      |\n",
      "|    ent_coef        | 0.223    |\n",
      "|    ent_coef_loss   | 0.379    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 107727   |\n",
      "---------------------------------\n",
      "episode: 21\n",
      "episode was finished at timestep: 20\n",
      "reward: 8.465294151627063\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.010846356550852457\n",
      "reward_2: 0.7479253399808019\n",
      "reward_3: 1.5500000000000007\n",
      "reward_4: 0.03785960671672456\n",
      "reward_5: 0.990035830998473\n",
      "reward_6: 0.19961843693256387\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 26.9     |\n",
      "|    ep_rew_mean     | 208      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 34       |\n",
      "|    time_elapsed    | 76       |\n",
      "|    total_timesteps | 2687     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -64.8    |\n",
      "|    critic_loss     | 248      |\n",
      "|    ent_coef        | 0.248    |\n",
      "|    ent_coef_loss   | 0.479    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 110386   |\n",
      "---------------------------------\n",
      "episode: 22\n",
      "episode was finished at timestep: 21\n",
      "reward: 9.96308826983027\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.010544914007186889\n",
      "reward_2: 0.9780580740754996\n",
      "reward_3: 1.5000000000000007\n",
      "reward_4: -0.003543347821613736\n",
      "reward_5: 0.9699707581085075\n",
      "reward_6: 0.2073446156978609\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 20.2     |\n",
      "|    ep_rew_mean     | 156      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 30       |\n",
      "|    time_elapsed    | 65       |\n",
      "|    total_timesteps | 2020     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -82.2    |\n",
      "|    critic_loss     | 230      |\n",
      "|    ent_coef        | 0.273    |\n",
      "|    ent_coef_loss   | 0.113    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 114619   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 25.7     |\n",
      "|    ep_rew_mean     | 202      |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 34       |\n",
      "|    time_elapsed    | 134      |\n",
      "|    total_timesteps | 4587     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -81      |\n",
      "|    critic_loss     | 256      |\n",
      "|    ent_coef        | 0.279    |\n",
      "|    ent_coef_loss   | 0.343    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 117186   |\n",
      "---------------------------------\n",
      "episode: 23\n",
      "episode was finished at timestep: 11\n",
      "reward: 9.50450849355567\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.004651292165120443\n",
      "reward_2: 0.8949975281158743\n",
      "reward_3: 1.3500000000000005\n",
      "reward_4: 0.017069143399411076\n",
      "reward_5: 0.992635480485409\n",
      "reward_6: 0.21981093311309796\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 20.6     |\n",
      "|    ep_rew_mean     | 148      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 29       |\n",
      "|    time_elapsed    | 69       |\n",
      "|    total_timesteps | 2056     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -92.7    |\n",
      "|    critic_loss     | 149      |\n",
      "|    ent_coef        | 0.282    |\n",
      "|    ent_coef_loss   | -0.429   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 119555   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 25.2     |\n",
      "|    ep_rew_mean     | 195      |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 34       |\n",
      "|    time_elapsed    | 131      |\n",
      "|    total_timesteps | 4572     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -84.4    |\n",
      "|    critic_loss     | 241      |\n",
      "|    ent_coef        | 0.278    |\n",
      "|    ent_coef_loss   | 0.771    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 122071   |\n",
      "---------------------------------\n",
      "episode: 24\n",
      "episode was finished at timestep: 6\n",
      "reward: -77.73098447032442\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.00973320934507582\n",
      "reward_2: -10\n",
      "reward_3: 1.0500000000000003\n",
      "reward_4: 0.006776130235199815\n",
      "reward_5: 0.9860068556807486\n",
      "reward_6: 0.23839284145832051\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 20       |\n",
      "|    ep_rew_mean     | 147      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 26       |\n",
      "|    time_elapsed    | 74       |\n",
      "|    total_timesteps | 2001     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -88.5    |\n",
      "|    critic_loss     | 130      |\n",
      "|    ent_coef        | 0.286    |\n",
      "|    ent_coef_loss   | -0.613   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 124400   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 24.5     |\n",
      "|    ep_rew_mean     | 191      |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 31       |\n",
      "|    time_elapsed    | 139      |\n",
      "|    total_timesteps | 4452     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -87.4    |\n",
      "|    critic_loss     | 283      |\n",
      "|    ent_coef        | 0.294    |\n",
      "|    ent_coef_loss   | -0.345   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 126851   |\n",
      "---------------------------------\n",
      "episode: 25\n",
      "episode was finished at timestep: 18\n",
      "reward: 8.056618862245541\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0036797205607096354\n",
      "reward_2: 0.7181556112390169\n",
      "reward_3: 1.3500000000000005\n",
      "reward_4: 0.013831580814841402\n",
      "reward_5: 0.9747183497420459\n",
      "reward_6: 0.229502696633339\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22       |\n",
      "|    ep_rew_mean     | 159      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 33       |\n",
      "|    time_elapsed    | 65       |\n",
      "|    total_timesteps | 2204     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -91.7    |\n",
      "|    critic_loss     | 295      |\n",
      "|    ent_coef        | 0.279    |\n",
      "|    ent_coef_loss   | -0.394   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 129503   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 26.5     |\n",
      "|    ep_rew_mean     | 206      |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 35       |\n",
      "|    time_elapsed    | 135      |\n",
      "|    total_timesteps | 4855     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -84.9    |\n",
      "|    critic_loss     | 262      |\n",
      "|    ent_coef        | 0.281    |\n",
      "|    ent_coef_loss   | 0.433    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 132154   |\n",
      "---------------------------------\n",
      "episode: 26\n",
      "episode was finished at timestep: 4\n",
      "reward: 7.768928738915858\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0040962782171037465\n",
      "reward_2: 0.6796747177426417\n",
      "reward_3: 1.7500000000000009\n",
      "reward_4: 0.017462305171398497\n",
      "reward_5: 0.9782055102529326\n",
      "reward_6: 0.2174899902343751\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 24       |\n",
      "|    ep_rew_mean     | 173      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 35       |\n",
      "|    time_elapsed    | 68       |\n",
      "|    total_timesteps | 2399     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.9    |\n",
      "|    critic_loss     | 308      |\n",
      "|    ent_coef        | 0.273    |\n",
      "|    ent_coef_loss   | 0.186    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 134598   |\n",
      "---------------------------------\n",
      "episode: 27\n",
      "episode was finished at timestep: 4\n",
      "reward: 7.3709113758858305\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.00036554071638319227\n",
      "reward_2: 0.6310801382675316\n",
      "reward_3: 1.1500000000000004\n",
      "reward_4: 0.007935800439863954\n",
      "reward_5: 0.9945536623061959\n",
      "reward_6: 0.2644424113035203\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.2     |\n",
      "|    ep_rew_mean     | 157      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 30       |\n",
      "|    time_elapsed    | 72       |\n",
      "|    total_timesteps | 2218     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -90.5    |\n",
      "|    critic_loss     | 295      |\n",
      "|    ent_coef        | 0.257    |\n",
      "|    ent_coef_loss   | -0.0633  |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 139317   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 26.9     |\n",
      "|    ep_rew_mean     | 205      |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 35       |\n",
      "|    time_elapsed    | 137      |\n",
      "|    total_timesteps | 4909     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -95.8    |\n",
      "|    critic_loss     | 145      |\n",
      "|    ent_coef        | 0.242    |\n",
      "|    ent_coef_loss   | -0.107   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 142008   |\n",
      "---------------------------------\n",
      "episode: 28\n",
      "episode was finished at timestep: 14\n",
      "reward: 8.487404940859978\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.009820933474434747\n",
      "reward_2: 0.7745345087839872\n",
      "reward_3: 1.4500000000000006\n",
      "reward_4: 0.014724910564279554\n",
      "reward_5: 0.9660647277760727\n",
      "reward_6: 0.21689245843887328\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 26       |\n",
      "|    ep_rew_mean     | 182      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 40       |\n",
      "|    time_elapsed    | 64       |\n",
      "|    total_timesteps | 2597     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -89.1    |\n",
      "|    critic_loss     | 385      |\n",
      "|    ent_coef        | 0.22     |\n",
      "|    ent_coef_loss   | 0.602    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 144596   |\n",
      "---------------------------------\n",
      "episode: 29\n",
      "episode was finished at timestep: 7\n",
      "reward: 9.500631759939854\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.005038486586676704\n",
      "reward_2: 0.8987489647853886\n",
      "reward_3: 1.6000000000000008\n",
      "reward_4: 0.019400769469891797\n",
      "reward_5: 0.9581043739192485\n",
      "reward_6: 0.2021546652317049\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 25.5     |\n",
      "|    ep_rew_mean     | 177      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 35       |\n",
      "|    time_elapsed    | 72       |\n",
      "|    total_timesteps | 2549     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -91.1    |\n",
      "|    critic_loss     | 198      |\n",
      "|    ent_coef        | 0.193    |\n",
      "|    ent_coef_loss   | 0.0121   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 149448   |\n",
      "---------------------------------\n",
      "episode: 30\n",
      "episode was finished at timestep: 8\n",
      "reward: 8.605803518160512\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0032426734765370687\n",
      "reward_2: 0.7848464887688047\n",
      "reward_3: 1.4000000000000006\n",
      "reward_4: 0.024902047450883487\n",
      "reward_5: 0.9460637716861501\n",
      "reward_6: 0.18480746352672583\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 25.5     |\n",
      "|    ep_rew_mean     | 173      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 33       |\n",
      "|    time_elapsed    | 76       |\n",
      "|    total_timesteps | 2549     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 137      |\n",
      "|    ent_coef        | 0.196    |\n",
      "|    ent_coef_loss   | -0.165   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 154348   |\n",
      "---------------------------------\n",
      "episode: 31\n",
      "episode was finished at timestep: 17\n",
      "reward: 9.40373348585317\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.004304136832555135\n",
      "reward_2: 0.8849068906205579\n",
      "reward_3: 1.5000000000000007\n",
      "reward_4: 0.020902892427173896\n",
      "reward_5: 0.9554733374050522\n",
      "reward_6: 0.2058860208988189\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 27.4     |\n",
      "|    ep_rew_mean     | 193      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 39       |\n",
      "|    time_elapsed    | 68       |\n",
      "|    total_timesteps | 2736     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -100     |\n",
      "|    critic_loss     | 231      |\n",
      "|    ent_coef        | 0.189    |\n",
      "|    ent_coef_loss   | 0.23     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 159435   |\n",
      "---------------------------------\n",
      "episode: 32\n",
      "episode was finished at timestep: 10\n",
      "reward: 9.396412611161283\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.009246402316623263\n",
      "reward_2: 0.8960241232358911\n",
      "reward_3: 1.5000000000000007\n",
      "reward_4: 0.016774524607172766\n",
      "reward_5: 0.930395027357197\n",
      "reward_6: 0.1726748033761979\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 26.4     |\n",
      "|    ep_rew_mean     | 204      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 33       |\n",
      "|    time_elapsed    | 78       |\n",
      "|    total_timesteps | 2636     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 329      |\n",
      "|    ent_coef        | 0.19     |\n",
      "|    ent_coef_loss   | -0.401   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 164235   |\n",
      "---------------------------------\n",
      "episode: 33\n",
      "episode was finished at timestep: 9\n",
      "reward: 7.42626376184806\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.006040955914391411\n",
      "reward_2: 0.6377056708124849\n",
      "reward_3: 1.5500000000000007\n",
      "reward_4: 0.01446847004072069\n",
      "reward_5: 0.9620302144732342\n",
      "reward_6: 0.2526747097969053\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.5     |\n",
      "|    ep_rew_mean     | 223      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 41       |\n",
      "|    time_elapsed    | 71       |\n",
      "|    total_timesteps | 2952     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -117     |\n",
      "|    critic_loss     | 210      |\n",
      "|    ent_coef        | 0.205    |\n",
      "|    ent_coef_loss   | 0.15     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 169451   |\n",
      "---------------------------------\n",
      "episode: 34\n",
      "episode was finished at timestep: 17\n",
      "reward: 8.641025354082064\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.00026727583673265244\n",
      "reward_2: 0.7708212815765215\n",
      "reward_3: 1.5500000000000007\n",
      "reward_4: 0.025890764328351138\n",
      "reward_5: 0.9680976858416404\n",
      "reward_6: 0.2992919101715087\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 26.9     |\n",
      "|    ep_rew_mean     | 192      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 40       |\n",
      "|    time_elapsed    | 66       |\n",
      "|    total_timesteps | 2695     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -124     |\n",
      "|    critic_loss     | 123      |\n",
      "|    ent_coef        | 0.209    |\n",
      "|    ent_coef_loss   | -0.0894  |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 174094   |\n",
      "---------------------------------\n",
      "episode: 35\n",
      "episode was finished at timestep: 19\n",
      "reward: 8.302660853928234\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.006600618362426758\n",
      "reward_2: 0.7591487015607395\n",
      "reward_3: 2.3499999999999996\n",
      "reward_4: 0.007820271189355594\n",
      "reward_5: 0.8940695981427095\n",
      "reward_6: 0.27912675881385807\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 34.1     |\n",
      "|    ep_rew_mean     | 213      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 46       |\n",
      "|    time_elapsed    | 74       |\n",
      "|    total_timesteps | 3409     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -112     |\n",
      "|    critic_loss     | 405      |\n",
      "|    ent_coef        | 0.222    |\n",
      "|    ent_coef_loss   | 0.414    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 179708   |\n",
      "---------------------------------\n",
      "episode: 36\n",
      "episode was finished at timestep: 48\n",
      "reward: 7.001130094773986\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0014627132150861952\n",
      "reward_2: 0.6314646700834892\n",
      "reward_3: 2.5999999999999988\n",
      "reward_4: -0.01714570106964061\n",
      "reward_5: 0.8663852349395373\n",
      "reward_6: 0.22130915427207998\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 33.8     |\n",
      "|    ep_rew_mean     | 213      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 47       |\n",
      "|    time_elapsed    | 71       |\n",
      "|    total_timesteps | 3382     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -130     |\n",
      "|    critic_loss     | 240      |\n",
      "|    ent_coef        | 0.238    |\n",
      "|    ent_coef_loss   | -0.154   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 184581   |\n",
      "---------------------------------\n",
      "episode: 37\n",
      "episode was finished at timestep: 52\n",
      "reward: 9.266521109720633\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0035975065496232773\n",
      "reward_2: 0.9167312393562771\n",
      "reward_3: 2.799999999999998\n",
      "reward_4: -0.006118508122736443\n",
      "reward_5: 0.7939465361102471\n",
      "reward_6: 0.19089689695835121\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 44.3     |\n",
      "|    ep_rew_mean     | 267      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 52       |\n",
      "|    time_elapsed    | 84       |\n",
      "|    total_timesteps | 4431     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -129     |\n",
      "|    critic_loss     | 353      |\n",
      "|    ent_coef        | 0.231    |\n",
      "|    ent_coef_loss   | -0.619   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 190530   |\n",
      "---------------------------------\n",
      "episode: 38\n",
      "episode was finished at timestep: 27\n",
      "reward: -77.68936246705975\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.002755736642413669\n",
      "reward_2: -10\n",
      "reward_3: 2.000000000000001\n",
      "reward_4: 0.01717084217890459\n",
      "reward_5: 0.9225492390017859\n",
      "reward_6: 0.25321062648296344\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 37.6     |\n",
      "|    ep_rew_mean     | 282      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 51       |\n",
      "|    time_elapsed    | 72       |\n",
      "|    total_timesteps | 3756     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -106     |\n",
      "|    critic_loss     | 230      |\n",
      "|    ent_coef        | 0.205    |\n",
      "|    ent_coef_loss   | -0.05    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 194755   |\n",
      "---------------------------------\n",
      "episode: 39\n",
      "episode was finished at timestep: 42\n",
      "reward: 9.825240322145222\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.004290488693449232\n",
      "reward_2: 0.9545874933847317\n",
      "reward_3: 2.549999999999999\n",
      "reward_4: 0.005267963495016375\n",
      "reward_5: 0.9115968706520662\n",
      "reward_6: 0.2387502851486204\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.3     |\n",
      "|    ep_rew_mean     | 164      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 44       |\n",
      "|    time_elapsed    | 67       |\n",
      "|    total_timesteps | 3027     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 189      |\n",
      "|    ent_coef        | 0.192    |\n",
      "|    ent_coef_loss   | -0.0319  |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 198926   |\n",
      "---------------------------------\n",
      "episode: 40\n",
      "episode was finished at timestep: 24\n",
      "reward: -77.58653915357742\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.010581541723675198\n",
      "reward_2: -10\n",
      "reward_3: 1.4000000000000006\n",
      "reward_4: 0.028516756149430764\n",
      "reward_5: 0.964706276523608\n",
      "reward_6: 0.2310153957605362\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.3     |\n",
      "|    ep_rew_mean     | 228      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 75       |\n",
      "|    total_timesteps | 3230     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -117     |\n",
      "|    critic_loss     | 249      |\n",
      "|    ent_coef        | 0.21     |\n",
      "|    ent_coef_loss   | 0.325    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 204029   |\n",
      "---------------------------------\n",
      "episode: 41\n",
      "episode was finished at timestep: 40\n",
      "reward: 9.577048702134714\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.004710884888966879\n",
      "reward_2: 0.9149002972538621\n",
      "reward_3: 2.0500000000000007\n",
      "reward_4: 0.01110271831310996\n",
      "reward_5: 0.9268908855108118\n",
      "reward_6: 0.24657124364376093\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 33.5     |\n",
      "|    ep_rew_mean     | 230      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 79       |\n",
      "|    total_timesteps | 3354     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -116     |\n",
      "|    critic_loss     | 271      |\n",
      "|    ent_coef        | 0.221    |\n",
      "|    ent_coef_loss   | 0.438    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 209053   |\n",
      "---------------------------------\n",
      "episode: 42\n",
      "episode was finished at timestep: 24\n",
      "reward: 8.998725328393288\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.00040938986672295466\n",
      "reward_2: 0.8134784072878395\n",
      "reward_3: 1.7500000000000009\n",
      "reward_4: 0.027220635927273945\n",
      "reward_5: 0.9883984286491676\n",
      "reward_6: 0.2849106105566025\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 41.5     |\n",
      "|    ep_rew_mean     | 234      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 56       |\n",
      "|    time_elapsed    | 73       |\n",
      "|    total_timesteps | 4150     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -125     |\n",
      "|    critic_loss     | 261      |\n",
      "|    ent_coef        | 0.221    |\n",
      "|    ent_coef_loss   | -0.0816  |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 214749   |\n",
      "---------------------------------\n",
      "episode: 43\n",
      "episode was finished at timestep: 38\n",
      "reward: 6.596171488675535\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0055616166856553816\n",
      "reward_2: 0.7338660321572441\n",
      "reward_3: 3.1999999999999966\n",
      "reward_4: 0.05934006481708394\n",
      "reward_5: 0.8370186286286577\n",
      "reward_6: 0.4186390342712403\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 47.2     |\n",
      "|    ep_rew_mean     | 161      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 63       |\n",
      "|    time_elapsed    | 74       |\n",
      "|    total_timesteps | 4725     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -142     |\n",
      "|    critic_loss     | 254      |\n",
      "|    ent_coef        | 0.246    |\n",
      "|    ent_coef_loss   | -0.184   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 220224   |\n",
      "---------------------------------\n",
      "episode: 44\n",
      "episode was finished at timestep: 22\n",
      "reward: 9.233239771719223\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.00317268172899882\n",
      "reward_2: 0.8903385244947669\n",
      "reward_3: 1.950000000000001\n",
      "reward_4: 0.006469806502919937\n",
      "reward_5: 0.8547488932877341\n",
      "reward_6: 0.20693691217899324\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 45\n",
      "episode was finished at timestep: 41\n",
      "reward: 8.999248154826851\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.007201449076334635\n",
      "reward_2: 0.8676626148408019\n",
      "reward_3: 2.5999999999999988\n",
      "reward_4: -0.0036135104675192055\n",
      "reward_5: 0.8418095173141159\n",
      "reward_6: 0.25190058493614187\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 46\n",
      "episode was finished at timestep: 20\n",
      "reward: 9.460207340929216\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.009152861436208089\n",
      "reward_2: 0.9149545477929808\n",
      "reward_3: 2.9499999999999975\n",
      "reward_4: 0.01601129328271142\n",
      "reward_5: 0.7771630078438879\n",
      "reward_6: 0.2440771325826644\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 47\n",
      "episode was finished at timestep: 20\n",
      "reward: 8.688182358736452\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.002282600270377265\n",
      "reward_2: 0.8313308124148578\n",
      "reward_3: 3.4999999999999956\n",
      "reward_4: 0.00334064496802327\n",
      "reward_5: 0.7945947092677912\n",
      "reward_6: 0.21803192400932314\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 48\n",
      "episode was finished at timestep: 15\n",
      "reward: 8.01705827126189\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.002784667412439982\n",
      "reward_2: 0.9656852792557202\n",
      "reward_3: 2.849999999999998\n",
      "reward_4: 0.028095221587267644\n",
      "reward_5: 0.7726515005997459\n",
      "reward_6: 0.296567431330681\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 47.6     |\n",
      "|    ep_rew_mean     | 413      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 61       |\n",
      "|    time_elapsed    | 77       |\n",
      "|    total_timesteps | 4765     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -173     |\n",
      "|    critic_loss     | 512      |\n",
      "|    ent_coef        | 0.446    |\n",
      "|    ent_coef_loss   | 0.148    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 244764   |\n",
      "---------------------------------\n",
      "episode: 49\n",
      "episode was finished at timestep: 36\n",
      "reward: 5.727873281116693\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0037646300262875027\n",
      "reward_2: 0.6731573750235726\n",
      "reward_3: 2.9999999999999973\n",
      "reward_4: 0.0412986404446238\n",
      "reward_5: 0.7433143583870175\n",
      "reward_6: 0.27227542901039126\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 38.7     |\n",
      "|    ep_rew_mean     | 324      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 46       |\n",
      "|    time_elapsed    | 83       |\n",
      "|    total_timesteps | 3873     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -193     |\n",
      "|    critic_loss     | 877      |\n",
      "|    ent_coef        | 0.457    |\n",
      "|    ent_coef_loss   | -0.228   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 248772   |\n",
      "---------------------------------\n",
      "episode: 50\n",
      "episode was finished at timestep: 41\n",
      "reward: 8.28569366424598\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.006526767545276218\n",
      "reward_2: 0.7685140791508512\n",
      "reward_3: 2.3999999999999995\n",
      "reward_4: 0.03219919594653604\n",
      "reward_5: 0.6967440162685418\n",
      "reward_6: 0.18945021474361445\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 36       |\n",
      "|    ep_rew_mean     | 307      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 49       |\n",
      "|    time_elapsed    | 72       |\n",
      "|    total_timesteps | 3595     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -192     |\n",
      "|    critic_loss     | 377      |\n",
      "|    ent_coef        | 0.469    |\n",
      "|    ent_coef_loss   | -0.288   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 253394   |\n",
      "---------------------------------\n",
      "episode: 51\n",
      "episode was finished at timestep: 50\n",
      "reward: 9.50895032759759\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.01072505580054389\n",
      "reward_2: 0.9190672491346714\n",
      "reward_3: 2.6999999999999984\n",
      "reward_4: 0.02657360660095435\n",
      "reward_5: 0.7423967709888137\n",
      "reward_6: 0.21179176652431508\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 38.1     |\n",
      "|    ep_rew_mean     | 335      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 48       |\n",
      "|    time_elapsed    | 78       |\n",
      "|    total_timesteps | 3809     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -182     |\n",
      "|    critic_loss     | 303      |\n",
      "|    ent_coef        | 0.457    |\n",
      "|    ent_coef_loss   | 0.247    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 258508   |\n",
      "---------------------------------\n",
      "episode: 52\n",
      "episode was finished at timestep: 8\n",
      "reward: 9.720634840600745\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0036847266885969374\n",
      "reward_2: 0.9546958762404314\n",
      "reward_3: 2.25\n",
      "reward_4: 0.0164871451445876\n",
      "reward_5: 0.7531415261129822\n",
      "reward_6: 0.2014138700962067\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 39.7     |\n",
      "|    ep_rew_mean     | 342      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 52       |\n",
      "|    time_elapsed    | 75       |\n",
      "|    total_timesteps | 3970     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -182     |\n",
      "|    critic_loss     | 323      |\n",
      "|    ent_coef        | 0.436    |\n",
      "|    ent_coef_loss   | -0.369   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 263569   |\n",
      "---------------------------------\n",
      "episode: 53\n",
      "episode was finished at timestep: 19\n",
      "reward: 6.31133877590567\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.00854979952176412\n",
      "reward_2: 0.76833215537247\n",
      "reward_3: 2.5999999999999988\n",
      "reward_4: 0.017568384414222038\n",
      "reward_5: 0.7451693294160523\n",
      "reward_6: 0.2871682610511781\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 42.1     |\n",
      "|    ep_rew_mean     | 354      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 50       |\n",
      "|    time_elapsed    | 84       |\n",
      "|    total_timesteps | 4214     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -171     |\n",
      "|    critic_loss     | 443      |\n",
      "|    ent_coef        | 0.438    |\n",
      "|    ent_coef_loss   | -0.105   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 268713   |\n",
      "---------------------------------\n",
      "episode: 54\n",
      "episode was finished at timestep: 46\n",
      "reward: 9.296527736593273\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0009669370121426052\n",
      "reward_2: 0.9015220207137686\n",
      "reward_3: 2.3999999999999995\n",
      "reward_4: 0.017450896567005998\n",
      "reward_5: 0.7369363870531344\n",
      "reward_6: 0.2084549483060837\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 45.9     |\n",
      "|    ep_rew_mean     | 382      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 60       |\n",
      "|    time_elapsed    | 75       |\n",
      "|    total_timesteps | 4592     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -165     |\n",
      "|    critic_loss     | 574      |\n",
      "|    ent_coef        | 0.447    |\n",
      "|    ent_coef_loss   | 0.341    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 273991   |\n",
      "---------------------------------\n",
      "episode: 55\n",
      "episode was finished at timestep: 64\n",
      "reward: 7.440714627417687\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0035362508561876086\n",
      "reward_2: 0.6816973400883775\n",
      "reward_3: 3.599999999999995\n",
      "reward_4: -0.003667589017425854\n",
      "reward_5: 0.82162391007911\n",
      "reward_6: 0.1979089596271516\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 49.9     |\n",
      "|    ep_rew_mean     | 407      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 57       |\n",
      "|    time_elapsed    | 87       |\n",
      "|    total_timesteps | 4991     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -191     |\n",
      "|    critic_loss     | 284      |\n",
      "|    ent_coef        | 0.458    |\n",
      "|    ent_coef_loss   | 0.101    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 279290   |\n",
      "---------------------------------\n",
      "episode: 56\n",
      "episode was finished at timestep: 62\n",
      "reward: 7.297985015716646\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0049647006723615855\n",
      "reward_2: 0.6632666427506575\n",
      "reward_3: 3.599999999999995\n",
      "reward_4: -0.00458127137377275\n",
      "reward_5: 0.8432942979499943\n",
      "reward_6: 0.18969244742393554\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 46.7     |\n",
      "|    ep_rew_mean     | 379      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 58       |\n",
      "|    time_elapsed    | 79       |\n",
      "|    total_timesteps | 4666     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -195     |\n",
      "|    critic_loss     | 475      |\n",
      "|    ent_coef        | 0.489    |\n",
      "|    ent_coef_loss   | -0.0288  |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 283865   |\n",
      "---------------------------------\n",
      "episode: 57\n",
      "episode was finished at timestep: 42\n",
      "reward: 8.454196255170563\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0012804302904340955\n",
      "reward_2: 0.7988823853722435\n",
      "reward_3: 3.2499999999999964\n",
      "reward_4: 0.0032399176378258687\n",
      "reward_5: 0.7946214804572356\n",
      "reward_6: 0.2434434475898738\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 58\n",
      "episode was finished at timestep: 41\n",
      "reward: 8.515240560759842\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.004975367916954888\n",
      "reward_2: 0.8083605117493449\n",
      "reward_3: 3.349999999999996\n",
      "reward_4: 0.012515527920882192\n",
      "reward_5: 0.7459002167420867\n",
      "reward_6: 0.20686072790622723\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 59\n",
      "episode was finished at timestep: 9\n",
      "reward: 6.96304971850242\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.002762856086095174\n",
      "reward_2: 0.6191788749948292\n",
      "reward_3: 3.4999999999999956\n",
      "reward_4: 0.010173995403341962\n",
      "reward_5: 0.7404108251810053\n",
      "reward_6: 0.1901121195554737\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 60\n",
      "episode was finished at timestep: 33\n",
      "reward: 7.474781560138005\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.009748335679372151\n",
      "reward_2: 0.6853436348345537\n",
      "reward_3: 3.7499999999999947\n",
      "reward_4: 0.00770477940134441\n",
      "reward_5: 0.7379171237850515\n",
      "reward_6: 0.20172545814514142\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 61\n",
      "episode was finished at timestep: 39\n",
      "reward: 9.224301051156406\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.010702983538309733\n",
      "reward_2: 0.9505367302185619\n",
      "reward_3: 4.749999999999991\n",
      "reward_4: -0.017090288666670686\n",
      "reward_5: 0.6044532324094648\n",
      "reward_6: 0.16234593653678908\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 62\n",
      "episode was finished at timestep: 48\n",
      "reward: -79.58378576863026\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.03778545260429382\n",
      "reward_2: -10\n",
      "reward_3: 5.349999999999989\n",
      "reward_4: -0.020931068195607878\n",
      "reward_5: 0.9679135613666877\n",
      "reward_6: 0.5772504296302796\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 44.7     |\n",
      "|    ep_rew_mean     | 344      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 57       |\n",
      "|    time_elapsed    | 77       |\n",
      "|    total_timesteps | 4466     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -223     |\n",
      "|    critic_loss     | 277      |\n",
      "|    ent_coef        | 0.532    |\n",
      "|    ent_coef_loss   | -0.105   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 313065   |\n",
      "---------------------------------\n",
      "episode: 63\n",
      "episode was finished at timestep: 17\n",
      "reward: 6.555641775868249\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0005419313907623291\n",
      "reward_2: 0.7895112254843281\n",
      "reward_3: 3.099999999999997\n",
      "reward_4: 0.01771630275932253\n",
      "reward_5: 0.7449431571861063\n",
      "reward_6: 0.35300699079036724\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 48.8     |\n",
      "|    ep_rew_mean     | 379      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 60       |\n",
      "|    time_elapsed    | 80       |\n",
      "|    total_timesteps | 4877     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -219     |\n",
      "|    critic_loss     | 580      |\n",
      "|    ent_coef        | 0.521    |\n",
      "|    ent_coef_loss   | -0.049   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 318376   |\n",
      "---------------------------------\n",
      "episode: 64\n",
      "episode was finished at timestep: 15\n",
      "reward: 7.094631424007004\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.008447678221596613\n",
      "reward_2: 0.8432559941803154\n",
      "reward_3: 3.349999999999996\n",
      "reward_4: 0.026389293870336415\n",
      "reward_5: 0.7785140334346662\n",
      "reward_6: 0.3669560977220536\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 65\n",
      "episode was finished at timestep: 18\n",
      "reward: 7.529696763086019\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.006971036063300239\n",
      "reward_2: 0.6802139729154051\n",
      "reward_3: 2.6999999999999984\n",
      "reward_4: 0.009471206575815216\n",
      "reward_5: 0.7495135777133084\n",
      "reward_6: 0.26931278550624804\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 42.7     |\n",
      "|    ep_rew_mean     | 326      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 53       |\n",
      "|    time_elapsed    | 80       |\n",
      "|    total_timesteps | 4271     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -241     |\n",
      "|    critic_loss     | 1.2e+03  |\n",
      "|    ent_coef        | 0.559    |\n",
      "|    ent_coef_loss   | -0.148   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 327570   |\n",
      "---------------------------------\n",
      "episode: 66\n",
      "episode was finished at timestep: 15\n",
      "reward: 7.597713235904005\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.005073312918345133\n",
      "reward_2: 0.9428040249483225\n",
      "reward_3: 2.8999999999999977\n",
      "reward_4: -0.00019389245016043332\n",
      "reward_5: 0.7812434913884503\n",
      "reward_6: 0.2802753307819371\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 67\n",
      "episode was finished at timestep: 23\n",
      "reward: 8.748469939119955\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0008836004469129774\n",
      "reward_2: 0.8631754658296149\n",
      "reward_3: 3.399999999999996\n",
      "reward_4: -0.003137992861611991\n",
      "reward_5: 0.6592339928029646\n",
      "reward_6: 0.20936642968654617\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 68\n",
      "episode was finished at timestep: 62\n",
      "reward: -78.28892584151798\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.058360897170172794\n",
      "reward_2: -10\n",
      "reward_3: 3.649999999999995\n",
      "reward_4: -0.01634902303628195\n",
      "reward_5: 0.6325913102779465\n",
      "reward_6: 0.150427468657494\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 69\n",
      "episode was finished at timestep: 10\n",
      "reward: 6.855032357735991\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0037789179219139945\n",
      "reward_2: 0.6083553231573976\n",
      "reward_3: 3.7499999999999947\n",
      "reward_4: -0.010381742416221015\n",
      "reward_5: 0.8070330775882563\n",
      "reward_6: 0.26748955214023606\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 70\n",
      "episode was finished at timestep: 60\n",
      "reward: 8.074845621423432\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.007824264632331001\n",
      "reward_2: 0.7903036243856898\n",
      "reward_3: 3.949999999999994\n",
      "reward_4: -0.01361525979771045\n",
      "reward_5: 0.6769931961054799\n",
      "reward_6: 0.19164310657978123\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 71\n",
      "episode was finished at timestep: 52\n",
      "reward: 6.092268191452315\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.004467543628480699\n",
      "reward_2: 0.7646833361049682\n",
      "reward_3: 3.4499999999999957\n",
      "reward_4: -0.014148245143098705\n",
      "reward_5: 0.7841255692144539\n",
      "reward_6: 0.30786943817138646\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 72\n",
      "episode was finished at timestep: 36\n",
      "reward: -78.52837757492452\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07044009831216601\n",
      "reward_2: -10\n",
      "reward_3: 3.7499999999999947\n",
      "reward_4: -0.027126708975969364\n",
      "reward_5: 0.5259558079458768\n",
      "reward_6: 0.0917401906251909\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 73\n",
      "episode was finished at timestep: 37\n",
      "reward: 9.22097490157936\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.006474410825305515\n",
      "reward_2: 0.9143815224140625\n",
      "reward_3: 3.1999999999999966\n",
      "reward_4: -0.009744287440710906\n",
      "reward_5: 0.7593637983866037\n",
      "reward_6: 0.23056096756458233\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 74\n",
      "episode was finished at timestep: 50\n",
      "reward: 5.219365059409681\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.009642016887664796\n",
      "reward_2: 0.6479350962516152\n",
      "reward_3: 3.399999999999996\n",
      "reward_4: 0.0016859829887090427\n",
      "reward_5: 0.748101015852179\n",
      "reward_6: 0.2834840931892397\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 75\n",
      "episode was finished at timestep: 45\n",
      "reward: 5.512666501572344\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.010272628731197782\n",
      "reward_2: 0.6686009240951634\n",
      "reward_3: 3.1999999999999966\n",
      "reward_4: 0.009924534857400715\n",
      "reward_5: 0.8019627464030739\n",
      "reward_6: 0.29234604561328836\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 76\n",
      "episode was finished at timestep: 3\n",
      "reward: 5.676743749609974\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.010174493657218085\n",
      "reward_2: 0.6973901514475309\n",
      "reward_3: 3.4499999999999957\n",
      "reward_4: 0.008836025385051158\n",
      "reward_5: 0.7409924131440416\n",
      "reward_6: 0.29565641546249344\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 77\n",
      "episode was finished at timestep: 8\n",
      "reward: 8.69716502399562\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0022272686163584392\n",
      "reward_2: 0.8519144161486846\n",
      "reward_3: 3.2999999999999963\n",
      "reward_4: -0.013374986136029464\n",
      "reward_5: 0.733228018768596\n",
      "reward_6: 0.25740883374214163\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 78\n",
      "episode was finished at timestep: 52\n",
      "reward: 9.291668069713836\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -8.89632436964247e-06\n",
      "reward_2: 0.9340916087145651\n",
      "reward_3: 3.2999999999999963\n",
      "reward_4: -0.01702857134297659\n",
      "reward_5: 0.7349818225868918\n",
      "reward_6: 0.21975084447860682\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 79\n",
      "episode was finished at timestep: 59\n",
      "reward: 8.935823216781356\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.004969303475485908\n",
      "reward_2: 0.8796973830928725\n",
      "reward_3: 3.149999999999997\n",
      "reward_4: -0.007360351123851103\n",
      "reward_5: 0.7622501133482469\n",
      "reward_6: 0.19942615115642537\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 80\n",
      "episode was finished at timestep: 52\n",
      "reward: 9.768803235799675\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.006630257103178236\n",
      "reward_2: 0.9815434022443814\n",
      "reward_3: 2.9999999999999973\n",
      "reward_4: -0.011093753978495612\n",
      "reward_5: 0.754085477293689\n",
      "reward_6: 0.2573508294820781\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 81\n",
      "episode was finished at timestep: 44\n",
      "reward: 10.018517738212367\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.001843841208351983\n",
      "reward_2: 0.987878509081695\n",
      "reward_3: 3.399999999999996\n",
      "reward_4: -0.0022376567445890317\n",
      "reward_5: 0.8809761551689735\n",
      "reward_6: 0.2538052722215651\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 82\n",
      "episode was finished at timestep: 49\n",
      "reward: 9.600986553603779\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.007246364487542047\n",
      "reward_2: 0.9659717456944016\n",
      "reward_3: 2.9999999999999973\n",
      "reward_4: -0.004022760359913207\n",
      "reward_5: 0.6997243089215779\n",
      "reward_6: 0.21251672649383557\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 83\n",
      "episode was finished at timestep: 50\n",
      "reward: 7.517341619174072\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.005514261457655165\n",
      "reward_2: 0.6682701172240607\n",
      "reward_3: 3.949999999999994\n",
      "reward_4: 0.018414495704118253\n",
      "reward_5: 0.7678365845693605\n",
      "reward_6: 0.26101572597026823\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 84\n",
      "episode was finished at timestep: 68\n",
      "reward: 7.381496475528688\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.009125252564748129\n",
      "reward_2: 0.6698153962173187\n",
      "reward_3: 4.149999999999993\n",
      "reward_4: 0.008141161590500729\n",
      "reward_5: 0.7402783589361507\n",
      "reward_6: 0.22613757336139717\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 85\n",
      "episode was finished at timestep: 27\n",
      "reward: 8.694093821790082\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.00921373036172655\n",
      "reward_2: 0.8295503384748131\n",
      "reward_3: 3.2499999999999964\n",
      "reward_4: 0.01504914237949464\n",
      "reward_5: 0.6995041022124382\n",
      "reward_6: 0.24657426977157582\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 86\n",
      "episode was finished at timestep: 18\n",
      "reward: 9.150545155585403\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.008060557312435573\n",
      "reward_2: 0.888064138876001\n",
      "reward_3: 3.999999999999994\n",
      "reward_4: 0.025856543420148342\n",
      "reward_5: 0.6716436565869285\n",
      "reward_6: 0.17506326460838262\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 87\n",
      "episode was finished at timestep: 18\n",
      "reward: 8.018962250505107\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.003972464799880981\n",
      "reward_2: 0.7482759746258604\n",
      "reward_3: 2.549999999999999\n",
      "reward_4: -0.002842149518821202\n",
      "reward_5: 0.7881031945296598\n",
      "reward_6: 0.2710209199190141\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 88\n",
      "episode was finished at timestep: 28\n",
      "reward: 7.527984726677374\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.008455391062630548\n",
      "reward_2: 0.9327205852797329\n",
      "reward_3: 2.8999999999999977\n",
      "reward_4: 0.011644959167967954\n",
      "reward_5: 0.7192052379220368\n",
      "reward_6: 0.2619238575696945\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 89\n",
      "episode was finished at timestep: 34\n",
      "reward: 8.659266439733276\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0028561009301079645\n",
      "reward_2: 0.8353989186073155\n",
      "reward_3: 3.949999999999994\n",
      "reward_4: 0.006489547450326682\n",
      "reward_5: 0.7297867801839021\n",
      "reward_6: 0.19670136535167737\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 90\n",
      "episode was finished at timestep: 29\n",
      "reward: 8.265252572426853\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0011708597342173258\n",
      "reward_2: 0.775829690233047\n",
      "reward_3: 4.099999999999993\n",
      "reward_4: 0.002905902950382\n",
      "reward_5: 0.8117504078310028\n",
      "reward_6: 0.22424161219596883\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 91\n",
      "episode was finished at timestep: 15\n",
      "reward: 8.471457899419175\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0013528936439090305\n",
      "reward_2: 0.8016814496065221\n",
      "reward_3: 4.249999999999993\n",
      "reward_4: 0.015725806640792258\n",
      "reward_5: 0.7206483957204607\n",
      "reward_6: 0.2123376806974414\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 92\n",
      "episode was finished at timestep: 13\n",
      "reward: 9.548530860655863\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0059733364317152236\n",
      "reward_2: 0.9422781995597008\n",
      "reward_3: 4.199999999999993\n",
      "reward_4: 0.005849082418351088\n",
      "reward_5: 0.7499418729886642\n",
      "reward_6: 0.21898406827449768\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 93\n",
      "episode was finished at timestep: 61\n",
      "reward: 8.46107091090405\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.010155434078640408\n",
      "reward_2: 0.7943588244283124\n",
      "reward_3: 4.499999999999992\n",
      "reward_4: 0.03589815187270375\n",
      "reward_5: 0.7226851127024225\n",
      "reward_6: 0.10588542187213901\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 94\n",
      "episode was finished at timestep: 62\n",
      "reward: 8.862867154690093\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.001919783486260308\n",
      "reward_2: 0.8482177462464113\n",
      "reward_3: 4.249999999999993\n",
      "reward_4: 0.018497892408480824\n",
      "reward_5: 0.7354662132482558\n",
      "reward_6: 0.19502894902229306\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 95\n",
      "episode was finished at timestep: 36\n",
      "reward: 6.824116732461256\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.003035667207505968\n",
      "reward_2: 0.60225167387252\n",
      "reward_3: 4.149999999999993\n",
      "reward_4: 0.01543554834724972\n",
      "reward_5: 0.7389122322999967\n",
      "reward_6: 0.14618905627727463\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 96\n",
      "episode was finished at timestep: 5\n",
      "reward: 7.695371874050151\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.006175749169455634\n",
      "reward_2: 0.7004562987981895\n",
      "reward_3: 4.199999999999993\n",
      "reward_4: 0.02955157458604859\n",
      "reward_5: 0.702382595916858\n",
      "reward_6: 0.15854204022884377\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 97\n",
      "episode was finished at timestep: 14\n",
      "reward: 9.813848146666182\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0022098090913560656\n",
      "reward_2: 0.9612738368632019\n",
      "reward_3: 2.6999999999999984\n",
      "reward_4: 0.015089270847132496\n",
      "reward_5: 0.7354782289625577\n",
      "reward_6: 0.26931486511230496\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 98\n",
      "episode was finished at timestep: 38\n",
      "reward: 7.190646428901829\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0012662708759307861\n",
      "reward_2: 0.6354350348865843\n",
      "reward_3: 4.199999999999993\n",
      "reward_4: 0.024661183827892758\n",
      "reward_5: 0.72130544931331\n",
      "reward_6: 0.18927750074863448\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 99\n",
      "episode was finished at timestep: 18\n",
      "reward: 9.24912249252006\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.005480759011374579\n",
      "reward_2: 0.8892968214805788\n",
      "reward_3: 2.849999999999998\n",
      "reward_4: 0.014216044383686607\n",
      "reward_5: 0.7705731978472926\n",
      "reward_6: 0.25554712677001923\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 100\n",
      "episode was finished at timestep: 27\n",
      "reward: 7.618798837818509\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0073437982135348846\n",
      "reward_2: 0.7008822260103391\n",
      "reward_3: 4.099999999999993\n",
      "reward_4: 0.00896108984379495\n",
      "reward_5: 0.7230221881177457\n",
      "reward_6: 0.2238272544145583\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 101\n",
      "episode was finished at timestep: 64\n",
      "reward: 7.224451594044761\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.00044677058855692545\n",
      "reward_2: 0.6387708015216983\n",
      "reward_3: 3.949999999999994\n",
      "reward_4: 0.011526826529277515\n",
      "reward_5: 0.7656523440052406\n",
      "reward_6: 0.25633832955360436\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 102\n",
      "episode was finished at timestep: 28\n",
      "reward: 6.157866303060744\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0006991432772742377\n",
      "reward_2: 0.7631221433926438\n",
      "reward_3: 3.4499999999999957\n",
      "reward_4: 0.0004886717411167751\n",
      "reward_5: 0.7530243120496252\n",
      "reward_6: 0.29619461321830753\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 103\n",
      "episode was finished at timestep: 16\n",
      "reward: 7.789648197870749\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.003597327735688951\n",
      "reward_2: 0.718788578449366\n",
      "reward_3: 4.049999999999994\n",
      "reward_4: 0.011780795061828825\n",
      "reward_5: 0.7351489439270971\n",
      "reward_6: 0.2130015935897832\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 104\n",
      "episode was finished at timestep: 5\n",
      "reward: 7.835884816452486\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.010078506999545628\n",
      "reward_2: 0.7190229055176911\n",
      "reward_3: 4.599999999999992\n",
      "reward_4: 0.015299762331113981\n",
      "reward_5: 0.7433123963030576\n",
      "reward_6: 0.2274562510252004\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 105\n",
      "episode was finished at timestep: 16\n",
      "reward: 8.801105399164229\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0025622877809736463\n",
      "reward_2: 0.8636988818221389\n",
      "reward_3: 3.649999999999995\n",
      "reward_4: -0.010847255492596589\n",
      "reward_5: 0.713943488792016\n",
      "reward_6: 0.26642452085018187\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 106\n",
      "episode was finished at timestep: 15\n",
      "reward: 7.294161624284732\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.008400624328189426\n",
      "reward_2: 0.6602745945085786\n",
      "reward_3: 4.399999999999992\n",
      "reward_4: 0.0026300065445961705\n",
      "reward_5: 0.7360610215028804\n",
      "reward_6: 0.2626777520179756\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 107\n",
      "episode was finished at timestep: 12\n",
      "reward: 8.838259462891283\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0019556734297010636\n",
      "reward_2: 0.8514856210301287\n",
      "reward_3: 3.7999999999999945\n",
      "reward_4: 0.008629302259006124\n",
      "reward_5: 0.7223365477119672\n",
      "reward_6: 0.2364525356292726\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 108\n",
      "episode was finished at timestep: 12\n",
      "reward: 8.747969816725254\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0016596542464362251\n",
      "reward_2: 0.8316692643753815\n",
      "reward_3: 4.849999999999991\n",
      "reward_4: 0.015005216341595542\n",
      "reward_5: 0.7346860752522134\n",
      "reward_6: 0.24090088331699355\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 109\n",
      "episode was finished at timestep: 44\n",
      "reward: 8.101951739162205\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.009468193186653985\n",
      "reward_2: 0.7363289066398141\n",
      "reward_3: 4.749999999999991\n",
      "reward_4: 0.029317687558939126\n",
      "reward_5: 0.7580786313589934\n",
      "reward_6: 0.227535214066505\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 110\n",
      "episode was finished at timestep: 35\n",
      "reward: 9.628646628305415\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0061200691594017875\n",
      "reward_2: 0.9687053414372727\n",
      "reward_3: 3.5499999999999954\n",
      "reward_4: -0.003853778325903079\n",
      "reward_5: 0.6759403905477449\n",
      "reward_6: 0.23954046869278034\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 111\n",
      "episode was finished at timestep: 54\n",
      "reward: 9.363213251991839\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.002925028403600057\n",
      "reward_2: 0.9180883272911036\n",
      "reward_3: 3.899999999999994\n",
      "reward_4: 0.0035451707018833646\n",
      "reward_5: 0.7431440252322906\n",
      "reward_6: 0.24940627121925396\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 112\n",
      "episode was finished at timestep: 15\n",
      "reward: 8.056433435432961\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.009181018008126153\n",
      "reward_2: 0.985456680686891\n",
      "reward_3: 4.799999999999991\n",
      "reward_4: 0.014680822934849118\n",
      "reward_5: 0.7662172187662912\n",
      "reward_6: 0.2976572057008746\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 113\n",
      "episode was finished at timestep: 41\n",
      "reward: 9.770496602919117\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.004224981864293416\n",
      "reward_2: 0.9499426014236914\n",
      "reward_3: 4.599999999999992\n",
      "reward_4: 0.015948239240502884\n",
      "reward_5: 0.7521233068705852\n",
      "reward_6: 0.29485821926593825\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 114\n",
      "episode was finished at timestep: 75\n",
      "reward: 8.977676575250259\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0009873231252034505\n",
      "reward_2: 0.8863228915427358\n",
      "reward_3: 4.449999999999992\n",
      "reward_4: -0.008860150448828534\n",
      "reward_5: 0.717521499674163\n",
      "reward_6: 0.24084713661670676\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 115\n",
      "episode was finished at timestep: 14\n",
      "reward: 7.216610141028257\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.009781581163406373\n",
      "reward_2: 0.6588386225666798\n",
      "reward_3: 4.249999999999993\n",
      "reward_4: 0.0037119491669936624\n",
      "reward_5: 0.7065997903084855\n",
      "reward_6: 0.218820691347123\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 116\n",
      "episode was finished at timestep: 15\n",
      "reward: 7.634553022958795\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.008422534333335029\n",
      "reward_2: 0.7229616421351288\n",
      "reward_3: 4.099999999999993\n",
      "reward_4: -0.010667413073285132\n",
      "reward_5: 0.7140437457842558\n",
      "reward_6: 0.23003131234645824\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 117\n",
      "episode was finished at timestep: 29\n",
      "reward: 8.038740577476666\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.003831866052415636\n",
      "reward_2: 0.7431204161775662\n",
      "reward_3: 4.849999999999991\n",
      "reward_4: 0.002875972060103322\n",
      "reward_5: 0.8087138292147283\n",
      "reward_6: 0.26524084174633034\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 118\n",
      "episode was finished at timestep: 68\n",
      "reward: 7.010154935197293\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.007222953107621935\n",
      "reward_2: 0.625814182957062\n",
      "reward_3: 3.899999999999994\n",
      "reward_4: 0.007895644838542637\n",
      "reward_5: 0.7053605396388841\n",
      "reward_6: 0.24181872630119317\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 119\n",
      "episode was finished at timestep: 24\n",
      "reward: 6.921334662185336\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.009844501150978936\n",
      "reward_2: 0.6165431133246824\n",
      "reward_3: 4.399999999999992\n",
      "reward_4: 0.005207647998639402\n",
      "reward_5: 0.7249162074041038\n",
      "reward_6: 0.2316701986789702\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 120\n",
      "episode was finished at timestep: 71\n",
      "reward: 8.429137115315404\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0021227902836269802\n",
      "reward_2: 0.7985918833906835\n",
      "reward_3: 4.099999999999993\n",
      "reward_4: 0.005855966923180347\n",
      "reward_5: 0.7221007791767706\n",
      "reward_6: 0.27302965724468276\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 121\n",
      "episode was finished at timestep: 64\n",
      "reward: 9.478950291594856\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.008405191368526882\n",
      "reward_2: 0.9419347242055636\n",
      "reward_3: 3.8499999999999943\n",
      "reward_4: 0.0051612108222414575\n",
      "reward_5: 0.6799787718522581\n",
      "reward_6: 0.23009589755535187\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 122\n",
      "episode was finished at timestep: 64\n",
      "reward: 8.830256528856307\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0050308810340033636\n",
      "reward_2: 0.8659518031186139\n",
      "reward_3: 3.5499999999999954\n",
      "reward_4: 0.003524967991007202\n",
      "reward_5: 0.655215422578307\n",
      "reward_6: 0.2237844851016999\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 123\n",
      "episode was finished at timestep: 15\n",
      "reward: 9.302665940730252\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.005216045512093438\n",
      "reward_2: 0.9240262180316845\n",
      "reward_3: 3.699999999999995\n",
      "reward_4: 0.0009447254340699373\n",
      "reward_5: 0.6626906629689644\n",
      "reward_6: 0.24493044221401206\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 124\n",
      "episode was finished at timestep: 10\n",
      "reward: 9.25509063436958\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0028812083933088513\n",
      "reward_2: 0.9272519774420601\n",
      "reward_3: 3.899999999999994\n",
      "reward_4: -0.007653275687306405\n",
      "reward_5: 0.6582916432832708\n",
      "reward_6: 0.24237058544158885\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 125\n",
      "episode was finished at timestep: 26\n",
      "reward: 8.173125044343532\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.00435981551806132\n",
      "reward_2: 0.7947395773090639\n",
      "reward_3: 3.899999999999994\n",
      "reward_4: -0.00507013716177795\n",
      "reward_5: 0.634440684718309\n",
      "reward_6: 0.22516865396499675\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 126\n",
      "episode was finished at timestep: 47\n",
      "reward: 8.467907471649836\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0024223175313737655\n",
      "reward_2: 0.797905949824406\n",
      "reward_3: 5.699999999999988\n",
      "reward_4: 0.009708510305351581\n",
      "reward_5: 0.7479309479954814\n",
      "reward_6: 0.2607231601476674\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 127\n",
      "episode was finished at timestep: 13\n",
      "reward: 8.88288406782669\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0013074682818518745\n",
      "reward_2: 0.8623337881563996\n",
      "reward_3: 4.399999999999992\n",
      "reward_4: -0.0014979937401078303\n",
      "reward_5: 0.7404372979192957\n",
      "reward_6: 0.2564812161922452\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 128\n",
      "episode was finished at timestep: 6\n",
      "reward: 7.792462214825251\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.010056951973173354\n",
      "reward_2: 0.7443303246708644\n",
      "reward_3: 4.799999999999991\n",
      "reward_4: -0.009601481278433823\n",
      "reward_5: 0.6962482903645859\n",
      "reward_6: 0.2278001292943953\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 129\n",
      "episode was finished at timestep: 45\n",
      "reward: 9.772588147355922\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.006396855248345269\n",
      "reward_2: 0.9820900293488888\n",
      "reward_3: 4.099999999999993\n",
      "reward_4: -0.0032502952873278445\n",
      "reward_5: 0.6908248340391373\n",
      "reward_6: 0.25689562940597566\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 130\n",
      "episode was finished at timestep: 20\n",
      "reward: 8.279401368486525\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.005006026559405857\n",
      "reward_2: 0.8222425375456446\n",
      "reward_3: 3.999999999999994\n",
      "reward_4: -0.026280970941435697\n",
      "reward_5: 0.6956865025289045\n",
      "reward_6: 0.2204950263500215\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 131\n",
      "episode was finished at timestep: 11\n",
      "reward: 7.866876572100645\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -1.6854868994818793e-05\n",
      "reward_2: 0.7432755791495351\n",
      "reward_3: 5.449999999999989\n",
      "reward_4: -7.318138920879846e-06\n",
      "reward_5: 0.723505428330157\n",
      "reward_6: 0.19651524388790131\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 132\n",
      "episode was finished at timestep: 40\n",
      "reward: 8.967316934464927\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.007373803191714817\n",
      "reward_2: 0.848474282831217\n",
      "reward_3: 4.799999999999991\n",
      "reward_4: 0.025780031889572258\n",
      "reward_5: 0.76960928503296\n",
      "reward_6: 0.21040693485736883\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 133\n",
      "episode was finished at timestep: 6\n",
      "reward: 7.594999219662344\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.003165103991826375\n",
      "reward_2: 0.739635151788464\n",
      "reward_3: 4.3499999999999925\n",
      "reward_4: -0.027486690160426264\n",
      "reward_5: 0.6858369299024069\n",
      "reward_6: 0.21455970072746244\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 134\n",
      "episode was finished at timestep: 51\n",
      "reward: 9.563083226445928\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0007689893245697021\n",
      "reward_2: 0.9326690037206113\n",
      "reward_3: 4.449999999999992\n",
      "reward_4: 0.014653722177122859\n",
      "reward_5: 0.7252224134091276\n",
      "reward_6: 0.2594546618461615\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 135\n",
      "episode was finished at timestep: 90\n",
      "reward: 6.65289175897787\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0029521286487579346\n",
      "reward_2: 0.615020738044129\n",
      "reward_3: 4.6499999999999915\n",
      "reward_4: -0.019345711157620543\n",
      "reward_5: 0.711256643058394\n",
      "reward_6: 0.17856702947616587\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 136\n",
      "episode was finished at timestep: 46\n",
      "reward: 8.620016872131314\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.00460061960750156\n",
      "reward_2: 0.8033678489531006\n",
      "reward_3: 4.549999999999992\n",
      "reward_4: 0.023801248707547275\n",
      "reward_5: 0.7414021989554984\n",
      "reward_6: 0.2652558448314669\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 137\n",
      "episode was finished at timestep: 74\n",
      "reward: 8.893429513089911\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0057121197382609045\n",
      "reward_2: 0.883904619934364\n",
      "reward_3: 4.699999999999991\n",
      "reward_4: -0.006970873098862711\n",
      "reward_5: 0.7045216164431624\n",
      "reward_6: 0.17852337503433247\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 138\n",
      "episode was finished at timestep: 42\n",
      "reward: 7.363020201573262\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0032974421977996827\n",
      "reward_2: 0.6901303601611346\n",
      "reward_3: 4.6499999999999915\n",
      "reward_4: -0.006078141425973627\n",
      "reward_5: 0.7114632311013825\n",
      "reward_6: 0.18181666278839104\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 139\n",
      "episode was finished at timestep: 20\n",
      "reward: 8.328311850327841\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.006185144848293729\n",
      "reward_2: 0.8049154455291149\n",
      "reward_3: 4.399999999999992\n",
      "reward_4: -0.003426766974705231\n",
      "reward_5: 0.7165563922368968\n",
      "reward_6: 0.20544450783729495\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 140\n",
      "episode was finished at timestep: 14\n",
      "reward: 6.9030251157028975\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0025227612919277616\n",
      "reward_2: 0.6071883847619808\n",
      "reward_3: 4.199999999999993\n",
      "reward_4: 0.012921735821874449\n",
      "reward_5: 0.7263537026138629\n",
      "reward_6: 0.2177532097101207\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 141\n",
      "episode was finished at timestep: 21\n",
      "reward: 9.660034391298629\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.001234236028459337\n",
      "reward_2: 0.9480963625705664\n",
      "reward_3: 3.699999999999995\n",
      "reward_4: 0.021492451956547143\n",
      "reward_5: 0.6652169919463492\n",
      "reward_6: 0.2388477858304976\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 142\n",
      "episode was finished at timestep: 4\n",
      "reward: 8.921602211552587\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.005559429195192125\n",
      "reward_2: 0.8976888990727894\n",
      "reward_3: 4.299999999999993\n",
      "reward_4: -0.01383949181663425\n",
      "reward_5: 0.6620165185033504\n",
      "reward_6: 0.1937765308618542\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 143\n",
      "episode was finished at timestep: 40\n",
      "reward: 9.532417494160786\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.00027767883406745064\n",
      "reward_2: 0.9460627239460253\n",
      "reward_3: 3.599999999999995\n",
      "reward_4: 0.0033523583035000113\n",
      "reward_5: 0.664051721295572\n",
      "reward_6: 0.2728427937030793\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 144\n",
      "episode was finished at timestep: 79\n",
      "reward: 7.636679299480669\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.004128372669219971\n",
      "reward_2: 0.7259515469029165\n",
      "reward_3: 4.149999999999993\n",
      "reward_4: -0.005850311609860057\n",
      "reward_5: 0.7093745077988556\n",
      "reward_6: 0.17006994867324832\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 145\n",
      "episode was finished at timestep: 68\n",
      "reward: 9.636324205811395\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0046993672847747804\n",
      "reward_2: 0.973020212570796\n",
      "reward_3: 4.149999999999993\n",
      "reward_4: 0.00044736599696335586\n",
      "reward_5: 0.6159069742588261\n",
      "reward_6: 0.23682263696193717\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 146\n",
      "episode was finished at timestep: 37\n",
      "reward: 9.15650143887996\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0037938720650143093\n",
      "reward_2: 0.9109465068015361\n",
      "reward_3: 3.899999999999994\n",
      "reward_4: 0.00025704310573786414\n",
      "reward_5: 0.635849755114442\n",
      "reward_6: 0.23429715657234185\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 147\n",
      "episode was finished at timestep: 19\n",
      "reward: 9.517959691508604\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.002040777603785197\n",
      "reward_2: 0.9596503843995399\n",
      "reward_3: 4.099999999999993\n",
      "reward_4: -0.0017051764908073608\n",
      "reward_5: 0.6370274858269415\n",
      "reward_6: 0.2188646533489228\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 148\n",
      "episode was finished at timestep: 49\n",
      "reward: 9.630267207013175\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.010557272699144152\n",
      "reward_2: 0.976712939167738\n",
      "reward_3: 4.199999999999993\n",
      "reward_4: -0.004418052777758277\n",
      "reward_5: 0.6427283800828446\n",
      "reward_6: 0.21917700850963595\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 149\n",
      "episode was finished at timestep: 36\n",
      "reward: 7.39141331811296\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.004884590705235799\n",
      "reward_2: 0.6772588357297279\n",
      "reward_3: 4.94999999999999\n",
      "reward_4: 0.01968434951028229\n",
      "reward_5: 0.6573041178008245\n",
      "reward_6: 0.1627883090972898\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 150\n",
      "episode was finished at timestep: 75\n",
      "reward: 9.23692913217231\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.006675473186704847\n",
      "reward_2: 0.9288620804835668\n",
      "reward_3: 4.299999999999993\n",
      "reward_4: -0.008157723073568945\n",
      "reward_5: 0.665644295231089\n",
      "reward_6: 0.2117521175146102\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 151\n",
      "episode was finished at timestep: 23\n",
      "reward: 9.190850434789935\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.008210855060153538\n",
      "reward_2: 0.8970723482739341\n",
      "reward_3: 4.3499999999999925\n",
      "reward_4: 0.016943483116074985\n",
      "reward_5: 0.6361372543916362\n",
      "reward_6: 0.25021738433837937\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 152\n",
      "episode was finished at timestep: 27\n",
      "reward: 9.549751619757224\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.008140805032518175\n",
      "reward_2: 0.9476480087749595\n",
      "reward_3: 3.899999999999994\n",
      "reward_4: 0.00552097058652592\n",
      "reward_5: 0.6955601614215258\n",
      "reward_6: 0.23646042847633375\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 153\n",
      "episode was finished at timestep: 65\n",
      "reward: 9.964629150432764\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.006534625424279107\n",
      "reward_2: 0.9934701452963421\n",
      "reward_3: 3.999999999999994\n",
      "reward_4: 0.02095773219498838\n",
      "reward_5: 0.6319169187335459\n",
      "reward_6: 0.2232905038595201\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 154\n",
      "episode was finished at timestep: 29\n",
      "reward: 9.823989351993651\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0061355815993414985\n",
      "reward_2: 0.9735403251645799\n",
      "reward_3: 3.699999999999995\n",
      "reward_4: 0.019415505058242674\n",
      "reward_5: 0.6534536771250363\n",
      "reward_6: 0.23253128135204315\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 155\n",
      "episode was finished at timestep: 71\n",
      "reward: 8.505928835078228\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.007173467344707913\n",
      "reward_2: 0.7996969786385645\n",
      "reward_3: 3.649999999999995\n",
      "reward_4: 0.032153292101470186\n",
      "reward_5: 0.6504412261931833\n",
      "reward_6: 0.2073722436428076\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 156\n",
      "episode was finished at timestep: 56\n",
      "reward: 9.965589294431417\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.008606064319610595\n",
      "reward_2: 0.9820705753516202\n",
      "reward_3: 3.899999999999994\n",
      "reward_4: 0.030135457156883802\n",
      "reward_5: 0.6041119118009782\n",
      "reward_6: 0.27191518688201877\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 157\n",
      "episode was finished at timestep: 72\n",
      "reward: 9.265710442286599\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.004591210020913018\n",
      "reward_2: 0.9155323557683239\n",
      "reward_3: 4.149999999999993\n",
      "reward_4: 0.011611275903304517\n",
      "reward_5: 0.6088764778633051\n",
      "reward_6: 0.2437227877378465\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 158\n",
      "episode was finished at timestep: 16\n",
      "reward: 10.061448878968733\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.010794626341925727\n",
      "reward_2: 0.9922126496632895\n",
      "reward_3: 4.199999999999993\n",
      "reward_4: 0.041263144758812445\n",
      "reward_5: 0.5906593553962981\n",
      "reward_6: 0.2132177945375442\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 159\n",
      "episode was finished at timestep: 48\n",
      "reward: 8.36420139049097\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.005331582493252224\n",
      "reward_2: 0.7727564240797526\n",
      "reward_3: 3.7499999999999947\n",
      "reward_4: 0.03870295820055759\n",
      "reward_5: 0.6657374990541811\n",
      "reward_6: 0.21162041568756074\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 160\n",
      "episode was finished at timestep: 64\n",
      "reward: 9.55170227348029\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0020744476053449843\n",
      "reward_2: 0.9506055505247879\n",
      "reward_3: 5.299999999999989\n",
      "reward_4: 0.03724420600717522\n",
      "reward_5: 0.3886860206750351\n",
      "reward_6: 0.2615859814882281\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 161\n",
      "episode was finished at timestep: 3\n",
      "reward: 9.209511892857085\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.00446475280655755\n",
      "reward_2: 0.8767624888711429\n",
      "reward_3: 4.199999999999993\n",
      "reward_4: 0.03937055719948987\n",
      "reward_5: 0.6327755975112154\n",
      "reward_6: 0.25157667958736407\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 162\n",
      "episode was finished at timestep: 42\n",
      "reward: 7.8416817913378845\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0030045628547668455\n",
      "reward_2: 0.7475371533079544\n",
      "reward_3: 4.799999999999991\n",
      "reward_4: 0.012175641013624698\n",
      "reward_5: 0.4985145961003886\n",
      "reward_6: 0.26782940351963036\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 163\n",
      "episode was finished at timestep: 12\n",
      "reward: 9.038335944721393\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.007687579923205906\n",
      "reward_2: 0.9274592491381671\n",
      "reward_3: 4.749999999999991\n",
      "reward_4: -0.01687360825550769\n",
      "reward_5: 0.49704420752620304\n",
      "reward_6: 0.2636608567237855\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 164\n",
      "episode was finished at timestep: 42\n",
      "reward: 4.707489610285087\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.006152687470118204\n",
      "reward_2: 0.6133855954590107\n",
      "reward_3: 4.849999999999991\n",
      "reward_4: 0.005553692628405002\n",
      "reward_5: 0.46995182685842085\n",
      "reward_6: 0.2915294995307923\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 165\n",
      "episode was finished at timestep: 5\n",
      "reward: 7.251037630582927\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0009153783321380615\n",
      "reward_2: 0.6911293339922563\n",
      "reward_3: 4.599999999999992\n",
      "reward_4: 0.010513607137005323\n",
      "reward_5: 0.37103299838288956\n",
      "reward_6: 0.26716314816475006\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 166\n",
      "episode was finished at timestep: 17\n",
      "reward: 6.686279079317188\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.004977567990620931\n",
      "reward_2: 0.8509691405943309\n",
      "reward_3: 5.09999999999999\n",
      "reward_4: -0.007788259479375626\n",
      "reward_5: 0.6166675589174953\n",
      "reward_6: 0.32846203947067243\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 167\n",
      "episode was finished at timestep: 6\n",
      "reward: -77.87055823096675\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.046471917629241945\n",
      "reward_2: -10\n",
      "reward_3: 3.899999999999994\n",
      "reward_4: 0.02321908099724297\n",
      "reward_5: 0.593369056253127\n",
      "reward_6: 0.30332814717292766\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 168\n",
      "episode was finished at timestep: 27\n",
      "reward: 8.29766679040679\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0038684388001759846\n",
      "reward_2: 0.8271748036424945\n",
      "reward_3: 4.3499999999999925\n",
      "reward_4: -0.03734198826744603\n",
      "reward_5: 0.7256019385607421\n",
      "reward_6: 0.25669076764583565\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 169\n",
      "episode was finished at timestep: 5\n",
      "reward: 9.063368851706057\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0011922246880001492\n",
      "reward_2: 0.9240039548994385\n",
      "reward_3: 4.449999999999992\n",
      "reward_4: -0.025406317182908963\n",
      "reward_5: 0.6186735205580333\n",
      "reward_6: 0.25651312077045385\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 170\n",
      "episode was finished at timestep: 61\n",
      "reward: 6.939676124421194\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.005177221033308241\n",
      "reward_2: 0.6378378707396762\n",
      "reward_3: 4.3499999999999925\n",
      "reward_4: 0.015516143069760489\n",
      "reward_5: 0.42470315650400997\n",
      "reward_6: 0.29273807847499866\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 171\n",
      "episode was finished at timestep: 64\n",
      "reward: 6.893623060999531\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0030351711644066703\n",
      "reward_2: 0.6445253464559864\n",
      "reward_3: 5.449999999999989\n",
      "reward_4: -0.0015990123574977132\n",
      "reward_5: 0.48710549041615553\n",
      "reward_6: 0.26541540229320537\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 172\n",
      "episode was finished at timestep: 55\n",
      "reward: 5.1934623356069824\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0012563268343607585\n",
      "reward_2: 0.6731823746746881\n",
      "reward_3: 4.899999999999991\n",
      "reward_4: 0.0043490236698852415\n",
      "reward_5: 0.4820906553318849\n",
      "reward_6: 0.291723487019539\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 173\n",
      "episode was finished at timestep: 16\n",
      "reward: 6.2439844373378\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.00011644893222384983\n",
      "reward_2: 0.7880382424908554\n",
      "reward_3: 5.09999999999999\n",
      "reward_4: 0.025123041590500748\n",
      "reward_5: 0.3833465210736653\n",
      "reward_6: 0.35478409254550936\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 174\n",
      "episode was finished at timestep: 3\n",
      "reward: 7.672840937416747\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.006538847419950697\n",
      "reward_2: 0.7396249956689906\n",
      "reward_3: 5.1999999999999895\n",
      "reward_4: 0.004587221786939182\n",
      "reward_5: 0.4470171029787439\n",
      "reward_6: 0.27797160887718175\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 175\n",
      "episode was finished at timestep: 74\n",
      "reward: 7.04566486119806\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0023500641187032064\n",
      "reward_2: 0.6588321593018421\n",
      "reward_3: 4.599999999999992\n",
      "reward_4: 0.000763980371806241\n",
      "reward_5: 0.5202960329581571\n",
      "reward_6: 0.2503364416360856\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 176\n",
      "episode was finished at timestep: 90\n",
      "reward: 7.664725517533729\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.006990330749087863\n",
      "reward_2: 0.7513232513507523\n",
      "reward_3: 4.899999999999991\n",
      "reward_4: -0.011703678198614682\n",
      "reward_5: 0.5205408409834512\n",
      "reward_6: 0.23356508874893223\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 177\n",
      "episode was finished at timestep: 60\n",
      "reward: 7.929689792101932\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0006651149855719672\n",
      "reward_2: 0.7672365345754529\n",
      "reward_3: 4.299999999999993\n",
      "reward_4: -0.01922447297916804\n",
      "reward_5: 0.6842052601363805\n",
      "reward_6: 0.26147982084751153\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 178\n",
      "episode was finished at timestep: 70\n",
      "reward: 5.060499913615643\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.005697339773178101\n",
      "reward_2: 0.6424344132361972\n",
      "reward_3: 4.799999999999991\n",
      "reward_4: 0.028352573641286228\n",
      "reward_5: 0.40046618734653855\n",
      "reward_6: 0.2987951710224147\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 179\n",
      "episode was finished at timestep: 81\n",
      "reward: 9.158705323457017\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.003399441639582316\n",
      "reward_2: 0.9233275299207993\n",
      "reward_3: 4.099999999999993\n",
      "reward_4: -0.00653917387748848\n",
      "reward_5: 0.5949054256033892\n",
      "reward_6: 0.23234582448005658\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 180\n",
      "episode was finished at timestep: 47\n",
      "reward: 8.755796920193628\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.008408227894041274\n",
      "reward_2: 0.8841865838025094\n",
      "reward_3: 4.94999999999999\n",
      "reward_4: 0.010728114078731324\n",
      "reward_5: 0.44215126382066455\n",
      "reward_6: 0.1620763012170786\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 181\n",
      "episode was finished at timestep: 66\n",
      "reward: 8.079411268260436\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.00381381180551317\n",
      "reward_2: 0.75587184735007\n",
      "reward_3: 4.549999999999992\n",
      "reward_4: 0.044410778445373895\n",
      "reward_5: 0.43428545600404755\n",
      "reward_6: 0.24607195103168478\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 182\n",
      "episode was finished at timestep: 13\n",
      "reward: 6.936363936453591\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.00274416274494595\n",
      "reward_2: 0.6184706713767423\n",
      "reward_3: 4.599999999999992\n",
      "reward_4: 0.03396843977839268\n",
      "reward_5: 0.47577046335984935\n",
      "reward_6: 0.24321141326427442\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 183\n",
      "episode was finished at timestep: 80\n",
      "reward: 7.737136244877449\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0002646591928270128\n",
      "reward_2: 0.7028232001644185\n",
      "reward_3: 4.399999999999992\n",
      "reward_4: 0.04522418729973083\n",
      "reward_5: 0.48697349530588624\n",
      "reward_6: 0.2654616423845293\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 184\n",
      "episode was finished at timestep: 51\n",
      "reward: 9.253045455541063\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.008895899852116902\n",
      "reward_2: 0.9262296863984656\n",
      "reward_3: 5.09999999999999\n",
      "reward_4: 0.023307878254287148\n",
      "reward_5: 0.4775038319551086\n",
      "reward_6: 0.18745700621604922\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 185\n",
      "episode was finished at timestep: 33\n",
      "reward: 9.93205374491657\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.008361489905251398\n",
      "reward_2: 0.981968032602866\n",
      "reward_3: 5.1999999999999895\n",
      "reward_4: 0.04724175766843061\n",
      "reward_5: 0.44966998944479997\n",
      "reward_6: 0.25637358987331416\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 186\n",
      "episode was finished at timestep: 99\n",
      "reward: 8.01635147057266\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.004005879826015897\n",
      "reward_2: 0.7720241222472085\n",
      "reward_3: 5.14999999999999\n",
      "reward_4: 0.03325924706942985\n",
      "reward_5: 0.44006895363184845\n",
      "reward_6: 0.13733477556705442\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 187\n",
      "episode was finished at timestep: 2\n",
      "reward: -77.97679679448608\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.005990640984641181\n",
      "reward_2: -10\n",
      "reward_3: 4.599999999999992\n",
      "reward_4: 0.04485749818127985\n",
      "reward_5: 0.44652435535838203\n",
      "reward_6: 0.22319617235660605\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 188\n",
      "episode was finished at timestep: 80\n",
      "reward: 7.774312826625206\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.001823319329155816\n",
      "reward_2: 0.725943266647966\n",
      "reward_3: 4.899999999999991\n",
      "reward_4: 0.03454557977602221\n",
      "reward_5: 0.4903850216425596\n",
      "reward_6: 0.20118701958656293\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 189\n",
      "episode was finished at timestep: 90\n",
      "reward: -77.7773391352393\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0012181904580858018\n",
      "reward_2: -10\n",
      "reward_3: 5.1999999999999895\n",
      "reward_4: 0.06253011723313691\n",
      "reward_5: 0.45922637722389664\n",
      "reward_6: 0.2637184067964553\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 190\n",
      "episode was finished at timestep: 62\n",
      "reward: -78.02482529165172\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.00969140198495653\n",
      "reward_2: -10\n",
      "reward_3: 4.799999999999991\n",
      "reward_4: 0.03249340957819911\n",
      "reward_5: 0.5066059013212508\n",
      "reward_6: 0.21767293238639795\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 191\n",
      "episode was finished at timestep: 10\n",
      "reward: -79.70421859936776\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.003570250670115153\n",
      "reward_2: -10\n",
      "reward_3: 5.299999999999989\n",
      "reward_4: 0.06624519818842302\n",
      "reward_5: 0.4100955569022742\n",
      "reward_6: 0.35858784222602846\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 192\n",
      "episode was finished at timestep: 3\n",
      "reward: 8.453633114375359\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.007186915477116903\n",
      "reward_2: 0.8196877517157553\n",
      "reward_3: 4.849999999999991\n",
      "reward_4: 0.01353331856618965\n",
      "reward_5: 0.5542634619858153\n",
      "reward_6: 0.24014133894443468\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 193\n",
      "episode was finished at timestep: 52\n",
      "reward: 5.933247061368887\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.007816569010416666\n",
      "reward_2: 0.785585321137279\n",
      "reward_3: 5.399999999999989\n",
      "reward_4: -0.005167088769563861\n",
      "reward_5: 0.38128121429246314\n",
      "reward_6: 0.3157165571451187\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 194\n",
      "episode was finished at timestep: 18\n",
      "reward: 7.124299323897257\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0002212226390838623\n",
      "reward_2: 0.8902655930833028\n",
      "reward_3: 5.399999999999989\n",
      "reward_4: 0.004912780136558865\n",
      "reward_5: 0.6419005452306493\n",
      "reward_6: 0.32047301554679886\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 195\n",
      "episode was finished at timestep: 51\n",
      "reward: 8.613246408549271\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0052533096737331815\n",
      "reward_2: 0.8211872411209835\n",
      "reward_3: 5.349999999999989\n",
      "reward_4: 0.01154733836182274\n",
      "reward_5: 0.6793346215448073\n",
      "reward_6: 0.2765751274824142\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 196\n",
      "episode was finished at timestep: 23\n",
      "reward: 5.274919502360392\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -2.8100278642442492e-05\n",
      "reward_2: 0.6696619703481332\n",
      "reward_3: 5.299999999999989\n",
      "reward_4: -0.014525239611478896\n",
      "reward_5: 0.7509766594188853\n",
      "reward_6: 0.2821704306602475\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 197\n",
      "episode was finished at timestep: 21\n",
      "reward: 8.224403957889443\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0003331932756635878\n",
      "reward_2: 0.8043623728919528\n",
      "reward_3: 5.749999999999988\n",
      "reward_4: -0.017225374078622194\n",
      "reward_5: 0.6947133700007823\n",
      "reward_6: 0.2321611239910124\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 198\n",
      "episode was finished at timestep: 64\n",
      "reward: 9.060676234859212\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.00014313856760660807\n",
      "reward_2: 0.8912839797560137\n",
      "reward_3: 5.1999999999999895\n",
      "reward_4: 0.006872435677322102\n",
      "reward_5: 0.6027000146977062\n",
      "reward_6: 0.27217470192909243\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 199\n",
      "episode was finished at timestep: 92\n",
      "reward: 9.058093543109278\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.002409180005391439\n",
      "reward_2: 0.9168893717653038\n",
      "reward_3: 5.549999999999988\n",
      "reward_4: -0.007634865935242346\n",
      "reward_5: 0.5563592645030854\n",
      "reward_6: 0.229367411971092\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 200\n",
      "episode was finished at timestep: 51\n",
      "reward: 9.506430558857689\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0005425638622707791\n",
      "reward_2: 0.976581552362837\n",
      "reward_3: 5.649999999999988\n",
      "reward_4: 0.000463656335621323\n",
      "reward_5: 0.48494950361377304\n",
      "reward_6: 0.2049086161851883\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 201\n",
      "episode was finished at timestep: 45\n",
      "reward: 7.523019446180921\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0067035211457146535\n",
      "reward_2: 0.7403057021649058\n",
      "reward_3: 5.349999999999989\n",
      "reward_4: -0.017681824198878645\n",
      "reward_5: 0.5073319448493216\n",
      "reward_6: 0.24068666541576467\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 202\n",
      "episode was finished at timestep: 32\n",
      "reward: 9.152965000262675\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.005926406383514405\n",
      "reward_2: 0.9383850118863271\n",
      "reward_3: 5.599999999999988\n",
      "reward_4: -0.003170518732803771\n",
      "reward_5: 0.4368267115451599\n",
      "reward_6: 0.2396020832061767\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 203\n",
      "episode was finished at timestep: 21\n",
      "reward: 9.298566565790907\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0026875509156121147\n",
      "reward_2: 0.9772725709902541\n",
      "reward_3: 5.04999999999999\n",
      "reward_4: -0.025136885892977575\n",
      "reward_5: 0.46382026449568287\n",
      "reward_6: 0.21967503809928912\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 204\n",
      "episode was finished at timestep: 80\n",
      "reward: 9.34571663178545\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.007226975096596612\n",
      "reward_2: 0.9809370040094147\n",
      "reward_3: 5.849999999999987\n",
      "reward_4: -0.018960429039895244\n",
      "reward_5: 0.46091199185661036\n",
      "reward_6: 0.1954390152692801\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 205\n",
      "episode was finished at timestep: 89\n",
      "reward: 9.368589436178032\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0039337105221218535\n",
      "reward_2: 0.9672591391198544\n",
      "reward_3: 5.399999999999989\n",
      "reward_4: -0.0069844215601311535\n",
      "reward_5: 0.481870931444193\n",
      "reward_6: 0.2077344747781752\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 206\n",
      "episode was finished at timestep: 51\n",
      "reward: 9.443718758140584\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.005042591359880236\n",
      "reward_2: 0.9503320756790916\n",
      "reward_3: 5.549999999999988\n",
      "reward_4: -0.0021672161042009465\n",
      "reward_5: 0.6234950105905476\n",
      "reward_6: 0.23920746231079126\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 207\n",
      "episode was finished at timestep: 101\n",
      "reward: 6.116719404438356\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0003888885180155436\n",
      "reward_2: 0.7783424878129528\n",
      "reward_3: 5.599999999999988\n",
      "reward_4: -0.022977263274624703\n",
      "reward_5: 0.7099611715453505\n",
      "reward_6: 0.3634786584377294\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 208\n",
      "episode was finished at timestep: 128\n",
      "reward: 8.838342782867786\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0015402615070343017\n",
      "reward_2: 0.889619082991946\n",
      "reward_3: 6.849999999999984\n",
      "reward_4: 0.0034832889064499283\n",
      "reward_5: 0.42622387993257377\n",
      "reward_6: 0.26792685592174514\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 209\n",
      "episode was finished at timestep: 93\n",
      "reward: 5.358070146503462\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.005183721250957913\n",
      "reward_2: 0.6896434232084128\n",
      "reward_3: 6.149999999999986\n",
      "reward_4: 0.003924711952588069\n",
      "reward_5: 0.43786937633305134\n",
      "reward_6: 0.3760194101333624\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 210\n",
      "episode was finished at timestep: 44\n",
      "reward: 9.047227161305793\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.005036814345253838\n",
      "reward_2: 0.9449954513729594\n",
      "reward_3: 6.799999999999984\n",
      "reward_4: -0.004135403371168991\n",
      "reward_5: 0.2792408235811256\n",
      "reward_6: 0.24523610138893126\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 211\n",
      "episode was finished at timestep: 127\n",
      "reward: 7.154278769106103\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0009018864896562364\n",
      "reward_2: 0.9428489552626687\n",
      "reward_3: 6.649999999999984\n",
      "reward_4: -0.006756679867062871\n",
      "reward_5: 0.371189091433077\n",
      "reward_6: 0.2943666943311697\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 212\n",
      "episode was finished at timestep: 37\n",
      "reward: 7.506974628106799\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.006841356224483914\n",
      "reward_2: 0.9620422470859342\n",
      "reward_3: 6.449999999999985\n",
      "reward_4: 0.020828909376124756\n",
      "reward_5: 0.3528705964415356\n",
      "reward_6: 0.29711613619327526\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 213\n",
      "episode was finished at timestep: 11\n",
      "reward: 5.371801929456925\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.004353214634789361\n",
      "reward_2: 0.7145690635686874\n",
      "reward_3: 6.449999999999985\n",
      "reward_4: -0.006891746290235688\n",
      "reward_5: 0.36981022595935314\n",
      "reward_6: 0.3440663799047471\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 214\n",
      "episode was finished at timestep: 49\n",
      "reward: 7.717417745271034\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.007578973637686836\n",
      "reward_2: 0.9406166145350092\n",
      "reward_3: 5.849999999999987\n",
      "reward_4: 0.019204438345334012\n",
      "reward_5: 0.6238956568107222\n",
      "reward_6: 0.4217526390552525\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 215\n",
      "episode was finished at timestep: 24\n",
      "reward: 9.015510075819593\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.008235639995998807\n",
      "reward_2: 0.9287146946316763\n",
      "reward_3: 5.299999999999989\n",
      "reward_4: 0.019708232563946097\n",
      "reward_5: 0.21548063449265212\n",
      "reward_6: 0.22017499709129362\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 216\n",
      "episode was finished at timestep: 11\n",
      "reward: 9.505802969005446\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.008037559853659736\n",
      "reward_2: 0.9878385386300963\n",
      "reward_3: 4.599999999999992\n",
      "reward_4: 0.012057824981024937\n",
      "reward_5: 0.24777561861655178\n",
      "reward_6: 0.2662806680202484\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 217\n",
      "episode was finished at timestep: 44\n",
      "reward: 6.4561198942768145\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -3.117587831285265e-05\n",
      "reward_2: 0.8519753313234665\n",
      "reward_3: 4.94999999999999\n",
      "reward_4: 0.00845173047914912\n",
      "reward_5: 0.2469248080969501\n",
      "reward_6: 0.32514976763725256\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 218\n",
      "episode was finished at timestep: 41\n",
      "reward: 7.401084553802746\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.006779157453113132\n",
      "reward_2: 0.9679232447692016\n",
      "reward_3: 4.749999999999991\n",
      "reward_4: 0.0018316838517917233\n",
      "reward_5: 0.3435931510839424\n",
      "reward_6: 0.30559779787063623\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 219\n",
      "episode was finished at timestep: 9\n",
      "reward: 8.303590516303991\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.004230257537629869\n",
      "reward_2: 0.8260834020282743\n",
      "reward_3: 5.14999999999999\n",
      "reward_4: 0.02158262604722779\n",
      "reward_5: 0.24781058561582928\n",
      "reward_6: 0.2779952969551085\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 220\n",
      "episode was finished at timestep: 63\n",
      "reward: 6.717001512476632\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0028804686334398056\n",
      "reward_2: 0.6343535402850016\n",
      "reward_3: 6.0499999999999865\n",
      "reward_4: -0.005390892314691058\n",
      "reward_5: 0.4567813550976531\n",
      "reward_6: 0.2305927755832673\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 221\n",
      "episode was finished at timestep: 31\n",
      "reward: 6.666753943323459\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.002433654997083876\n",
      "reward_2: 0.8513315786619945\n",
      "reward_3: 7.349999999999982\n",
      "reward_4: 0.00979896829704444\n",
      "reward_5: 0.4174260647073672\n",
      "reward_6: 0.36173715794086436\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 222\n",
      "episode was finished at timestep: 47\n",
      "reward: 7.862334250121829\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.00048434270752800837\n",
      "reward_2: 0.9843231695626697\n",
      "reward_3: 7.149999999999983\n",
      "reward_4: 0.007135529202104891\n",
      "reward_5: 0.5499066968808397\n",
      "reward_6: 0.3802889724969869\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 223\n",
      "episode was finished at timestep: 82\n",
      "reward: 8.846542803516051\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0067165003882514104\n",
      "reward_2: 0.9452625008190807\n",
      "reward_3: 7.499999999999981\n",
      "reward_4: -0.011732218487798178\n",
      "reward_5: 0.15720411014013524\n",
      "reward_6: 0.22681293511390666\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 224\n",
      "episode was finished at timestep: 45\n",
      "reward: 9.023748381557066\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.006836163997650147\n",
      "reward_2: 0.9429878911818973\n",
      "reward_3: 6.649999999999984\n",
      "reward_4: 0.0010860472128482001\n",
      "reward_5: 0.26083289501023\n",
      "reward_6: 0.21627347671985608\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 225\n",
      "episode was finished at timestep: 42\n",
      "reward: 8.570028399640819\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0027629408571455214\n",
      "reward_2: 0.8850006964893506\n",
      "reward_3: 7.649999999999981\n",
      "reward_4: 0.008663608327869951\n",
      "reward_5: 0.20887901788217428\n",
      "reward_6: 0.21357788407802625\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 226\n",
      "episode was finished at timestep: 48\n",
      "reward: 7.576723427265172\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0005110164483388264\n",
      "reward_2: 0.7820595239502742\n",
      "reward_3: 7.649999999999981\n",
      "reward_4: -0.00020063096396924607\n",
      "reward_5: 0.10473469300773305\n",
      "reward_6: 0.216608606815338\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 227\n",
      "episode was finished at timestep: 99\n",
      "reward: 8.310590454120419\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0015599158075120714\n",
      "reward_2: 0.8828711436102992\n",
      "reward_3: 7.349999999999982\n",
      "reward_4: 0.004516864545025925\n",
      "reward_5: 0.05068418598339453\n",
      "reward_6: 0.16138211870193486\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 228\n",
      "episode was finished at timestep: 143\n",
      "reward: 8.751860066632148\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.006586488750245836\n",
      "reward_2: 0.9271372216999454\n",
      "reward_3: 7.649999999999981\n",
      "reward_4: -0.010239832773361428\n",
      "reward_5: 0.20762027078437187\n",
      "reward_6: 0.21462717318534896\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 229\n",
      "episode was finished at timestep: 87\n",
      "reward: 7.3495364432812025\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.00013945831192864312\n",
      "reward_2: 0.9110477822515783\n",
      "reward_3: 6.299999999999986\n",
      "reward_4: 0.01586900750373772\n",
      "reward_5: 0.5286330204946095\n",
      "reward_6: 0.40486856305599217\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 230\n",
      "episode was finished at timestep: 80\n",
      "reward: 8.008142757931179\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.003128867679172092\n",
      "reward_2: 0.9723842707139919\n",
      "reward_3: 6.099999999999986\n",
      "reward_4: 0.011850161365784118\n",
      "reward_5: 0.674440155113029\n",
      "reward_6: 0.46214268052577967\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 231\n",
      "episode was finished at timestep: 139\n",
      "reward: 7.32158333718524\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0041522370444403755\n",
      "reward_2: 0.7621773657662663\n",
      "reward_3: 8.04999999999998\n",
      "reward_4: 0.004152776125027913\n",
      "reward_5: -0.004388726327457822\n",
      "reward_6: 0.19010535800457007\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 232\n",
      "episode was finished at timestep: 41\n",
      "reward: 7.582167697263807\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.010051843192842271\n",
      "reward_2: 0.9609149537803884\n",
      "reward_3: 6.5999999999999845\n",
      "reward_4: 0.036624063356523774\n",
      "reward_5: 0.19389698529914176\n",
      "reward_6: 0.4171304180622105\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 233\n",
      "episode was finished at timestep: 18\n",
      "reward: 6.89364979733425\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.004118618037965562\n",
      "reward_2: 0.7022344936504034\n",
      "reward_3: 6.699999999999984\n",
      "reward_4: 0.006466853818571678\n",
      "reward_5: -0.004334191937996697\n",
      "reward_6: 0.22336125814914698\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 234\n",
      "episode was finished at timestep: 23\n",
      "reward: 7.099547884173269\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.005869593885209825\n",
      "reward_2: 0.7383116888589767\n",
      "reward_3: 7.099999999999983\n",
      "reward_4: -0.0003805579249215896\n",
      "reward_5: 0.032348319290656964\n",
      "reward_6: 0.16867344462871514\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 235\n",
      "episode was finished at timestep: 54\n",
      "reward: 6.458960195718911\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0022510237163967557\n",
      "reward_2: 0.6654954383996902\n",
      "reward_3: 7.549999999999981\n",
      "reward_4: -0.031684272643629614\n",
      "reward_5: 0.16023606974917837\n",
      "reward_6: 0.22947915697097832\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 236\n",
      "episode was finished at timestep: 126\n",
      "reward: 9.06024063458727\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.003600033124287923\n",
      "reward_2: 0.9299518480307913\n",
      "reward_3: 6.749999999999984\n",
      "reward_4: 0.018048994023835547\n",
      "reward_5: 0.21493078414929875\n",
      "reward_6: 0.26400314712524453\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 237\n",
      "episode was finished at timestep: 101\n",
      "reward: 7.643937786575341\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.006619225607977973\n",
      "reward_2: 0.7983793624567732\n",
      "reward_3: 6.699999999999984\n",
      "reward_4: -0.0025702746835568747\n",
      "reward_5: 0.08940608803910971\n",
      "reward_6: 0.1937848886251452\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 238\n",
      "episode was finished at timestep: 16\n",
      "reward: 7.912606958928223\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.005992721186743842\n",
      "reward_2: 0.8327954277465688\n",
      "reward_3: 6.8999999999999835\n",
      "reward_4: -0.0005088919615994314\n",
      "reward_5: 0.06876649618449378\n",
      "reward_6: 0.19062089765071843\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 239\n",
      "episode was finished at timestep: 139\n",
      "reward: 7.8533971283351445\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.008404188685946994\n",
      "reward_2: 0.831368512800761\n",
      "reward_3: 7.299999999999982\n",
      "reward_4: -0.004013931727042888\n",
      "reward_5: 0.0166107627789831\n",
      "reward_6: 0.22538057231903108\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 240\n",
      "episode was finished at timestep: 30\n",
      "reward: 8.164246911473008\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.00294595824347602\n",
      "reward_2: 0.8666636846480025\n",
      "reward_3: 7.099999999999983\n",
      "reward_4: 0.001144531107329101\n",
      "reward_5: 0.048563220818771666\n",
      "reward_6: 0.17521725618839268\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 241\n",
      "episode was finished at timestep: 112\n",
      "reward: 7.643276000048092\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.00036150548193189834\n",
      "reward_2: 0.9432607588994371\n",
      "reward_3: 6.749999999999984\n",
      "reward_4: 0.04687067792564932\n",
      "reward_5: 0.37696773442863113\n",
      "reward_6: 0.34471827650070197\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 242\n",
      "episode was finished at timestep: 143\n",
      "reward: 8.065965769828676\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.005519318580627442\n",
      "reward_2: 0.8503986235516525\n",
      "reward_3: 7.399999999999982\n",
      "reward_4: -0.0005823897087425678\n",
      "reward_5: 0.06010768123407608\n",
      "reward_6: 0.21186086976528196\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 243\n",
      "episode was finished at timestep: 77\n",
      "reward: 9.026396368950454\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.007084127267201742\n",
      "reward_2: 0.9714243693722867\n",
      "reward_3: 6.799999999999984\n",
      "reward_4: 9.274991589393267e-05\n",
      "reward_5: 0.09245581187961041\n",
      "reward_6: 0.16798106336593532\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 244\n",
      "episode was finished at timestep: 77\n",
      "reward: 8.21367486716911\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.003030746512942844\n",
      "reward_2: 0.8723419728004274\n",
      "reward_3: 7.599999999999981\n",
      "reward_4: -0.0037523888006943196\n",
      "reward_5: 0.0708325531502793\n",
      "reward_6: 0.1961430552005765\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 245\n",
      "episode was finished at timestep: 95\n",
      "reward: 9.218675925069222\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.009492723809348212\n",
      "reward_2: 0.9964151936850196\n",
      "reward_3: 6.949999999999983\n",
      "reward_4: 0.0024311351768540133\n",
      "reward_5: 0.07196708350513852\n",
      "reward_6: 0.16450426781177585\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 246\n",
      "episode was finished at timestep: 42\n",
      "reward: 9.03833150310251\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.008182193173302545\n",
      "reward_2: 0.9595755216510817\n",
      "reward_3: 7.249999999999982\n",
      "reward_4: 0.007725739838821255\n",
      "reward_5: 0.07363246448054153\n",
      "reward_6: 0.23350447320938084\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 247\n",
      "episode was finished at timestep: 107\n",
      "reward: 7.463864334846795\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.01659476492140028\n",
      "reward_2: 0.7747040853083209\n",
      "reward_3: 6.8999999999999835\n",
      "reward_4: 0.01608773341013773\n",
      "reward_5: -0.011562965347406617\n",
      "reward_6: 0.13157798552513145\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 248\n",
      "episode was finished at timestep: 46\n",
      "reward: 7.631815359661506\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.011041612095303006\n",
      "reward_2: 0.8882416275060347\n",
      "reward_3: 5.599999999999988\n",
      "reward_4: 0.06199539352512659\n",
      "reward_5: 0.555555538894686\n",
      "reward_6: 0.48465859794616717\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 249\n",
      "episode was finished at timestep: 104\n",
      "reward: 8.081415484486769\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.010271414783265856\n",
      "reward_2: 0.9747732704537906\n",
      "reward_3: 6.699999999999984\n",
      "reward_4: 0.051965726119564834\n",
      "reward_5: 0.40854421639768845\n",
      "reward_6: 0.46833737695217126\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 250\n",
      "episode was finished at timestep: 15\n",
      "reward: 8.6960736746231\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.02202246387799581\n",
      "reward_2: 0.9221519236311202\n",
      "reward_3: 6.249999999999986\n",
      "reward_4: 0.020426670549830418\n",
      "reward_5: -0.011755183458471189\n",
      "reward_6: 0.14434430742263793\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 251\n",
      "episode was finished at timestep: 64\n",
      "reward: 8.926386839093382\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0076089044411977134\n",
      "reward_2: 0.9612587163475717\n",
      "reward_3: 5.399999999999989\n",
      "reward_4: 0.007499122391362221\n",
      "reward_5: 0.07282412261427425\n",
      "reward_6: 0.11038891100883519\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 252\n",
      "episode was finished at timestep: 9\n",
      "reward: 8.62500663479482\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0031560546822018095\n",
      "reward_2: 0.9237605094910359\n",
      "reward_3: 5.749999999999988\n",
      "reward_4: -0.0004930925545723142\n",
      "reward_5: 0.06328861836131712\n",
      "reward_6: 0.1779680689573292\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 253\n",
      "episode was finished at timestep: 101\n",
      "reward: 8.061906619423853\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0014452166027492947\n",
      "reward_2: 0.8560064474574401\n",
      "reward_3: 6.549999999999985\n",
      "reward_4: -0.0010862495019465256\n",
      "reward_5: 0.023286254414615945\n",
      "reward_6: 0.19983066463470434\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 254\n",
      "episode was finished at timestep: 7\n",
      "reward: 8.36795881010076\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04899175233311123\n",
      "reward_2: 0.8583067557416182\n",
      "reward_3: 7.299999999999982\n",
      "reward_4: 0.0252168879532924\n",
      "reward_5: -0.005171634765471348\n",
      "reward_6: 0.2549762096405027\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 255\n",
      "episode was finished at timestep: 8\n",
      "reward: 7.536201102941876\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04399315383699205\n",
      "reward_2: 0.7448305100393258\n",
      "reward_3: 7.94999999999998\n",
      "reward_4: 0.03422047526463118\n",
      "reward_5: -0.012007031295828934\n",
      "reward_6: 0.2707470979690557\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 256\n",
      "episode was finished at timestep: 82\n",
      "reward: 8.917765245691339\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04905009667078654\n",
      "reward_2: 0.927305632552242\n",
      "reward_3: 6.8999999999999835\n",
      "reward_4: 0.02528068612504484\n",
      "reward_5: -0.01227685581919135\n",
      "reward_6: 0.2593814554214481\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 257\n",
      "episode was finished at timestep: 46\n",
      "reward: 9.229146718451455\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04779024587737189\n",
      "reward_2: 0.9757904141596228\n",
      "reward_3: 7.299999999999982\n",
      "reward_4: 0.016357456822467923\n",
      "reward_5: -0.005905907002283091\n",
      "reward_6: 0.24910607838630683\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 258\n",
      "episode was finished at timestep: 142\n",
      "reward: 8.77750573049952\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.01649489336543613\n",
      "reward_2: 0.9266948928588249\n",
      "reward_3: 7.4499999999999815\n",
      "reward_4: 0.015440700949369415\n",
      "reward_5: -0.010932082999986884\n",
      "reward_6: 0.23386483633518207\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 259\n",
      "episode was finished at timestep: 49\n",
      "reward: 8.622646601908672\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0519199788570404\n",
      "reward_2: 0.8872046727668568\n",
      "reward_3: 8.549999999999986\n",
      "reward_4: 0.036337474862203296\n",
      "reward_5: -0.00687724801094672\n",
      "reward_6: 0.18812669003009874\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 260\n",
      "episode was finished at timestep: 54\n",
      "reward: 6.58097017980667\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.13245138393508063\n",
      "reward_2: 0.8593159846127356\n",
      "reward_3: 6.8999999999999835\n",
      "reward_4: 0.032248577752109354\n",
      "reward_5: -0.009163481011761712\n",
      "reward_6: 0.32424577796459186\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 261\n",
      "episode was finished at timestep: 126\n",
      "reward: 7.221746828048624\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.029656716187795005\n",
      "reward_2: 0.717593407735597\n",
      "reward_3: 8.349999999999984\n",
      "reward_4: 0.03024489329359298\n",
      "reward_5: -0.013357373784660235\n",
      "reward_6: 0.22162774407863606\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 262\n",
      "episode was finished at timestep: 20\n",
      "reward: 5.59143130817212\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.012438267469406128\n",
      "reward_2: 0.7815536381914241\n",
      "reward_3: 8.249999999999982\n",
      "reward_4: 0.005069321774899862\n",
      "reward_5: -0.00883920994691465\n",
      "reward_6: 0.29374857091903717\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 263\n",
      "episode was finished at timestep: 79\n",
      "reward: 6.957433638472048\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.03430687785148621\n",
      "reward_2: 0.6867590683885529\n",
      "reward_3: 7.4499999999999815\n",
      "reward_4: 0.029065179606654824\n",
      "reward_5: -0.01743645410580754\n",
      "reward_6: 0.21297589743137335\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 264\n",
      "episode was finished at timestep: 64\n",
      "reward: 6.029751246958494\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.006244664722018772\n",
      "reward_2: 0.7136990656946921\n",
      "reward_3: 6.849999999999984\n",
      "reward_4: 0.03501831513565435\n",
      "reward_5: 0.5894468737606818\n",
      "reward_6: 0.4558966579437257\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 265\n",
      "episode was finished at timestep: 144\n",
      "reward: 9.250622208777063\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.05422972308264838\n",
      "reward_2: 0.9679008096663463\n",
      "reward_3: 9.049999999999994\n",
      "reward_4: 0.02977385752264908\n",
      "reward_5: -0.008852413374046719\n",
      "reward_6: 0.22264089488983085\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 266\n",
      "episode was finished at timestep: 73\n",
      "reward: 7.0424781334688085\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.015382872687445747\n",
      "reward_2: 0.7092422993891075\n",
      "reward_3: 8.79999999999999\n",
      "reward_4: 0.01245253731303265\n",
      "reward_5: -0.0029080360865799313\n",
      "reward_6: 0.25527126991748783\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 267\n",
      "episode was finished at timestep: 68\n",
      "reward: 7.279540276862958\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0069874333010779485\n",
      "reward_2: 0.8479130453180181\n",
      "reward_3: 5.549999999999988\n",
      "reward_4: 0.06002596321159956\n",
      "reward_5: 0.5886854858487556\n",
      "reward_6: 0.4335901560783386\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 268\n",
      "episode was finished at timestep: 67\n",
      "reward: 4.541535281531335\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07618603242768182\n",
      "reward_2: 0.6391016889431713\n",
      "reward_3: 8.74999999999999\n",
      "reward_4: 0.007671084096637771\n",
      "reward_5: -0.012765651624184098\n",
      "reward_6: 0.30276604974269783\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 269\n",
      "episode was finished at timestep: 71\n",
      "reward: 7.481351003917309\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0019897970888349747\n",
      "reward_2: 0.9354297783133955\n",
      "reward_3: 8.699999999999989\n",
      "reward_4: 0.007634817026173551\n",
      "reward_5: 0.43568132828573974\n",
      "reward_6: 0.5019827100038525\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 270\n",
      "episode was finished at timestep: 16\n",
      "reward: 8.534584866851269\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0740527696079678\n",
      "reward_2: 0.8873018537226349\n",
      "reward_3: 9.45\n",
      "reward_4: 0.013395866438097101\n",
      "reward_5: -0.00513635340508157\n",
      "reward_6: 0.2588266893625262\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 271\n",
      "episode was finished at timestep: 9\n",
      "reward: 8.17585193275322\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.05447303321626451\n",
      "reward_2: 0.8287172502145512\n",
      "reward_3: 9.750000000000004\n",
      "reward_4: 0.024471472144930572\n",
      "reward_5: -0.001092922075907173\n",
      "reward_6: 0.2956620427370076\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 272\n",
      "episode was finished at timestep: 65\n",
      "reward: 6.913407256919447\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0026551889048682317\n",
      "reward_2: 0.7738007275303972\n",
      "reward_3: 4.099999999999993\n",
      "reward_4: 0.09674525714298313\n",
      "reward_5: 0.6068528021545556\n",
      "reward_6: 0.3442950996160504\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 273\n",
      "episode was finished at timestep: 83\n",
      "reward: 7.2970547773564975\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08664125535223219\n",
      "reward_2: 0.9819707978018173\n",
      "reward_3: 7.599999999999981\n",
      "reward_4: 0.00831434869211094\n",
      "reward_5: -0.012725774812055946\n",
      "reward_6: 0.29984479153156296\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 274\n",
      "episode was finished at timestep: 0\n",
      "reward: 8.006594012407035\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09206233620643615\n",
      "reward_2: 0.8254788021528963\n",
      "reward_3: 7.649999999999981\n",
      "reward_4: 0.004200439313675872\n",
      "reward_5: -0.009440816179943804\n",
      "reward_6: 0.2855185606479649\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 275\n",
      "episode was finished at timestep: 40\n",
      "reward: 7.143564912875948\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.059254876772562665\n",
      "reward_2: 0.9683618140010537\n",
      "reward_3: 7.199999999999982\n",
      "reward_4: 0.006682332866552798\n",
      "reward_5: -0.010035325107226\n",
      "reward_6: 0.29303218626975935\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 276\n",
      "episode was finished at timestep: 77\n",
      "reward: -78.66557396711008\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.022687277528974745\n",
      "reward_2: -10\n",
      "reward_3: 4.899999999999991\n",
      "reward_4: 0.03930817679894744\n",
      "reward_5: -0.0058118960838671775\n",
      "reward_6: 0.0024319037199025395\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 277\n",
      "episode was finished at timestep: 109\n",
      "reward: 6.447128127741733\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.009009353319803874\n",
      "reward_2: 0.8916350978049078\n",
      "reward_3: 7.699999999999981\n",
      "reward_4: -0.0057701936652846085\n",
      "reward_5: -0.01040921025590317\n",
      "reward_6: 0.36058208489418075\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 278\n",
      "episode was finished at timestep: 137\n",
      "reward: 4.233918056125697\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.01655668020248413\n",
      "reward_2: 0.6109764298885538\n",
      "reward_3: 6.949999999999983\n",
      "reward_4: 0.0034862233607263703\n",
      "reward_5: -0.002779170684571734\n",
      "reward_6: 0.30351265394687676\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 279\n",
      "episode was finished at timestep: 143\n",
      "reward: 7.137621254591688\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10396731032265558\n",
      "reward_2: 0.9492584798580281\n",
      "reward_3: 7.249999999999982\n",
      "reward_4: 0.015336948205828805\n",
      "reward_5: -0.010459932156292004\n",
      "reward_6: 0.32638378524780287\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 280\n",
      "episode was finished at timestep: 43\n",
      "reward: 7.754592143542321\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04948758946524726\n",
      "reward_2: 0.7925723079724388\n",
      "reward_3: 7.4499999999999815\n",
      "reward_4: 0.020163292418072274\n",
      "reward_5: -0.0007245608978806217\n",
      "reward_6: 0.2029509785175324\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 281\n",
      "episode was finished at timestep: 16\n",
      "reward: 9.295078765056099\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10774502754211426\n",
      "reward_2: 0.9675464943944228\n",
      "reward_3: 7.4499999999999815\n",
      "reward_4: 0.02338754631331753\n",
      "reward_5: -0.0017422279826603197\n",
      "reward_6: 0.2606103065013886\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 282\n",
      "episode was finished at timestep: 68\n",
      "reward: 9.192520271504646\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.12421744134691026\n",
      "reward_2: 0.954662211230076\n",
      "reward_3: 8.549999999999986\n",
      "reward_4: 0.028532235722720997\n",
      "reward_5: -0.0037324409182829753\n",
      "reward_6: 0.20533969545364328\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 283\n",
      "episode was finished at timestep: 36\n",
      "reward: -78.13916138397182\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.025008085701200698\n",
      "reward_2: -10\n",
      "reward_3: 6.499999999999985\n",
      "reward_4: 0.005170654659740137\n",
      "reward_5: 0.47550837267164897\n",
      "reward_6: 0.31809025371074595\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 284\n",
      "episode was finished at timestep: 22\n",
      "reward: 7.462977882755327\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.1209883001115587\n",
      "reward_2: 0.7350268297295223\n",
      "reward_3: 9.049999999999994\n",
      "reward_4: 0.030516641754924193\n",
      "reward_5: -0.006214208687395128\n",
      "reward_6: 0.22264935278892606\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 285\n",
      "episode was finished at timestep: 63\n",
      "reward: 9.032952003750886\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10013033019171821\n",
      "reward_2: 0.9278202637249823\n",
      "reward_3: 8.249999999999982\n",
      "reward_4: 0.034667518794201865\n",
      "reward_5: -0.009464640158377691\n",
      "reward_6: 0.24128405356407145\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 286\n",
      "episode was finished at timestep: 104\n",
      "reward: 7.29982633716924\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0015684154298570422\n",
      "reward_2: 0.9849610931951689\n",
      "reward_3: 10.000000000000007\n",
      "reward_4: -0.030990708654526175\n",
      "reward_5: 0.16568302023153691\n",
      "reward_6: 0.5026153227090846\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 287\n",
      "episode was finished at timestep: 104\n",
      "reward: 8.87298374695606\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.12167947755919563\n",
      "reward_2: 0.9104972996489963\n",
      "reward_3: 8.74999999999999\n",
      "reward_4: 0.029196664198985332\n",
      "reward_5: -9.227432391215966e-05\n",
      "reward_6: 0.23267816627025617\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 288\n",
      "episode was finished at timestep: 110\n",
      "reward: 8.954060684272273\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08581081297662523\n",
      "reward_2: 0.9391381280719397\n",
      "reward_3: 6.499999999999985\n",
      "reward_4: 0.019610638124861027\n",
      "reward_5: -0.0160130773130169\n",
      "reward_6: 0.21340615236759153\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 289\n",
      "episode was finished at timestep: 82\n",
      "reward: 8.207134338942254\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07259139948421055\n",
      "reward_2: 0.845870317881017\n",
      "reward_3: 6.849999999999984\n",
      "reward_4: 0.017474650195260608\n",
      "reward_5: -0.012221389024336797\n",
      "reward_6: 0.23909125053882596\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 290\n",
      "episode was finished at timestep: 89\n",
      "reward: 8.803426583603017\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07743147280481126\n",
      "reward_2: 0.9143092406656997\n",
      "reward_3: 7.84999999999998\n",
      "reward_4: 0.030422577317214206\n",
      "reward_5: -0.012706213409750452\n",
      "reward_6: 0.17980011367797866\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 291\n",
      "episode was finished at timestep: 136\n",
      "reward: 8.39581437825446\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07330997387568156\n",
      "reward_2: 0.8637928211804052\n",
      "reward_3: 7.049999999999983\n",
      "reward_4: 0.030354456616639852\n",
      "reward_5: -0.00010833603919238043\n",
      "reward_6: 0.16849451804161053\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 292\n",
      "episode was finished at timestep: 11\n",
      "reward: 8.403701853008688\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.11148321893480088\n",
      "reward_2: 0.8655849773616364\n",
      "reward_3: 6.999999999999983\n",
      "reward_4: 0.018098049884770262\n",
      "reward_5: -0.012156173886393281\n",
      "reward_6: 0.23397725665569302\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 293\n",
      "episode was finished at timestep: 99\n",
      "reward: 8.676061626028455\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10554172396659851\n",
      "reward_2: 0.9025243023687158\n",
      "reward_3: 7.599999999999981\n",
      "reward_4: 0.013953852937752061\n",
      "reward_5: -0.012527701490402283\n",
      "reward_6: 0.2502090277671819\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 294\n",
      "episode was finished at timestep: 158\n",
      "reward: 9.093574314008363\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09247849252488878\n",
      "reward_2: 0.9455858044069163\n",
      "reward_3: 8.349999999999984\n",
      "reward_4: 0.03225879502870455\n",
      "reward_5: -0.006984596097872971\n",
      "reward_6: 0.18421028876304646\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 295\n",
      "episode was finished at timestep: 18\n",
      "reward: 8.707817649425673\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09732856353123982\n",
      "reward_2: 0.8895574622236679\n",
      "reward_3: 7.99999999999998\n",
      "reward_4: 0.035817565606374016\n",
      "reward_5: -0.008172034898890483\n",
      "reward_6: 0.21459423148632062\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 296\n",
      "episode was finished at timestep: 116\n",
      "reward: 9.158216779064963\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07011048661337958\n",
      "reward_2: 0.9631649065578826\n",
      "reward_3: 8.499999999999986\n",
      "reward_4: 0.025436418639863092\n",
      "reward_5: -0.010726534637481558\n",
      "reward_6: 0.18888889217376736\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 297\n",
      "episode was finished at timestep: 31\n",
      "reward: 8.918972100487894\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08775362504853143\n",
      "reward_2: 0.9293414246099088\n",
      "reward_3: 8.04999999999998\n",
      "reward_4: 0.026238780291345024\n",
      "reward_5: -0.0020752368663079796\n",
      "reward_6: 0.18757873976230688\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 298\n",
      "episode was finished at timestep: 121\n",
      "reward: 9.089785586680184\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07837117777930366\n",
      "reward_2: 0.9409425593213825\n",
      "reward_3: 7.99999999999998\n",
      "reward_4: 0.03703412963977911\n",
      "reward_5: -0.01715441922867645\n",
      "reward_6: 0.20368864977359769\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 299\n",
      "episode was finished at timestep: 17\n",
      "reward: 9.33809897888821\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.054784091975953846\n",
      "reward_2: 0.9815156593562442\n",
      "reward_3: 8.299999999999983\n",
      "reward_4: 0.0285723709398124\n",
      "reward_5: -0.007730864423279845\n",
      "reward_6: 0.2092348423004159\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 300\n",
      "episode was finished at timestep: 99\n",
      "reward: 8.431946172144892\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.010680143038431804\n",
      "reward_2: 0.9019172900599208\n",
      "reward_3: 7.649999999999981\n",
      "reward_4: 0.004244726527285252\n",
      "reward_5: -0.017687969015345927\n",
      "reward_6: 0.18863786542415673\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 301\n",
      "episode was finished at timestep: 56\n",
      "reward: 5.988038703812569\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10038966470294529\n",
      "reward_2: 0.7982464235621385\n",
      "reward_3: 7.149999999999983\n",
      "reward_4: 0.02192956640971019\n",
      "reward_5: -0.012404216890994017\n",
      "reward_6: 0.33769200289249435\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 302\n",
      "episode was finished at timestep: 103\n",
      "reward: 5.51839591642182\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09812149869071113\n",
      "reward_2: 0.7399309408427795\n",
      "reward_3: 7.249999999999982\n",
      "reward_4: 0.02793262481253649\n",
      "reward_5: -0.012188108572540794\n",
      "reward_6: 0.2885873343944553\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 303\n",
      "episode was finished at timestep: 11\n",
      "reward: 5.856079817811061\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0035700089401668974\n",
      "reward_2: 0.7170408840401961\n",
      "reward_3: 6.999999999999983\n",
      "reward_4: 0.009800962875696796\n",
      "reward_5: 0.6816634559905327\n",
      "reward_6: 0.36231826210021945\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 304\n",
      "episode was finished at timestep: 4\n",
      "reward: 8.978728670617972\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06397163073221843\n",
      "reward_2: 0.9296754551679467\n",
      "reward_3: 7.84999999999998\n",
      "reward_4: 0.029485832040035406\n",
      "reward_5: -0.015317098240468851\n",
      "reward_6: 0.2557371737956997\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 305\n",
      "episode was finished at timestep: 74\n",
      "reward: 7.223089145121214\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10151113867759705\n",
      "reward_2: 0.9569734736882424\n",
      "reward_3: 8.449999999999985\n",
      "reward_4: 0.01689570084774999\n",
      "reward_5: -0.007863806160036072\n",
      "reward_6: 0.3373617496490475\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 306\n",
      "episode was finished at timestep: 29\n",
      "reward: 5.9701029045430465\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0034847226407792834\n",
      "reward_2: 0.7481246282077386\n",
      "reward_3: 9.800000000000004\n",
      "reward_4: 0.038116596757994045\n",
      "reward_5: 0.30352902820386457\n",
      "reward_6: 0.3788221325874328\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 307\n",
      "episode was finished at timestep: 122\n",
      "reward: 5.354564328151169\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0027855674425760904\n",
      "reward_2: 0.7894960582580717\n",
      "reward_3: 10.650000000000016\n",
      "reward_4: -0.03322657407937982\n",
      "reward_5: -0.005819435137247808\n",
      "reward_6: 0.306022322416306\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 308\n",
      "episode was finished at timestep: 52\n",
      "reward: 7.219348761964163\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04875444836086697\n",
      "reward_2: 0.7110520047716923\n",
      "reward_3: 7.99999999999998\n",
      "reward_4: 0.028818156018746634\n",
      "reward_5: -0.0038040989434622455\n",
      "reward_6: 0.25437045955657966\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 309\n",
      "episode was finished at timestep: 4\n",
      "reward: 7.593219554923411\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.001371006833182441\n",
      "reward_2: 0.810221043640718\n",
      "reward_3: 9.099999999999994\n",
      "reward_4: -0.012921509594281132\n",
      "reward_5: -0.003487069844518705\n",
      "reward_6: 0.21572601222991938\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 310\n",
      "episode was finished at timestep: 81\n",
      "reward: 8.470059794213372\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.034456560346815324\n",
      "reward_2: 0.8924042432460997\n",
      "reward_3: 7.7499999999999805\n",
      "reward_4: 0.0070369097506466005\n",
      "reward_5: -0.0017552888738684657\n",
      "reward_6: 0.24079596543312043\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 311\n",
      "episode was finished at timestep: 98\n",
      "reward: 7.3639782171304144\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.047536846664216786\n",
      "reward_2: 0.7542578110921381\n",
      "reward_3: 7.94999999999998\n",
      "reward_4: 0.008444162873463341\n",
      "reward_5: -0.014468360906289253\n",
      "reward_6: 0.22823393964767458\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 312\n",
      "episode was finished at timestep: 22\n",
      "reward: 8.142365173090592\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.11003472540113661\n",
      "reward_2: 0.8382309311450994\n",
      "reward_3: 8.249999999999982\n",
      "reward_4: 0.017244583437279176\n",
      "reward_5: -0.007122501386107179\n",
      "reward_6: 0.1945488324165343\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 313\n",
      "episode was finished at timestep: 16\n",
      "reward: 7.501236679083951\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04935612943437365\n",
      "reward_2: 0.7544588139782732\n",
      "reward_3: 7.299999999999982\n",
      "reward_4: 0.020183148513894907\n",
      "reward_5: -0.013287031594733278\n",
      "reward_6: 0.2670585479736328\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 314\n",
      "episode was finished at timestep: 91\n",
      "reward: 7.677428032923886\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10133145915137397\n",
      "reward_2: 0.7872153626448204\n",
      "reward_3: 8.449999999999985\n",
      "reward_4: 0.008522172510204058\n",
      "reward_5: -0.00985436927156608\n",
      "reward_6: 0.2189239951372155\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 315\n",
      "episode was finished at timestep: 18\n",
      "reward: 7.919866657995257\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08901956015162998\n",
      "reward_2: 0.8014770576040785\n",
      "reward_3: 7.4499999999999815\n",
      "reward_4: 0.019176348241834375\n",
      "reward_5: -0.0004108182488678835\n",
      "reward_6: 0.26503733599185864\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 316\n",
      "episode was finished at timestep: 142\n",
      "reward: 6.52957556894626\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.007710663477579752\n",
      "reward_2: 0.6341601931266849\n",
      "reward_3: 8.04999999999998\n",
      "reward_4: 0.039932203356416236\n",
      "reward_5: -0.009146803935929763\n",
      "reward_6: 0.13719920420646714\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 317\n",
      "episode was finished at timestep: 153\n",
      "reward: 7.24821138902473\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.05445190005832248\n",
      "reward_2: 0.7641679342990472\n",
      "reward_3: 10.350000000000012\n",
      "reward_4: -0.016275544606031644\n",
      "reward_5: -0.003514329596051032\n",
      "reward_6: 0.2127547010183346\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 318\n",
      "episode was finished at timestep: 1\n",
      "reward: 8.12964800824909\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10164569550090366\n",
      "reward_2: 0.8386253887307952\n",
      "reward_3: 8.09999999999998\n",
      "reward_4: 0.010553039930173752\n",
      "reward_5: -0.004510018187133606\n",
      "reward_6: 0.23800490164756816\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 319\n",
      "episode was finished at timestep: 117\n",
      "reward: 8.347816735888646\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07096968160735237\n",
      "reward_2: 0.8774005220184368\n",
      "reward_3: 7.89999999999998\n",
      "reward_4: 0.013452071992771408\n",
      "reward_5: -0.008265942770428343\n",
      "reward_6: 0.15723891162872272\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 320\n",
      "episode was finished at timestep: 160\n",
      "reward: 8.324657716950618\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.11861468089951409\n",
      "reward_2: 0.8587251399158948\n",
      "reward_3: 9.650000000000002\n",
      "reward_4: 0.023677228019478632\n",
      "reward_5: -0.0015159889201758147\n",
      "reward_6: 0.14705341482162515\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 321\n",
      "episode was finished at timestep: 49\n",
      "reward: 8.09587273006737\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.12701076600286695\n",
      "reward_2: 0.8364915200697428\n",
      "reward_3: 8.79999999999999\n",
      "reward_4: 0.016765009530091534\n",
      "reward_5: -0.013310725065079628\n",
      "reward_6: 0.15494711899757418\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 322\n",
      "episode was finished at timestep: 116\n",
      "reward: 6.373076880503535\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.02257346444659763\n",
      "reward_2: 0.6254885165668188\n",
      "reward_3: 8.349999999999984\n",
      "reward_4: 0.024232354662719474\n",
      "reward_5: -0.010741860776985135\n",
      "reward_6: 0.1623649736642836\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 323\n",
      "episode was finished at timestep: 15\n",
      "reward: 8.757810770364479\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.128371971183353\n",
      "reward_2: 0.9203955289213568\n",
      "reward_3: 8.949999999999992\n",
      "reward_4: 0.0048644144379066745\n",
      "reward_5: -0.0014690440618981171\n",
      "reward_6: 0.22763496303558284\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 324\n",
      "episode was finished at timestep: 157\n",
      "reward: 8.243667054930768\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07500762343406678\n",
      "reward_2: 0.8709308426390511\n",
      "reward_3: 8.699999999999989\n",
      "reward_4: 0.011210072792627842\n",
      "reward_5: -0.017731225310726018\n",
      "reward_6: 0.12810333335399604\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 325\n",
      "episode was finished at timestep: 17\n",
      "reward: 7.885017755206203\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0995693756474389\n",
      "reward_2: 0.8155012379639702\n",
      "reward_3: 8.599999999999987\n",
      "reward_4: 0.012418193751646385\n",
      "reward_5: -0.007386907312901414\n",
      "reward_6: 0.1683331664800647\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 326\n",
      "episode was finished at timestep: 35\n",
      "reward: 9.22356032427094\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04166158636411031\n",
      "reward_2: 0.9880679027538823\n",
      "reward_3: 7.7499999999999805\n",
      "reward_4: 0.0017445947455040313\n",
      "reward_5: -0.009608334595941887\n",
      "reward_6: 0.27197375917434674\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 327\n",
      "episode was finished at timestep: 15\n",
      "reward: 9.240340213597008\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.071003567510181\n",
      "reward_2: 0.988937041044171\n",
      "reward_3: 8.449999999999985\n",
      "reward_4: 0.009001330946622801\n",
      "reward_5: -0.015241359981035884\n",
      "reward_6: 0.199944363474846\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 328\n",
      "episode was finished at timestep: 68\n",
      "reward: 8.901027046306963\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06696715354919433\n",
      "reward_2: 0.9452497552905236\n",
      "reward_3: 8.699999999999989\n",
      "reward_4: 0.012130513080174552\n",
      "reward_5: -0.007604664538589034\n",
      "reward_6: 0.18146241033077237\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 329\n",
      "episode was finished at timestep: 77\n",
      "reward: 9.198990562621843\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0512357321050432\n",
      "reward_2: 0.9947162946707543\n",
      "reward_3: 7.79999999999998\n",
      "reward_4: 0.0046167780077287545\n",
      "reward_5: -0.0008281315673089059\n",
      "reward_6: 0.15287838065624315\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 330\n",
      "episode was finished at timestep: 119\n",
      "reward: 7.375684652335815\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07463985880215963\n",
      "reward_2: 0.7594095181423575\n",
      "reward_3: 7.94999999999998\n",
      "reward_4: 0.013061422973283356\n",
      "reward_5: -0.009866186304900163\n",
      "reward_6: 0.1300834509134292\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 331\n",
      "episode was finished at timestep: 120\n",
      "reward: 8.596331450669918\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.051178700394100614\n",
      "reward_2: 0.9246087502547946\n",
      "reward_3: 8.649999999999988\n",
      "reward_4: 0.006224993852667353\n",
      "reward_5: -0.009554152007032713\n",
      "reward_6: 0.10688361608982067\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 332\n",
      "episode was finished at timestep: 110\n",
      "reward: 8.653430752607747\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.03173683020803664\n",
      "reward_2: 0.9326242738020017\n",
      "reward_3: 7.549999999999981\n",
      "reward_4: 0.0007654641939760154\n",
      "reward_5: -0.002940106299810689\n",
      "reward_6: 0.15650945806503236\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 333\n",
      "episode was finished at timestep: 89\n",
      "reward: 7.76661860420438\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.02872272398736742\n",
      "reward_2: 0.817615090085704\n",
      "reward_3: 8.09999999999998\n",
      "reward_4: 0.009224710025551702\n",
      "reward_5: -0.011080441491360678\n",
      "reward_6: 0.13317792081832835\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 334\n",
      "episode was finished at timestep: 37\n",
      "reward: 8.135714250349128\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10803926719559563\n",
      "reward_2: 0.8425665591258816\n",
      "reward_3: 7.84999999999998\n",
      "reward_4: 0.010028731962293307\n",
      "reward_5: -0.002294915314731938\n",
      "reward_6: 0.2081609030961985\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 335\n",
      "episode was finished at timestep: 101\n",
      "reward: 9.072799107935824\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.05832655032475789\n",
      "reward_2: 0.9854287428683717\n",
      "reward_3: 8.84999999999999\n",
      "reward_4: -0.008846967559714898\n",
      "reward_5: -0.011851510518856755\n",
      "reward_6: 0.21248986566066785\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 336\n",
      "episode was finished at timestep: 143\n",
      "reward: 7.957111646556212\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04122639033529493\n",
      "reward_2: 0.8474613488799936\n",
      "reward_3: 8.199999999999982\n",
      "reward_4: -0.002266486669509504\n",
      "reward_5: -0.015259106267923173\n",
      "reward_6: 0.168492131471634\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 337\n",
      "episode was finished at timestep: 21\n",
      "reward: 9.300170475902807\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08620622687869602\n",
      "reward_2: 0.9821388737528908\n",
      "reward_3: 8.599999999999987\n",
      "reward_4: 0.01592629433301269\n",
      "reward_5: -0.00036859170314365033\n",
      "reward_6: 0.22866482937335897\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 338\n",
      "episode was finished at timestep: 98\n",
      "reward: 9.057817492391415\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.11497827304734123\n",
      "reward_2: 0.9498598521560183\n",
      "reward_3: 7.649999999999981\n",
      "reward_4: 0.02084873064194497\n",
      "reward_5: -0.0013020861956833348\n",
      "reward_6: 0.17745264315605114\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 339\n",
      "episode was finished at timestep: 132\n",
      "reward: 8.842317456452951\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10019512838787503\n",
      "reward_2: 0.9327870714806945\n",
      "reward_3: 9.700000000000003\n",
      "reward_4: 0.002228722323202703\n",
      "reward_5: -0.008638739514246178\n",
      "reward_6: 0.26934138381481165\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 340\n",
      "episode was finished at timestep: 2\n",
      "reward: 6.389018759358101\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08104884094662136\n",
      "reward_2: 0.624180467946488\n",
      "reward_3: 8.649999999999988\n",
      "reward_4: 0.018589798658671983\n",
      "reward_5: -0.00339064141871989\n",
      "reward_6: 0.16804509365558684\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 341\n",
      "episode was finished at timestep: 180\n",
      "reward: 9.196298791328143\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06699627306726244\n",
      "reward_2: 0.9879344819792483\n",
      "reward_3: 9.850000000000005\n",
      "reward_4: 0.001959564799761324\n",
      "reward_5: -0.009306251538453955\n",
      "reward_6: 0.2181430622339251\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 342\n",
      "episode was finished at timestep: 63\n",
      "reward: 9.409154136821547\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.13657355705897015\n",
      "reward_2: 0.9823530897722625\n",
      "reward_3: 8.249999999999982\n",
      "reward_4: 0.026338718700014\n",
      "reward_5: -0.0046925749110060385\n",
      "reward_6: 0.20663868689537035\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 343\n",
      "episode was finished at timestep: 53\n",
      "reward: 8.62266265848728\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.17665911316871644\n",
      "reward_2: 0.8809242816695342\n",
      "reward_3: 7.84999999999998\n",
      "reward_4: 0.023997554231940086\n",
      "reward_5: -0.008834964779379225\n",
      "reward_6: 0.21441715621948254\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 344\n",
      "episode was finished at timestep: 132\n",
      "reward: 9.341366753473546\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.17224078045950997\n",
      "reward_2: 0.9775191073729811\n",
      "reward_3: 7.89999999999998\n",
      "reward_4: 0.01326889026502073\n",
      "reward_5: -0.010529737891474274\n",
      "reward_6: 0.25229839646816243\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 345\n",
      "episode was finished at timestep: 46\n",
      "reward: 8.12072473071337\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.1268054697248671\n",
      "reward_2: 0.831960346165484\n",
      "reward_3: 9.650000000000002\n",
      "reward_4: 0.02155603171188389\n",
      "reward_5: -0.0065554273076045885\n",
      "reward_6: 0.17105699861049695\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 346\n",
      "episode was finished at timestep: 74\n",
      "reward: 7.790185360063621\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.1370125823550754\n",
      "reward_2: 0.7843593328724083\n",
      "reward_3: 9.049999999999994\n",
      "reward_4: 0.027295911501238522\n",
      "reward_5: -0.014492358177069302\n",
      "reward_6: 0.1732165142297739\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 347\n",
      "episode was finished at timestep: 48\n",
      "reward: 9.358580141658262\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09835147725211249\n",
      "reward_2: 0.9877816942735048\n",
      "reward_3: 8.349999999999984\n",
      "reward_4: 0.030258148603011393\n",
      "reward_5: -0.009043372275999554\n",
      "reward_6: 0.12383996033668532\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 348\n",
      "episode was finished at timestep: 14\n",
      "reward: 8.8525998422827\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.11651008658938938\n",
      "reward_2: 0.8886424292478001\n",
      "reward_3: 9.099999999999994\n",
      "reward_4: 0.0646803096073461\n",
      "reward_5: -0.019944116034178568\n",
      "reward_6: 0.12823862755298643\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 349\n",
      "episode was finished at timestep: 107\n",
      "reward: 7.883128248846727\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.16664873162905375\n",
      "reward_2: 0.7716025643979039\n",
      "reward_3: 8.399999999999984\n",
      "reward_4: 0.058216672188280964\n",
      "reward_5: -0.02386499293301038\n",
      "reward_6: 0.10067061746120565\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 350\n",
      "episode was finished at timestep: 53\n",
      "reward: 8.760072211750241\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.14318155116505094\n",
      "reward_2: 0.870421582516735\n",
      "reward_3: 7.4499999999999815\n",
      "reward_4: 0.06370983679109585\n",
      "reward_5: -0.016742923485355613\n",
      "reward_6: 0.15958889627456707\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 351\n",
      "episode was finished at timestep: 90\n",
      "reward: 9.231272998344906\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.22079705132378472\n",
      "reward_2: 0.920855311332511\n",
      "reward_3: 8.549999999999986\n",
      "reward_4: 0.06505115341190745\n",
      "reward_5: -0.011814758346677934\n",
      "reward_6: 0.13389898741245287\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 352\n",
      "episode was finished at timestep: 13\n",
      "reward: 8.714408550343197\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.19055232140753003\n",
      "reward_2: 0.8770394758418725\n",
      "reward_3: 9.399999999999999\n",
      "reward_4: 0.04712339180115222\n",
      "reward_5: -0.014013907865623546\n",
      "reward_6: 0.1433138623237612\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 353\n",
      "episode was finished at timestep: 138\n",
      "reward: 8.731258914963483\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.19681378073162503\n",
      "reward_2: 0.8769065386612656\n",
      "reward_3: 8.249999999999982\n",
      "reward_4: 0.046947991896115294\n",
      "reward_5: -0.0023909704900609324\n",
      "reward_6: 0.14489986026287116\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 354\n",
      "episode was finished at timestep: 151\n",
      "reward: 9.830032709521042\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.28059183359146117\n",
      "reward_2: 0.9732916025941698\n",
      "reward_3: 7.79999999999998\n",
      "reward_4: 0.07966460844528939\n",
      "reward_5: -0.011123057791288814\n",
      "reward_6: 0.1358742454051972\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 355\n",
      "episode was finished at timestep: 87\n",
      "reward: 9.225030722384233\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.14083404342333475\n",
      "reward_2: 0.959401429515\n",
      "reward_3: 8.949999999999992\n",
      "reward_4: 0.02897069499609117\n",
      "reward_5: -0.012803501850095482\n",
      "reward_6: 0.18882985138893205\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 356\n",
      "episode was finished at timestep: 63\n",
      "reward: 8.548701670297326\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.20747911267810398\n",
      "reward_2: 0.8330459147357707\n",
      "reward_3: 8.74999999999999\n",
      "reward_4: 0.07090263480118437\n",
      "reward_5: -0.011265784928922903\n",
      "reward_6: 0.11973327958583846\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 357\n",
      "episode was finished at timestep: 44\n",
      "reward: 9.00669181099937\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.1719512575202518\n",
      "reward_2: 0.895383372118976\n",
      "reward_3: 8.449999999999985\n",
      "reward_4: 0.07016181612188505\n",
      "reward_5: -0.01400984295419446\n",
      "reward_6: 0.12326222383975927\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 358\n",
      "episode was finished at timestep: 0\n",
      "reward: 7.071866478032387\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.1509176552295685\n",
      "reward_2: 0.6748869640849292\n",
      "reward_3: 9.049999999999994\n",
      "reward_4: 0.03118966075404458\n",
      "reward_5: -0.011742254256814395\n",
      "reward_6: 0.28287141168117536\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 359\n",
      "episode was finished at timestep: 142\n",
      "reward: 8.061213579260162\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.1939881655904982\n",
      "reward_2: 0.782439732366649\n",
      "reward_3: 7.99999999999998\n",
      "reward_4: 0.06704509860035884\n",
      "reward_5: -0.011395544892381083\n",
      "reward_6: 0.08167564415931672\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 360\n",
      "episode was finished at timestep: 17\n",
      "reward: 7.689239844667109\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0981911109553443\n",
      "reward_2: 0.7536707476612383\n",
      "reward_3: 8.84999999999999\n",
      "reward_4: 0.046778313335030505\n",
      "reward_5: -0.002642104239692126\n",
      "reward_6: 0.18891834998130763\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 361\n",
      "episode was finished at timestep: 81\n",
      "reward: 8.999757135212816\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04246084756321377\n",
      "reward_2: 0.9527062188280123\n",
      "reward_3: 9.750000000000004\n",
      "reward_4: 0.014729730696092104\n",
      "reward_5: -0.003667008373288638\n",
      "reward_6: 0.22017569983005514\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 362\n",
      "episode was finished at timestep: 26\n",
      "reward: 9.170073454600264\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09945314857694838\n",
      "reward_2: 0.9686165866798924\n",
      "reward_3: 9.45\n",
      "reward_4: 0.012830523936078038\n",
      "reward_5: -0.008223793927488761\n",
      "reward_6: 0.22600721502304022\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 363\n",
      "episode was finished at timestep: 151\n",
      "reward: 8.006294612935413\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10755677753024631\n",
      "reward_2: 0.7963210901145701\n",
      "reward_3: 9.600000000000001\n",
      "reward_4: 0.03470072243131739\n",
      "reward_5: -0.008339542559742223\n",
      "reward_6: 0.2576228775978088\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 364\n",
      "episode was finished at timestep: 27\n",
      "reward: -78.64628240867414\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.034954531987508135\n",
      "reward_2: -10\n",
      "reward_3: 9.099999999999994\n",
      "reward_4: 0.006351619852283222\n",
      "reward_5: -0.004483319268592348\n",
      "reward_6: 0.2712200864553449\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 365\n",
      "episode was finished at timestep: 96\n",
      "reward: 5.139681419861757\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0560157126850552\n",
      "reward_2: 0.7110266316126488\n",
      "reward_3: 9.800000000000004\n",
      "reward_4: 0.008299261202364079\n",
      "reward_5: -0.007826422274883645\n",
      "reward_6: 0.33557832026481593\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 366\n",
      "episode was finished at timestep: 111\n",
      "reward: 9.04646268510962\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10436447130309211\n",
      "reward_2: 0.9190605941775007\n",
      "reward_3: 8.74999999999999\n",
      "reward_4: 0.04094584580564828\n",
      "reward_5: -0.002402286906659749\n",
      "reward_6: 0.2632823141813281\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 367\n",
      "episode was finished at timestep: 148\n",
      "reward: 8.91695820671946\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07419554326269362\n",
      "reward_2: 0.9244539782851404\n",
      "reward_3: 8.74999999999999\n",
      "reward_4: 0.03597259441151337\n",
      "reward_5: -0.0021162646585049555\n",
      "reward_6: 0.1602996798753742\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 368\n",
      "episode was finished at timestep: 90\n",
      "reward: 8.131105324956467\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06212284101380242\n",
      "reward_2: 0.8217289098252666\n",
      "reward_3: 8.399999999999984\n",
      "reward_4: 0.03083598120580831\n",
      "reward_5: -0.016946492752782188\n",
      "reward_6: 0.2642898484468468\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 369\n",
      "episode was finished at timestep: 65\n",
      "reward: 9.29609158789371\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10918442938062879\n",
      "reward_2: 0.9569923961613173\n",
      "reward_3: 8.04999999999998\n",
      "reward_4: 0.040119568716928594\n",
      "reward_5: -0.016016589190189615\n",
      "reward_6: 0.22495469534397083\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 370\n",
      "episode was finished at timestep: 92\n",
      "reward: -80.87548703748621\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0064670609103308786\n",
      "reward_2: -10\n",
      "reward_3: 9.299999999999997\n",
      "reward_4: -0.031575456412693936\n",
      "reward_5: 0.04260436314978762\n",
      "reward_6: 0.33973931157588966\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 371\n",
      "episode was finished at timestep: 36\n",
      "reward: 9.274253627974424\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.16420922213130526\n",
      "reward_2: 0.9546883842454796\n",
      "reward_3: 10.25000000000001\n",
      "reward_4: 0.02667191461242311\n",
      "reward_5: -0.015820599886996214\n",
      "reward_6: 0.2736159482002264\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 372\n",
      "episode was finished at timestep: 151\n",
      "reward: 7.570588668156847\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09135470853911506\n",
      "reward_2: 0.7724092277366458\n",
      "reward_3: 9.800000000000004\n",
      "reward_4: 0.01177397017017583\n",
      "reward_5: -0.0019271461184409589\n",
      "reward_6: 0.20638885581493382\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 373\n",
      "episode was finished at timestep: 178\n",
      "reward: 8.762769218413696\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06263205077913073\n",
      "reward_2: 0.9328756177467987\n",
      "reward_3: 9.55\n",
      "reward_4: -0.003904707645104537\n",
      "reward_5: -0.0004788019228958736\n",
      "reward_6: 0.2675753554105753\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 374\n",
      "episode was finished at timestep: 195\n",
      "reward: 8.98385667052261\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.23088696863916186\n",
      "reward_2: 0.8791910623880763\n",
      "reward_3: 10.100000000000009\n",
      "reward_4: 0.059118818187106965\n",
      "reward_5: -0.004675095221095304\n",
      "reward_6: 0.24981908583640988\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 375\n",
      "episode was finished at timestep: 94\n",
      "reward: 8.564356373323657\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.005597284105088976\n",
      "reward_2: 0.9115612138646583\n",
      "reward_3: 8.84999999999999\n",
      "reward_4: -0.004665736539776191\n",
      "reward_5: 0.06255352090423637\n",
      "reward_6: 0.25105631792545324\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 376\n",
      "episode was finished at timestep: 104\n",
      "reward: 8.520574102929523\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06977231833669874\n",
      "reward_2: 0.8772596533003764\n",
      "reward_3: 8.449999999999985\n",
      "reward_4: 0.029650317212840775\n",
      "reward_5: -0.005650348875425948\n",
      "reward_6: 0.20004570269584654\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 377\n",
      "episode was finished at timestep: 144\n",
      "reward: 9.308362134594478\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.23909790714581808\n",
      "reward_2: 0.8673930942257995\n",
      "reward_3: 8.499999999999986\n",
      "reward_4: 0.10767870438048448\n",
      "reward_5: -0.0038361247159858893\n",
      "reward_6: 0.27139262998104097\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 378\n",
      "episode was finished at timestep: 80\n",
      "reward: 8.62837709389746\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.15716198086738586\n",
      "reward_2: 0.8552242794882499\n",
      "reward_3: 9.049999999999994\n",
      "reward_4: 0.048175521737358055\n",
      "reward_5: -0.00018988810118412877\n",
      "reward_6: 0.24299992465972953\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 379\n",
      "episode was finished at timestep: 93\n",
      "reward: 6.885194579440671\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.12879108124309116\n",
      "reward_2: 0.6441312558813597\n",
      "reward_3: 7.7499999999999805\n",
      "reward_4: 0.040204314279479264\n",
      "reward_5: -0.006596551220972794\n",
      "reward_6: 0.28728215479850805\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 380\n",
      "episode was finished at timestep: 177\n",
      "reward: 6.323037687904098\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09649313092231751\n",
      "reward_2: 0.838330189492144\n",
      "reward_3: 9.45\n",
      "reward_4: 0.028434283455568733\n",
      "reward_5: -0.011072201741446127\n",
      "reward_6: 0.30224097514152526\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 381\n",
      "episode was finished at timestep: 46\n",
      "reward: 7.520717806845143\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.16571964687771268\n",
      "reward_2: 0.7138511846955737\n",
      "reward_3: 8.84999999999999\n",
      "reward_4: 0.04802953522583863\n",
      "reward_5: -0.009051614663611218\n",
      "reward_6: 0.2678240152597424\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 382\n",
      "episode was finished at timestep: 5\n",
      "reward: 9.24126034389114\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.1481241762638092\n",
      "reward_2: 0.9465057990311767\n",
      "reward_3: 10.000000000000007\n",
      "reward_4: 0.03503643619196467\n",
      "reward_5: -0.003261072714864592\n",
      "reward_6: 0.2427260252237312\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 383\n",
      "episode was finished at timestep: 69\n",
      "reward: 7.628377931596985\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10418020553059049\n",
      "reward_2: 0.7833851014341867\n",
      "reward_3: 9.700000000000003\n",
      "reward_4: 0.003344498402024101\n",
      "reward_5: -0.006124513157248875\n",
      "reward_6: 0.2351921072006231\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 384\n",
      "episode was finished at timestep: 128\n",
      "reward: 8.460818446134315\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.048663517501619125\n",
      "reward_2: 0.9052833953115714\n",
      "reward_3: 9.099999999999994\n",
      "reward_4: -0.010479350838240009\n",
      "reward_5: -0.010129486364096963\n",
      "reward_6: 0.2626387258768078\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 385\n",
      "episode was finished at timestep: 63\n",
      "reward: 8.860415446226579\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.1263635171784295\n",
      "reward_2: 0.8940536127567\n",
      "reward_3: 8.999999999999993\n",
      "reward_4: 0.04522769559254911\n",
      "reward_5: -0.0014961882737986561\n",
      "reward_6: 0.2200976505279545\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 386\n",
      "episode was finished at timestep: 94\n",
      "reward: 9.053379180225768\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.15279783142937553\n",
      "reward_2: 0.9217118800517348\n",
      "reward_3: 8.899999999999991\n",
      "reward_4: 0.0378753135210917\n",
      "reward_5: -0.014262073749257809\n",
      "reward_6: 0.23695920729637132\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 387\n",
      "episode was finished at timestep: 149\n",
      "reward: 8.660952249632242\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.1253049949804942\n",
      "reward_2: 0.8959968641152443\n",
      "reward_3: 9.349999999999998\n",
      "reward_4: 0.017448590821112477\n",
      "reward_5: -0.01048334493228597\n",
      "reward_6: 0.23732029342651328\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 388\n",
      "episode was finished at timestep: 104\n",
      "reward: 8.990800171472896\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.11516224808163113\n",
      "reward_2: 0.9261907053868159\n",
      "reward_3: 9.45\n",
      "reward_4: 0.02937334744151542\n",
      "reward_5: -0.011911664409869734\n",
      "reward_6: 0.24177716517448478\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 389\n",
      "episode was finished at timestep: 37\n",
      "reward: 8.800835083602157\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.14555694195959304\n",
      "reward_2: 0.8906904318606514\n",
      "reward_3: 9.149999999999995\n",
      "reward_4: 0.03487871431686685\n",
      "reward_5: -0.011035014507203537\n",
      "reward_6: 0.26053998672962186\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 390\n",
      "episode was finished at timestep: 7\n",
      "reward: 8.342344662426655\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.1392658703856998\n",
      "reward_2: 0.8361243073508028\n",
      "reward_3: 9.650000000000002\n",
      "reward_4: 0.03295159633930453\n",
      "reward_5: -0.00018823160704961595\n",
      "reward_6: 0.24937312746048002\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 391\n",
      "episode was finished at timestep: 98\n",
      "reward: 8.3652777928289\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.14165651533338758\n",
      "reward_2: 0.8461816327931606\n",
      "reward_3: 8.649999999999988\n",
      "reward_4: 0.02711664915197687\n",
      "reward_5: -0.0003754705604883668\n",
      "reward_6: 0.23645715916156795\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 392\n",
      "episode was finished at timestep: 52\n",
      "reward: 8.001982607581875\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.15601070523262023\n",
      "reward_2: 0.7906924493644151\n",
      "reward_3: 9.55\n",
      "reward_4: 0.03453849110813735\n",
      "reward_5: -0.008934930101525514\n",
      "reward_6: 0.2517859753370282\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 393\n",
      "episode was finished at timestep: 152\n",
      "reward: 7.83227642151129\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.1376970112323761\n",
      "reward_2: 0.779087453446903\n",
      "reward_3: 9.800000000000004\n",
      "reward_4: 0.031325892943061005\n",
      "reward_5: -0.010109238078754027\n",
      "reward_6: 0.22007521057128954\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 394\n",
      "episode was finished at timestep: 170\n",
      "reward: 8.336000857619418\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.11410364508628845\n",
      "reward_2: 0.8474521680594007\n",
      "reward_3: 10.350000000000012\n",
      "reward_4: 0.028891952573714547\n",
      "reward_5: -0.010757634350562857\n",
      "reward_6: 0.22052188181877097\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 395\n",
      "episode was finished at timestep: 3\n",
      "reward: 6.460974994720893\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.19059799313545228\n",
      "reward_2: 0.852781271738546\n",
      "reward_3: 8.84999999999999\n",
      "reward_4: 0.01712244182491176\n",
      "reward_5: -0.0028635910212288468\n",
      "reward_6: 0.3128308840990083\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 396\n",
      "episode was finished at timestep: 80\n",
      "reward: 7.372008447705245\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0017295208242204454\n",
      "reward_2: 0.7762041852260865\n",
      "reward_3: 10.050000000000008\n",
      "reward_4: -0.016567901485540517\n",
      "reward_5: 0.03209188055757508\n",
      "reward_6: 0.26321581804752336\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 397\n",
      "episode was finished at timestep: 44\n",
      "reward: 9.110828095544651\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.1045768678188324\n",
      "reward_2: 0.9691431522347088\n",
      "reward_3: 10.20000000000001\n",
      "reward_4: -0.0025794389068421707\n",
      "reward_5: -0.00573927343179849\n",
      "reward_6: 0.27812079453468297\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 398\n",
      "episode was finished at timestep: 160\n",
      "reward: 6.262647865005215\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0028026004632314048\n",
      "reward_2: 0.6143392052094614\n",
      "reward_3: 9.199999999999996\n",
      "reward_4: -0.028482618446268617\n",
      "reward_5: 0.3005890882997157\n",
      "reward_6: 0.27678201639652267\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 399\n",
      "episode was finished at timestep: 19\n",
      "reward: -78.54304862096923\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.12083284126387703\n",
      "reward_2: -10\n",
      "reward_3: 10.500000000000014\n",
      "reward_4: 0.007608214834985603\n",
      "reward_5: -0.005398356078160305\n",
      "reward_6: 0.2792511751651763\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 400\n",
      "episode was finished at timestep: 217\n",
      "reward: 6.376208397136724\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.1535188403394487\n",
      "reward_2: 0.6043093808752927\n",
      "reward_3: 10.95000000000002\n",
      "reward_4: 0.017904691482663822\n",
      "reward_5: -0.01254292997958461\n",
      "reward_6: 0.25605990791320765\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 401\n",
      "episode was finished at timestep: 4\n",
      "reward: 8.640934861697946\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.15144655770725673\n",
      "reward_2: 0.8945410459966983\n",
      "reward_3: 10.20000000000001\n",
      "reward_4: 0.012281819448248115\n",
      "reward_5: -0.007683180612621025\n",
      "reward_6: 0.2412285610437398\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 402\n",
      "episode was finished at timestep: 9\n",
      "reward: 8.145747264182704\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.13984490434328714\n",
      "reward_2: 0.8390177241656621\n",
      "reward_3: 10.500000000000014\n",
      "reward_4: 0.007544756937043076\n",
      "reward_5: -0.006390168315911519\n",
      "reward_6: 0.23839267933368746\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 403\n",
      "episode was finished at timestep: 164\n",
      "reward: 8.067005707787034\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0020707541041904026\n",
      "reward_2: 0.8633097150867467\n",
      "reward_3: 10.500000000000014\n",
      "reward_4: -0.021800543874450115\n",
      "reward_5: 0.10048699164315344\n",
      "reward_6: 0.235116100549698\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 404\n",
      "episode was finished at timestep: 22\n",
      "reward: 8.583117534639781\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09309113423029582\n",
      "reward_2: 0.8904516569558026\n",
      "reward_3: 9.5\n",
      "reward_4: 0.01825754086952216\n",
      "reward_5: -0.009628923160546065\n",
      "reward_6: 0.22871507430076599\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 405\n",
      "episode was finished at timestep: 69\n",
      "reward: 7.750748233439462\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08856061299641928\n",
      "reward_2: 0.7962880633698136\n",
      "reward_3: 10.300000000000011\n",
      "reward_4: 0.008156954424837722\n",
      "reward_5: -0.0073296834583328994\n",
      "reward_6: 0.23258382821083134\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 406\n",
      "episode was finished at timestep: 42\n",
      "reward: 9.43654723178402\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.21384172373347812\n",
      "reward_2: 0.9608716450759001\n",
      "reward_3: 10.20000000000001\n",
      "reward_4: 0.041737516449400686\n",
      "reward_5: -0.009956965250801631\n",
      "reward_6: 0.21042918109893827\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 407\n",
      "episode was finished at timestep: 24\n",
      "reward: 10.517774870706331\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.002997143401039971\n",
      "reward_2: 0.9945380754277405\n",
      "reward_3: 10.300000000000011\n",
      "reward_4: 0.15403988296097168\n",
      "reward_5: 0.11794249937829863\n",
      "reward_6: 0.21283251428604189\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 408\n",
      "episode was finished at timestep: 45\n",
      "reward: 8.161569434448756\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09560288654433356\n",
      "reward_2: 0.8469600390075034\n",
      "reward_3: 10.15000000000001\n",
      "reward_4: 0.002851737849836269\n",
      "reward_5: -0.005289088137245675\n",
      "reward_6: 0.2714080878496177\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 409\n",
      "episode was finished at timestep: 21\n",
      "reward: 9.230285324055462\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.15036327176623873\n",
      "reward_2: 0.9554791811879746\n",
      "reward_3: 9.700000000000003\n",
      "reward_4: 0.02875270520785506\n",
      "reward_5: -0.005047436921365881\n",
      "reward_6: 0.20982106471061746\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 410\n",
      "episode was finished at timestep: 65\n",
      "reward: 8.026336610214685\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.13892239994472927\n",
      "reward_2: 0.8272470830665192\n",
      "reward_3: 10.25000000000001\n",
      "reward_4: 0.00493456879268237\n",
      "reward_5: -0.008831244976952254\n",
      "reward_6: 0.23742557370662765\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 411\n",
      "episode was finished at timestep: 105\n",
      "reward: 7.677895033673815\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.061350178056293066\n",
      "reward_2: 0.7838891796724494\n",
      "reward_3: 10.650000000000016\n",
      "reward_4: 0.013180200274548639\n",
      "reward_5: -0.003745771002224766\n",
      "reward_6: 0.24231558704376255\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 412\n",
      "episode was finished at timestep: 55\n",
      "reward: 7.660766729175012\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.1943026211526659\n",
      "reward_2: 0.7578713125873144\n",
      "reward_3: 9.600000000000001\n",
      "reward_4: 0.01889384429972651\n",
      "reward_5: -0.0015193594028931538\n",
      "reward_6: 0.2525822123289112\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 413\n",
      "episode was finished at timestep: 155\n",
      "reward: 9.263406274795049\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10003821783595615\n",
      "reward_2: 0.9777669487853078\n",
      "reward_3: 10.650000000000016\n",
      "reward_4: 0.009625080658195912\n",
      "reward_5: -0.0005792021055915105\n",
      "reward_6: 0.263391023516655\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 414\n",
      "episode was finished at timestep: 154\n",
      "reward: 8.49325924414821\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.17288294633229573\n",
      "reward_2: 0.8693133570055689\n",
      "reward_3: 10.600000000000016\n",
      "reward_4: 0.015885313615441134\n",
      "reward_5: -0.012907949223979524\n",
      "reward_6: 0.2502815487384795\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 415\n",
      "episode was finished at timestep: 123\n",
      "reward: 7.905810895119646\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.17670532597435845\n",
      "reward_2: 0.776785044920066\n",
      "reward_3: 9.349999999999998\n",
      "reward_4: 0.04058694206215407\n",
      "reward_5: -0.013490393352055227\n",
      "reward_6: 0.20237339997291592\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 416\n",
      "episode was finished at timestep: 157\n",
      "reward: 9.057905925633085\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.12994639277458192\n",
      "reward_2: 0.9485902542232711\n",
      "reward_3: 10.750000000000018\n",
      "reward_4: 0.00941255007887733\n",
      "reward_5: -0.010238339064724756\n",
      "reward_6: 0.27274210417270706\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 417\n",
      "episode was finished at timestep: 39\n",
      "reward: 8.803552113814675\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09834550950262282\n",
      "reward_2: 0.9083989542190419\n",
      "reward_3: 10.95000000000002\n",
      "reward_4: 0.02567496829913992\n",
      "reward_5: -0.00406281939915445\n",
      "reward_6: 0.23521804356575082\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 418\n",
      "episode was finished at timestep: 19\n",
      "reward: 8.602254169856735\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.23465509679582383\n",
      "reward_2: 0.8630218088419571\n",
      "reward_3: 10.750000000000018\n",
      "reward_4: 0.028585593869868687\n",
      "reward_5: -0.001374201581058069\n",
      "reward_6: 0.23468071961402903\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 419\n",
      "episode was finished at timestep: 117\n",
      "reward: 6.690678780042703\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.060483715931574505\n",
      "reward_2: 0.6764755557619807\n",
      "reward_3: 8.699999999999989\n",
      "reward_4: 0.0013478439986769786\n",
      "reward_5: -0.008349636968668623\n",
      "reward_6: 0.21479750299453704\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 420\n",
      "episode was finished at timestep: 90\n",
      "reward: 8.48374674361351\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.16178232431411743\n",
      "reward_2: 0.8714817824987527\n",
      "reward_3: 10.95000000000002\n",
      "reward_4: 0.015367170364498008\n",
      "reward_5: -0.0014952376451554746\n",
      "reward_6: 0.22720803403854306\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 421\n",
      "episode was finished at timestep: 11\n",
      "reward: 9.112664073868729\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0875464697678884\n",
      "reward_2: 0.9726584326181065\n",
      "reward_3: 10.20000000000001\n",
      "reward_4: -0.0008649323315438551\n",
      "reward_5: -0.004420725225655057\n",
      "reward_6: 0.25383032703399533\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 422\n",
      "episode was finished at timestep: 183\n",
      "reward: 8.52936739102702\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09820084373156229\n",
      "reward_2: 0.9109844048530544\n",
      "reward_3: 10.750000000000018\n",
      "reward_4: -0.009950357723074746\n",
      "reward_5: -0.006608844245317039\n",
      "reward_6: 0.22806968116760296\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 423\n",
      "episode was finished at timestep: 225\n",
      "reward: 8.44892852320406\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0015786800119611951\n",
      "reward_2: 0.9365210459698521\n",
      "reward_3: 11.500000000000028\n",
      "reward_4: -0.040225443520440364\n",
      "reward_5: 0.01182338549056645\n",
      "reward_6: 0.26678566479682775\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 424\n",
      "episode was finished at timestep: 43\n",
      "reward: 7.492039831336081\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0709574712647332\n",
      "reward_2: 0.7930683183122001\n",
      "reward_3: 10.450000000000014\n",
      "reward_4: -0.017253443295364976\n",
      "reward_5: -0.009638519462951578\n",
      "reward_6: 0.22280854606628442\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 425\n",
      "episode was finished at timestep: 181\n",
      "reward: 8.129890728333196\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08971496687995063\n",
      "reward_2: 0.8581348930690698\n",
      "reward_3: 10.700000000000017\n",
      "reward_4: -0.011477335468216552\n",
      "reward_5: -0.006027698885008685\n",
      "reward_6: 0.2715163328647614\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 426\n",
      "episode was finished at timestep: 19\n",
      "reward: 8.264058712665399\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0927893148528205\n",
      "reward_2: 0.8814748538689617\n",
      "reward_3: 11.050000000000022\n",
      "reward_4: -0.014388897274559014\n",
      "reward_5: -0.012170079296179399\n",
      "reward_6: 0.24527849102020338\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 427\n",
      "episode was finished at timestep: 30\n",
      "reward: 7.244996526302218\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06631483634312947\n",
      "reward_2: 0.7516480057599491\n",
      "reward_3: 10.500000000000014\n",
      "reward_4: -0.007333719925265143\n",
      "reward_5: -0.004935588323187427\n",
      "reward_6: 0.22770299160480467\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 428\n",
      "episode was finished at timestep: 119\n",
      "reward: 7.264944360413137\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.001570206880569458\n",
      "reward_2: 0.9296267192803522\n",
      "reward_3: 6.5999999999999845\n",
      "reward_4: -0.03582097852569163\n",
      "reward_5: 0.8370027965966161\n",
      "reward_6: 0.27818584465980556\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 429\n",
      "episode was finished at timestep: 144\n",
      "reward: -78.33730765240811\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.11016451054149204\n",
      "reward_2: -10\n",
      "reward_3: 10.350000000000012\n",
      "reward_4: 0.046102370089619316\n",
      "reward_5: -0.01245677785375605\n",
      "reward_6: 0.1947856541872034\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 430\n",
      "episode was finished at timestep: 39\n",
      "reward: 5.9308437220243935\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0917942139837477\n",
      "reward_2: 0.8248104110441432\n",
      "reward_3: 11.150000000000023\n",
      "reward_4: -0.006669840400126219\n",
      "reward_5: -0.007434143850712971\n",
      "reward_6: 0.299872420072556\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 431\n",
      "episode was finished at timestep: 22\n",
      "reward: 8.077183244612273\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07393791344430711\n",
      "reward_2: 0.8179411739677687\n",
      "reward_3: 11.050000000000022\n",
      "reward_4: 0.026675340302095094\n",
      "reward_5: -0.0032559585665192497\n",
      "reward_6: 0.2480958422422418\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 432\n",
      "episode was finished at timestep: 212\n",
      "reward: 9.022818780808656\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.1338404999838935\n",
      "reward_2: 0.9680324524036674\n",
      "reward_3: 11.60000000000003\n",
      "reward_4: -0.007506687774763492\n",
      "reward_5: -0.005153557181074812\n",
      "reward_6: 0.20837905430793824\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 433\n",
      "episode was finished at timestep: 37\n",
      "reward: -78.2137202133986\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.14563123650021023\n",
      "reward_2: -10\n",
      "reward_3: 10.550000000000015\n",
      "reward_4: 0.04717624881741287\n",
      "reward_5: -0.007879211378585892\n",
      "reward_6: 0.2697111042737961\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 434\n",
      "episode was finished at timestep: 143\n",
      "reward: 8.161380694296943\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10565351512697008\n",
      "reward_2: 0.8540160283032261\n",
      "reward_3: 11.200000000000024\n",
      "reward_4: 0.0038739744537681984\n",
      "reward_5: -0.007045785894722437\n",
      "reward_6: 0.1981596096754078\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 435\n",
      "episode was finished at timestep: 77\n",
      "reward: 8.705218891988636\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0892106360859341\n",
      "reward_2: 0.9203487761103497\n",
      "reward_3: 11.950000000000035\n",
      "reward_4: 0.003593426496616132\n",
      "reward_5: -0.011730038026157293\n",
      "reward_6: 0.2346073397397993\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 436\n",
      "episode was finished at timestep: 60\n",
      "reward: 8.529505996987881\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.1679487791326311\n",
      "reward_2: 0.8805492548021908\n",
      "reward_3: 10.90000000000002\n",
      "reward_4: 0.011470329799074933\n",
      "reward_5: -0.011118368960762837\n",
      "reward_6: 0.23506557667255368\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 437\n",
      "episode was finished at timestep: 167\n",
      "reward: -77.95564659116445\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07462245027224222\n",
      "reward_2: -10\n",
      "reward_3: 11.300000000000026\n",
      "reward_4: 0.10223058084889373\n",
      "reward_5: -0.013059376243456692\n",
      "reward_6: 0.16343902134895394\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 438\n",
      "episode was finished at timestep: 95\n",
      "reward: 8.589816167835592\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07925548089875115\n",
      "reward_2: 0.9288968999281894\n",
      "reward_3: 11.55000000000003\n",
      "reward_4: -0.020479527326460384\n",
      "reward_5: -0.003953916855201929\n",
      "reward_6: 0.24563562297821062\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 439\n",
      "episode was finished at timestep: 71\n",
      "reward: 8.679295246753988\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.006675157282087538\n",
      "reward_2: 0.9098505889071987\n",
      "reward_3: 7.99999999999998\n",
      "reward_4: 0.021589431773319064\n",
      "reward_5: -0.010197202448212888\n",
      "reward_6: 0.2302304598093029\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 440\n",
      "episode was finished at timestep: 137\n",
      "reward: 8.395524100896974\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.032523670461442736\n",
      "reward_2: 0.8819404448482304\n",
      "reward_3: 9.900000000000006\n",
      "reward_4: 0.007731409390022179\n",
      "reward_5: -0.011343832672567207\n",
      "reward_6: 0.255649429202079\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 441\n",
      "episode was finished at timestep: 119\n",
      "reward: 8.764163560776538\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.19878604743215772\n",
      "reward_2: 0.8097181528181941\n",
      "reward_3: 10.000000000000007\n",
      "reward_4: 0.12646662274315829\n",
      "reward_5: -0.02037234881200938\n",
      "reward_6: 0.09493832433223681\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 442\n",
      "episode was finished at timestep: 50\n",
      "reward: 5.80621294899982\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.00792463223139445\n",
      "reward_2: 0.6183107671033774\n",
      "reward_3: 10.25000000000001\n",
      "reward_4: -0.04560692986660129\n",
      "reward_5: -0.003421375312500885\n",
      "reward_6: 0.2345615919828412\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 443\n",
      "episode was finished at timestep: 104\n",
      "reward: 7.409575411551963\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.30943884319729276\n",
      "reward_2: 0.6187797330697874\n",
      "reward_3: 10.800000000000018\n",
      "reward_4: 0.12386014107019278\n",
      "reward_5: -0.007946482153476353\n",
      "reward_6: 0.16552405738830578\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 444\n",
      "episode was finished at timestep: 0\n",
      "reward: 8.333553137963657\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.16201174590322706\n",
      "reward_2: 0.8012230809767814\n",
      "reward_3: 11.400000000000027\n",
      "reward_4: 0.07059261468826505\n",
      "reward_5: -0.007245432238786738\n",
      "reward_6: 0.2027412589788442\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 445\n",
      "episode was finished at timestep: 39\n",
      "reward: 7.95531196080063\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0011766513188680014\n",
      "reward_2: 0.7426953002159126\n",
      "reward_3: 6.299999999999986\n",
      "reward_4: -0.013260171844085704\n",
      "reward_5: 0.8545636688574606\n",
      "reward_6: 0.2656039162874225\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 446\n",
      "episode was finished at timestep: 145\n",
      "reward: 7.651596576438172\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0032755699422624377\n",
      "reward_2: 0.8028924462310698\n",
      "reward_3: 9.099999999999994\n",
      "reward_4: -0.02029957329530447\n",
      "reward_5: 0.13176830222390473\n",
      "reward_6: 0.26114752733707447\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 447\n",
      "episode was finished at timestep: 61\n",
      "reward: 9.32202077627471\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.13314134942160713\n",
      "reward_2: 0.9643665760081068\n",
      "reward_3: 10.800000000000018\n",
      "reward_4: 0.0320092352144475\n",
      "reward_5: -0.004555856538857365\n",
      "reward_6: 0.22098879361152723\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 448\n",
      "episode was finished at timestep: 184\n",
      "reward: 8.452105497984936\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.12437293397055732\n",
      "reward_2: 0.8505948266078336\n",
      "reward_3: 11.250000000000025\n",
      "reward_4: 0.03647375705083547\n",
      "reward_5: -0.012780794509733795\n",
      "reward_6: 0.24246468925476017\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 449\n",
      "episode was finished at timestep: 139\n",
      "reward: 7.621887522383085\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.008655871947606404\n",
      "reward_2: 0.81985406551855\n",
      "reward_3: 9.950000000000006\n",
      "reward_4: -0.022872703276035224\n",
      "reward_5: 0.021456176537109902\n",
      "reward_6: 0.23190965318679746\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 450\n",
      "episode was finished at timestep: 37\n",
      "reward: 8.140862903859258\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.009596895509295994\n",
      "reward_2: 0.8976622727559924\n",
      "reward_3: 10.15000000000001\n",
      "reward_4: -0.03185191091590539\n",
      "reward_5: -0.004836724481868752\n",
      "reward_6: 0.22746029579639437\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 451\n",
      "episode was finished at timestep: 97\n",
      "reward: 6.294526437303867\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06301957368850708\n",
      "reward_2: 0.6235543303992221\n",
      "reward_3: 8.399999999999984\n",
      "reward_4: 0.011892232178119428\n",
      "reward_5: -0.005233218318413672\n",
      "reward_6: 0.15204758131504081\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 452\n",
      "episode was finished at timestep: 103\n",
      "reward: 7.201562778391745\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.00842787226041158\n",
      "reward_2: 0.9092588501923851\n",
      "reward_3: 6.199999999999986\n",
      "reward_4: -0.022741163377141334\n",
      "reward_5: 0.8303775589816293\n",
      "reward_6: 0.2866449304819112\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 453\n",
      "episode was finished at timestep: 207\n",
      "reward: 8.774086886463907\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.1509293191962772\n",
      "reward_2: 0.9081428187018001\n",
      "reward_3: 11.750000000000032\n",
      "reward_4: 0.014726363606192762\n",
      "reward_5: -0.009969099854214628\n",
      "reward_6: 0.24860654199123478\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 454\n",
      "episode was finished at timestep: 88\n",
      "reward: 6.797344536330798\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.17656779487927754\n",
      "reward_2: 0.6630850271317181\n",
      "reward_3: 12.35000000000004\n",
      "reward_4: 0.0056833812372951795\n",
      "reward_5: -0.009141918224304983\n",
      "reward_6: 0.27812472605705285\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 455\n",
      "episode was finished at timestep: 52\n",
      "reward: 7.137079814415994\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0007321503427293566\n",
      "reward_2: 0.6594127913356191\n",
      "reward_3: 9.099999999999994\n",
      "reward_4: 0.0018583256789570157\n",
      "reward_5: 0.5791732783919327\n",
      "reward_6: 0.2672564169168473\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 456\n",
      "episode was finished at timestep: 38\n",
      "reward: 8.161412595647063\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.1268794059753418\n",
      "reward_2: 0.8316670045405343\n",
      "reward_3: 10.90000000000002\n",
      "reward_4: 0.01926489266463278\n",
      "reward_5: -0.009897057090341594\n",
      "reward_6: 0.23552173578739144\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 457\n",
      "episode was finished at timestep: 26\n",
      "reward: 6.777457102433113\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.1345702913072374\n",
      "reward_2: 0.6715799876350059\n",
      "reward_3: 10.600000000000016\n",
      "reward_4: 0.006965900051259695\n",
      "reward_5: -0.009071161615674346\n",
      "reward_6: 0.22217753791809103\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 458\n",
      "episode was finished at timestep: 114\n",
      "reward: 8.381391254675545\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.15326982604132758\n",
      "reward_2: 0.8477249507412147\n",
      "reward_3: 10.20000000000001\n",
      "reward_4: 0.030761485643904934\n",
      "reward_5: -0.013410797462609026\n",
      "reward_6: 0.21228073501586886\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 459\n",
      "episode was finished at timestep: 171\n",
      "reward: 7.6634687081867\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.13413767351044548\n",
      "reward_2: 0.762490166394668\n",
      "reward_3: 10.90000000000002\n",
      "reward_4: 0.027039721872629627\n",
      "reward_5: -0.013347266812137094\n",
      "reward_6: 0.22498586201667792\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 460\n",
      "episode was finished at timestep: 31\n",
      "reward: 5.9945556539145795\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.008551724751790364\n",
      "reward_2: 0.6078388791938654\n",
      "reward_3: 9.099999999999994\n",
      "reward_4: -0.00978268312417029\n",
      "reward_5: 0.039335884503670586\n",
      "reward_6: 0.17810859227180564\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 461\n",
      "episode was finished at timestep: 209\n",
      "reward: 8.460047564069473\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.05733041697078281\n",
      "reward_2: 0.896378901018793\n",
      "reward_3: 11.350000000000026\n",
      "reward_4: -0.0028588830478591377\n",
      "reward_5: -0.002599602640435942\n",
      "reward_6: 0.25564327263832076\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 462\n",
      "episode was finished at timestep: 194\n",
      "reward: 8.637343866973769\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10515248444345263\n",
      "reward_2: 0.9143629118532358\n",
      "reward_3: 11.000000000000021\n",
      "reward_4: -0.003908966774935152\n",
      "reward_5: -0.00787748136897252\n",
      "reward_6: 0.2549706366062161\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 463\n",
      "episode was finished at timestep: 72\n",
      "reward: -80.10636890078734\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10747900207837423\n",
      "reward_2: -10\n",
      "reward_3: 8.649999999999988\n",
      "reward_4: 0.050474692579492456\n",
      "reward_5: 0.08754740276954524\n",
      "reward_6: 0.2936538203954697\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 464\n",
      "episode was finished at timestep: 60\n",
      "reward: 8.560222388423359\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.006214097473356459\n",
      "reward_2: 0.9371502408701193\n",
      "reward_3: 8.79999999999999\n",
      "reward_4: -0.03705894503303668\n",
      "reward_5: 0.10738634726808745\n",
      "reward_6: 0.25714643859863295\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 465\n",
      "episode was finished at timestep: 43\n",
      "reward: 7.50739008341677\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.12293069958686828\n",
      "reward_2: 0.978796794664374\n",
      "reward_3: 8.999999999999993\n",
      "reward_4: 0.032523352687085776\n",
      "reward_5: -0.007635148501216686\n",
      "reward_6: 0.3003333535194399\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 466\n",
      "episode was finished at timestep: 79\n",
      "reward: 8.76574518111901\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07849384347597758\n",
      "reward_2: 0.9215506071477757\n",
      "reward_3: 11.300000000000026\n",
      "reward_4: 0.006847585899314054\n",
      "reward_5: -0.005762222305914122\n",
      "reward_6: 0.2643213489055626\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 467\n",
      "episode was finished at timestep: 6\n",
      "reward: 8.754836915055197\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08594957192738852\n",
      "reward_2: 0.9303845133501539\n",
      "reward_3: 10.90000000000002\n",
      "reward_4: -0.0020090383283998393\n",
      "reward_5: -0.0029829284115173494\n",
      "reward_6: 0.2434131380319592\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 468\n",
      "episode was finished at timestep: 199\n",
      "reward: 8.999424182857348\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.03816492623753018\n",
      "reward_2: 0.9662736166398715\n",
      "reward_3: 12.500000000000043\n",
      "reward_4: -0.003279054187828336\n",
      "reward_5: -0.003321710766786386\n",
      "reward_6: 0.25895780110359257\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 469\n",
      "episode was finished at timestep: 246\n",
      "reward: 8.620109682749545\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08382928238974677\n",
      "reward_2: 0.908527740539218\n",
      "reward_3: 12.550000000000043\n",
      "reward_4: 0.002310188904853021\n",
      "reward_5: -0.009168897961260688\n",
      "reward_6: 0.2570725294351581\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 470\n",
      "episode was finished at timestep: 118\n",
      "reward: 7.847421359959773\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.11289062367545234\n",
      "reward_2: 0.809962886039358\n",
      "reward_3: 11.750000000000032\n",
      "reward_4: 0.0005106597571392513\n",
      "reward_5: -0.009389049929106719\n",
      "reward_6: 0.25856475317478267\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 471\n",
      "episode was finished at timestep: 121\n",
      "reward: 9.474676312551825\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.11454920371373495\n",
      "reward_2: 0.9856760449511668\n",
      "reward_3: 11.500000000000028\n",
      "reward_4: 0.028792195385487957\n",
      "reward_5: -0.007995159759816654\n",
      "reward_6: 0.250843012571335\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 472\n",
      "episode was finished at timestep: 193\n",
      "reward: 8.677922062943747\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.061557092269261676\n",
      "reward_2: 0.928521466420251\n",
      "reward_3: 12.800000000000047\n",
      "reward_4: -0.009514785109248436\n",
      "reward_5: -0.008994537225363903\n",
      "reward_6: 0.2715993907451617\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 473\n",
      "episode was finished at timestep: 59\n",
      "reward: 8.786626039711795\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.03089073101679484\n",
      "reward_2: 0.9473163448836612\n",
      "reward_3: 12.150000000000038\n",
      "reward_4: -0.005742073167917994\n",
      "reward_5: -0.009434498194397753\n",
      "reward_6: 0.23095563316345247\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 474\n",
      "episode was finished at timestep: 109\n",
      "reward: 8.475282600232433\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09697445299890306\n",
      "reward_2: 0.8927551805752509\n",
      "reward_3: 12.35000000000004\n",
      "reward_4: -0.004055552056374978\n",
      "reward_5: -0.007154324048607563\n",
      "reward_6: 0.27421877646446235\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 475\n",
      "episode was finished at timestep: 112\n",
      "reward: 8.438775590426157\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09206747081544664\n",
      "reward_2: 0.8846154825014694\n",
      "reward_3: 12.050000000000036\n",
      "reward_4: 0.0004904841180490393\n",
      "reward_5: -0.0058208164548601594\n",
      "reward_6: 0.2700745364427566\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 476\n",
      "episode was finished at timestep: 57\n",
      "reward: 8.393272312019297\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07934574948416816\n",
      "reward_2: 0.8866162989063309\n",
      "reward_3: 12.000000000000036\n",
      "reward_4: -0.005852778633587974\n",
      "reward_5: -0.005342246776826324\n",
      "reward_6: 0.27156064713001304\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 477\n",
      "episode was finished at timestep: 58\n",
      "reward: 8.820428460177768\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.051564894782172306\n",
      "reward_2: 0.942073517607545\n",
      "reward_3: 11.950000000000035\n",
      "reward_4: -0.004485808800739051\n",
      "reward_5: -0.0008481721339453685\n",
      "reward_6: 0.2674167337417599\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 478\n",
      "episode was finished at timestep: 28\n",
      "reward: 8.151169519784133\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08601578606499566\n",
      "reward_2: 0.8522956438607053\n",
      "reward_3: 11.150000000000023\n",
      "reward_4: -0.0026334998227738994\n",
      "reward_5: -0.0008402137967402486\n",
      "reward_6: 0.26721012854576054\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 479\n",
      "episode was finished at timestep: 133\n",
      "reward: 8.653760671387762\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07312138279279073\n",
      "reward_2: 0.8800721407053672\n",
      "reward_3: 11.000000000000021\n",
      "reward_4: 0.03355364966152109\n",
      "reward_5: -0.006066904656323284\n",
      "reward_6: 0.27623320364952075\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 480\n",
      "episode was finished at timestep: 180\n",
      "reward: 7.567277093192735\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.15382915801472133\n",
      "reward_2: 0.7578709547043657\n",
      "reward_3: 12.950000000000049\n",
      "reward_4: 0.009111305487977575\n",
      "reward_5: -0.0010464948244264841\n",
      "reward_6: 0.2769096817970276\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 481\n",
      "episode was finished at timestep: 212\n",
      "reward: 8.581712750297507\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.02385527359114753\n",
      "reward_2: 0.9059453005789034\n",
      "reward_3: 11.65000000000003\n",
      "reward_4: 0.007427777016082615\n",
      "reward_5: -0.009258878833205723\n",
      "reward_6: 0.25857840144634325\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 482\n",
      "episode was finished at timestep: 106\n",
      "reward: 8.10229972494902\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06662589377827115\n",
      "reward_2: 0.8521024015711571\n",
      "reward_3: 12.35000000000004\n",
      "reward_4: -0.0035776627927612027\n",
      "reward_5: -0.006137915007905074\n",
      "reward_6: 0.25196716928482077\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 483\n",
      "episode was finished at timestep: 135\n",
      "reward: 8.673723595097881\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.03546699417961968\n",
      "reward_2: 0.9218637308725419\n",
      "reward_3: 12.200000000000038\n",
      "reward_4: 0.0023964182077418172\n",
      "reward_5: -0.009359885781535956\n",
      "reward_6: 0.25190862739086106\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 484\n",
      "episode was finished at timestep: 132\n",
      "reward: 8.328878063469917\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10158074034584894\n",
      "reward_2: 0.8541855110514\n",
      "reward_3: 11.450000000000028\n",
      "reward_4: 0.014314255629783333\n",
      "reward_5: -0.00016349772399072056\n",
      "reward_6: 0.27793602073192647\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 485\n",
      "episode was finished at timestep: 166\n",
      "reward: 7.994399429123014\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07014763818846809\n",
      "reward_2: 0.8376178074164053\n",
      "reward_3: 11.65000000000003\n",
      "reward_4: -0.004508719704554664\n",
      "reward_5: -0.004121122765238165\n",
      "reward_6: 0.2619468786716459\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 486\n",
      "episode was finished at timestep: 64\n",
      "reward: 8.873987428050803\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.05970848533842299\n",
      "reward_2: 0.9257025908269798\n",
      "reward_3: 10.15000000000001\n",
      "reward_4: 0.021055408031648\n",
      "reward_5: -0.001934639581901602\n",
      "reward_6: 0.24079625809192662\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 487\n",
      "episode was finished at timestep: 164\n",
      "reward: 8.150880986129579\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.12541249593098958\n",
      "reward_2: 0.8187582630054369\n",
      "reward_3: 10.400000000000013\n",
      "reward_4: 0.03491410658943494\n",
      "reward_5: -0.01478639199322688\n",
      "reward_6: 0.20948925876617508\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 488\n",
      "episode was finished at timestep: 34\n",
      "reward: 6.903565759089538\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04626933799849616\n",
      "reward_2: 0.9398176846649957\n",
      "reward_3: 10.90000000000002\n",
      "reward_4: 0.005365460359423935\n",
      "reward_5: -0.006791042545680289\n",
      "reward_6: 0.301168970108032\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 489\n",
      "episode was finished at timestep: 159\n",
      "reward: 7.789830946341346\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07679356270366244\n",
      "reward_2: 0.816798010757305\n",
      "reward_3: 11.700000000000031\n",
      "reward_4: -0.013018963766230343\n",
      "reward_5: -0.0007504225220076914\n",
      "reward_6: 0.2819954302310944\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 490\n",
      "episode was finished at timestep: 100\n",
      "reward: 8.140572585592766\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09020338190926445\n",
      "reward_2: 0.8751466084717183\n",
      "reward_3: 12.750000000000046\n",
      "reward_4: -0.02204226912326078\n",
      "reward_5: -0.0006833550658752093\n",
      "reward_6: 0.22451784396171603\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 491\n",
      "episode was finished at timestep: 119\n",
      "reward: 7.795308050430437\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -7.298125161064996e-05\n",
      "reward_2: 0.7548744071561327\n",
      "reward_3: 8.499999999999986\n",
      "reward_4: -0.017682297733762196\n",
      "reward_5: 0.6179165919125826\n",
      "reward_6: 0.2787942310571674\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 492\n",
      "episode was finished at timestep: 120\n",
      "reward: 9.010428552163473\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04831721385320028\n",
      "reward_2: 0.9597656706065205\n",
      "reward_3: 12.000000000000036\n",
      "reward_4: 0.00486931794346134\n",
      "reward_5: -0.005509829116109799\n",
      "reward_6: 0.24894125902652775\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 493\n",
      "episode was finished at timestep: 166\n",
      "reward: 8.606487702974864\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10272627539104885\n",
      "reward_2: 0.9129495912680007\n",
      "reward_3: 11.150000000000023\n",
      "reward_4: -0.007750731941416262\n",
      "reward_5: -0.002203124508285252\n",
      "reward_6: 0.26288701081275834\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 494\n",
      "episode was finished at timestep: 82\n",
      "reward: 8.300058338096177\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.11034929421212938\n",
      "reward_2: 0.8692904622568438\n",
      "reward_3: 11.700000000000031\n",
      "reward_4: -0.0040301526393074025\n",
      "reward_5: -0.003379853964217953\n",
      "reward_6: 0.2694464209079741\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 495\n",
      "episode was finished at timestep: 85\n",
      "reward: 8.872454753177358\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09523479408688015\n",
      "reward_2: 0.9427387408959589\n",
      "reward_3: 11.500000000000028\n",
      "reward_4: -0.0018580051032938626\n",
      "reward_5: -0.0056282301200025605\n",
      "reward_6: 0.2542689695358271\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 496\n",
      "episode was finished at timestep: 89\n",
      "reward: 7.691006132644227\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.1179387927055359\n",
      "reward_2: 0.7931309026579818\n",
      "reward_3: 10.700000000000017\n",
      "reward_4: -0.005734687774190519\n",
      "reward_5: -0.0004598898668339994\n",
      "reward_6: 0.2729308440685273\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 497\n",
      "episode was finished at timestep: 233\n",
      "reward: 8.019572846342335\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.13029552499453226\n",
      "reward_2: 0.8281369654292041\n",
      "reward_3: 12.150000000000038\n",
      "reward_4: -0.00033151721741120355\n",
      "reward_5: -0.006959413574635912\n",
      "reward_6: 0.2721731492280961\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 498\n",
      "episode was finished at timestep: 198\n",
      "reward: 8.712247689164087\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.11125383509529961\n",
      "reward_2: 0.920009245787124\n",
      "reward_3: 12.30000000000004\n",
      "reward_4: -0.0031314605808015015\n",
      "reward_5: -0.0014333026361513864\n",
      "reward_6: 0.2657648750543594\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 499\n",
      "episode was finished at timestep: 17\n",
      "reward: -78.1123085791567\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.11350003216001722\n",
      "reward_2: -10\n",
      "reward_3: 10.800000000000018\n",
      "reward_4: 0.020880065433279357\n",
      "reward_5: 0.2737128570850646\n",
      "reward_6: 0.331998008131981\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 500\n",
      "episode was finished at timestep: 24\n",
      "reward: 8.661038182754947\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10852126545376248\n",
      "reward_2: 0.9239688546492356\n",
      "reward_3: 12.800000000000047\n",
      "reward_4: -0.015174386549819018\n",
      "reward_5: -0.0023852188207355834\n",
      "reward_6: 0.28283972465991947\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 501\n",
      "episode was finished at timestep: 240\n",
      "reward: 9.230302955092569\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09212509195009867\n",
      "reward_2: 0.9975735855687461\n",
      "reward_3: 12.150000000000038\n",
      "reward_4: -0.0064154801165039995\n",
      "reward_5: -0.006311669358295072\n",
      "reward_6: 0.21360468888282802\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 502\n",
      "episode was finished at timestep: 46\n",
      "reward: 7.727004515795654\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.003254058625962999\n",
      "reward_2: 0.7753150648833051\n",
      "reward_3: 9.900000000000006\n",
      "reward_4: -0.015572953122710089\n",
      "reward_5: 0.38334456940736733\n",
      "reward_6: 0.2676571109294893\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 503\n",
      "episode was finished at timestep: 179\n",
      "reward: 9.061516350014204\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07950120303365919\n",
      "reward_2: 0.9811632641870214\n",
      "reward_3: 12.35000000000004\n",
      "reward_4: -0.012120862478138008\n",
      "reward_5: -0.006920103622195721\n",
      "reward_6: 0.23494937026500706\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 504\n",
      "episode was finished at timestep: 42\n",
      "reward: 9.16435799955631\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0821292221546173\n",
      "reward_2: 0.9916599234473626\n",
      "reward_3: 12.100000000000037\n",
      "reward_4: -0.01398323328184432\n",
      "reward_5: -0.007408892423213113\n",
      "reward_6: 0.2666108151674267\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 505\n",
      "episode was finished at timestep: 33\n",
      "reward: 9.048642639333249\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0791821969879998\n",
      "reward_2: 0.9662475065334085\n",
      "reward_3: 11.400000000000027\n",
      "reward_4: -0.00282686110638096\n",
      "reward_5: -0.00796652645751384\n",
      "reward_6: 0.2685418053865435\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 506\n",
      "episode was finished at timestep: 77\n",
      "reward: 6.805941189697009\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07211355302068923\n",
      "reward_2: 0.9316408342581017\n",
      "reward_3: 11.60000000000003\n",
      "reward_4: -0.002253561870136309\n",
      "reward_5: -0.0016290127926097853\n",
      "reward_6: 0.2988118036985392\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 507\n",
      "episode was finished at timestep: 203\n",
      "reward: 7.60669716550952\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09063616196314493\n",
      "reward_2: 0.7725565510138461\n",
      "reward_3: 12.550000000000043\n",
      "reward_4: 0.008910028351487824\n",
      "reward_5: -0.007360338774074767\n",
      "reward_6: 0.27001537406444487\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 508\n",
      "episode was finished at timestep: 24\n",
      "reward: 8.951621358318562\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09948424895604452\n",
      "reward_2: 0.9447868635975644\n",
      "reward_3: 12.050000000000036\n",
      "reward_4: 0.0059346572136311695\n",
      "reward_5: -0.0008033839642690074\n",
      "reward_6: 0.2455616601705557\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 509\n",
      "episode was finished at timestep: 37\n",
      "reward: 7.210258047638584\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07930751045544943\n",
      "reward_2: 0.7243440421886544\n",
      "reward_3: 11.700000000000031\n",
      "reward_4: 0.012165880134338636\n",
      "reward_5: -0.0001685444695436189\n",
      "reward_6: 0.23747970306873434\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 510\n",
      "episode was finished at timestep: 209\n",
      "reward: 7.3008531560234795\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10100540982352363\n",
      "reward_2: 0.7505731842291194\n",
      "reward_3: 12.000000000000036\n",
      "reward_4: -0.009218201438531963\n",
      "reward_5: -0.005828698046322837\n",
      "reward_6: 0.27323658192157785\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 511\n",
      "episode was finished at timestep: 52\n",
      "reward: 7.256497510868965\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07877822783258226\n",
      "reward_2: 0.7568778799114674\n",
      "reward_3: 12.35000000000004\n",
      "reward_4: -0.014553371587228697\n",
      "reward_5: -0.00828635296085712\n",
      "reward_6: 0.24576290273666412\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 512\n",
      "episode was finished at timestep: 81\n",
      "reward: 6.6961908130912775\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.027787782748540244\n",
      "reward_2: 0.9293583876090319\n",
      "reward_3: 11.700000000000031\n",
      "reward_4: -0.006142143983328907\n",
      "reward_5: -0.004979321240287386\n",
      "reward_6: 0.2860924025774003\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 513\n",
      "episode was finished at timestep: 130\n",
      "reward: 7.576361995060513\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.03953736027081808\n",
      "reward_2: 0.7782919729617206\n",
      "reward_3: 10.90000000000002\n",
      "reward_4: 0.013756269523518654\n",
      "reward_5: -0.004502313257895097\n",
      "reward_6: 0.20348767483234387\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 514\n",
      "episode was finished at timestep: 145\n",
      "reward: 8.365345897553532\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06737364331881206\n",
      "reward_2: 0.8947662435558726\n",
      "reward_3: 11.300000000000026\n",
      "reward_4: -0.016866407254802027\n",
      "reward_5: -0.004144969266979833\n",
      "reward_6: 0.277411866426468\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 515\n",
      "episode was finished at timestep: 148\n",
      "reward: 8.9020698891965\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.046236972676383124\n",
      "reward_2: 0.9613204696869385\n",
      "reward_3: 11.55000000000003\n",
      "reward_4: -0.012469202558234116\n",
      "reward_5: -0.005926398051249985\n",
      "reward_6: 0.269409177541733\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 516\n",
      "episode was finished at timestep: 206\n",
      "reward: 9.229486030474298\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08220009869999356\n",
      "reward_2: 0.9776053212756972\n",
      "reward_3: 11.55000000000003\n",
      "reward_4: 0.009020285784133933\n",
      "reward_5: -0.0026286090429142204\n",
      "reward_6: 0.25536968433857\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 517\n",
      "episode was finished at timestep: 167\n",
      "reward: 8.86866613949072\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04176736937628852\n",
      "reward_2: 0.9385946333698115\n",
      "reward_3: 10.650000000000016\n",
      "reward_4: 0.007405156389151984\n",
      "reward_5: -0.008856756347512847\n",
      "reward_6: 0.26633720839023645\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 518\n",
      "episode was finished at timestep: 68\n",
      "reward: 8.457833255485882\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.060554626252916126\n",
      "reward_2: 0.8987526082058658\n",
      "reward_3: 10.95000000000002\n",
      "reward_4: -0.007616695927597306\n",
      "reward_5: -0.0038985335666609443\n",
      "reward_6: 0.2706298645734787\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 519\n",
      "episode was finished at timestep: 205\n",
      "reward: 8.718180654521781\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07689353293842739\n",
      "reward_2: 0.9240305004721829\n",
      "reward_3: 12.250000000000039\n",
      "reward_4: 0.00038090098706220485\n",
      "reward_5: -0.005665020016843059\n",
      "reward_6: 0.25002759659290286\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 520\n",
      "episode was finished at timestep: 191\n",
      "reward: 7.0019423238940215\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.00492187672191196\n",
      "reward_2: 0.7177623178761531\n",
      "reward_3: 10.85000000000002\n",
      "reward_4: 0.012164861267677053\n",
      "reward_5: 0.039581477231997654\n",
      "reward_6: 0.12641862356662836\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 521\n",
      "episode was finished at timestep: 106\n",
      "reward: 8.06989586651814\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07655622561772664\n",
      "reward_2: 0.830483018485832\n",
      "reward_3: 11.150000000000023\n",
      "reward_4: 0.010022904755387146\n",
      "reward_5: -0.0017810555110453188\n",
      "reward_6: 0.26958664381504005\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 522\n",
      "episode was finished at timestep: 80\n",
      "reward: 8.854218133045663\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06289121641053094\n",
      "reward_2: 0.9422884719587667\n",
      "reward_3: 11.100000000000023\n",
      "reward_4: -0.0022722269980982902\n",
      "reward_5: -0.009172314309525476\n",
      "reward_6: 0.2788892712593093\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 523\n",
      "episode was finished at timestep: 146\n",
      "reward: 9.454945119783789\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.12968978550699023\n",
      "reward_2: 0.9968576833499073\n",
      "reward_3: 10.85000000000002\n",
      "reward_4: 0.017077212524089162\n",
      "reward_5: -0.0022681831691860072\n",
      "reward_6: 0.21459768378734623\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 524\n",
      "episode was finished at timestep: 77\n",
      "reward: 7.808716763370689\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.17176613873905605\n",
      "reward_2: 0.7676309821324729\n",
      "reward_3: 10.750000000000018\n",
      "reward_4: 0.036341187568942675\n",
      "reward_5: -0.008123171848532824\n",
      "reward_6: 0.21186310553550758\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 525\n",
      "episode was finished at timestep: 73\n",
      "reward: 7.856608237064457\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.1349360293812222\n",
      "reward_2: 0.7912431452629047\n",
      "reward_3: 11.400000000000027\n",
      "reward_4: 0.021382207171947273\n",
      "reward_5: -0.008232280720865978\n",
      "reward_6: 0.22738166892528555\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 526\n",
      "episode was finished at timestep: 128\n",
      "reward: 8.702577284808779\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.13653644190894232\n",
      "reward_2: 0.889617823567215\n",
      "reward_3: 10.90000000000002\n",
      "reward_4: 0.026114497654254762\n",
      "reward_5: -0.003311388827118004\n",
      "reward_6: 0.2420403286218642\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 527\n",
      "episode was finished at timestep: 94\n",
      "reward: 8.737591918642202\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10179925097359552\n",
      "reward_2: 0.9025640673402936\n",
      "reward_3: 11.300000000000026\n",
      "reward_4: 0.022690010746459707\n",
      "reward_5: -0.004099989709428087\n",
      "reward_6: 0.2363533660173417\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 528\n",
      "episode was finished at timestep: 120\n",
      "reward: 8.401042011394487\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08319302068816291\n",
      "reward_2: 0.8655168546894612\n",
      "reward_3: 11.900000000000034\n",
      "reward_4: 0.01841808185334983\n",
      "reward_5: -0.007332614870365243\n",
      "reward_6: 0.2521154465675357\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 529\n",
      "episode was finished at timestep: 86\n",
      "reward: 8.928574507569031\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.12358737720383538\n",
      "reward_2: 0.9387474832029511\n",
      "reward_3: 11.100000000000023\n",
      "reward_4: 0.007724368905560937\n",
      "reward_5: -0.005831899421181082\n",
      "reward_6: 0.237564212918281\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 530\n",
      "episode was finished at timestep: 54\n",
      "reward: 9.088773592505099\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06858597993850708\n",
      "reward_2: 0.983494689176187\n",
      "reward_3: 12.000000000000036\n",
      "reward_4: -0.0034092994040484824\n",
      "reward_5: -0.008353826061298857\n",
      "reward_6: 0.18625832045078272\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 531\n",
      "episode was finished at timestep: 85\n",
      "reward: 9.3157952719589\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.15402414798736572\n",
      "reward_2: 0.9826745081897366\n",
      "reward_3: 10.90000000000002\n",
      "reward_4: 0.006707928197120055\n",
      "reward_5: -0.0011386327009523948\n",
      "reward_6: 0.24639693224430015\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 532\n",
      "episode was finished at timestep: 18\n",
      "reward: 8.72389908103973\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.1862145443757375\n",
      "reward_2: 0.8865794636829847\n",
      "reward_3: 11.65000000000003\n",
      "reward_4: 0.026311759975245933\n",
      "reward_5: -0.011333696361134097\n",
      "reward_6: 0.24433511042594946\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 533\n",
      "episode was finished at timestep: 148\n",
      "reward: 8.925121715171915\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.15072110229068333\n",
      "reward_2: 0.9265564238667455\n",
      "reward_3: 11.050000000000022\n",
      "reward_4: 0.01761806590409705\n",
      "reward_5: -0.006662258227720604\n",
      "reward_6: 0.22619361960887896\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 534\n",
      "episode was finished at timestep: 200\n",
      "reward: 9.321695936857921\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.19978826377126907\n",
      "reward_2: 0.9535399847611117\n",
      "reward_3: 11.050000000000022\n",
      "reward_4: 0.04386213593249494\n",
      "reward_5: -0.0010119041215683447\n",
      "reward_6: 0.14222927832603383\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 535\n",
      "episode was finished at timestep: 153\n",
      "reward: 6.995925100315261\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.17224724888801574\n",
      "reward_2: 0.6626368726622253\n",
      "reward_3: 11.100000000000023\n",
      "reward_4: 0.03495504100331161\n",
      "reward_5: -0.00642634267984062\n",
      "reward_6: 0.2478888847827907\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 536\n",
      "episode was finished at timestep: 88\n",
      "reward: 9.42991575274988\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08219585948520236\n",
      "reward_2: 0.9926241773016743\n",
      "reward_3: 11.800000000000033\n",
      "reward_4: 0.0167542135617434\n",
      "reward_5: -0.0033156600212328395\n",
      "reward_6: 0.27443509304523483\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 537\n",
      "episode was finished at timestep: 35\n",
      "reward: 8.185117003375266\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.14829262163903978\n",
      "reward_2: 0.8290620533730785\n",
      "reward_3: 11.500000000000028\n",
      "reward_4: 0.023488582994365004\n",
      "reward_5: -0.007324662820734199\n",
      "reward_6: 0.2222106202840809\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 538\n",
      "episode was finished at timestep: 163\n",
      "reward: 6.791643163889045\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.041124391555786136\n",
      "reward_2: 0.6731739120859\n",
      "reward_3: 10.85000000000002\n",
      "reward_4: 0.012951875357370142\n",
      "reward_5: -0.011051514178717763\n",
      "reward_6: 0.2711173202991488\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 539\n",
      "episode was finished at timestep: 197\n",
      "reward: 8.065201287008364\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.03201378517680698\n",
      "reward_2: 0.8229684017062004\n",
      "reward_3: 11.450000000000028\n",
      "reward_4: 0.026230634924751684\n",
      "reward_5: -0.003779944187008866\n",
      "reward_6: 0.24184848630428302\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 540\n",
      "episode was finished at timestep: 15\n",
      "reward: 7.208476297317111\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.018854837947421602\n",
      "reward_2: 0.7465015115953527\n",
      "reward_3: 12.100000000000037\n",
      "reward_4: -0.0023894706721422666\n",
      "reward_5: -0.007543390625068488\n",
      "reward_6: 0.24265518927574126\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 541\n",
      "episode was finished at timestep: 209\n",
      "reward: 7.781572482850117\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.001565972301695082\n",
      "reward_2: 0.7915315515664498\n",
      "reward_3: 11.100000000000023\n",
      "reward_4: 0.026971730670444317\n",
      "reward_5: 0.0033817979055385194\n",
      "reward_6: 0.2302503993511198\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 542\n",
      "episode was finished at timestep: 116\n",
      "reward: 6.944061893003056\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0029701458083258737\n",
      "reward_2: 0.6747589039587443\n",
      "reward_3: 11.350000000000026\n",
      "reward_4: -0.004376217282908356\n",
      "reward_5: 0.3187098141717338\n",
      "reward_6: 0.2637473978996274\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 543\n",
      "episode was finished at timestep: 48\n",
      "reward: 7.988220483619893\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.01384240256415473\n",
      "reward_2: 0.8086769509904208\n",
      "reward_3: 11.750000000000032\n",
      "reward_4: 0.03325453642138726\n",
      "reward_5: -0.007161307907254392\n",
      "reward_6: 0.2445208230018613\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 544\n",
      "episode was finished at timestep: 187\n",
      "reward: 8.431055168570959\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0405143744415707\n",
      "reward_2: 0.8784504322413443\n",
      "reward_3: 12.200000000000038\n",
      "reward_4: 0.012400500395879987\n",
      "reward_5: -0.0051348744246767575\n",
      "reward_6: 0.26724154078960294\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 545\n",
      "episode was finished at timestep: 120\n",
      "reward: 9.066372948607604\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0307361728615231\n",
      "reward_2: 0.9661436957119898\n",
      "reward_3: 11.750000000000032\n",
      "reward_4: 0.004022590371751562\n",
      "reward_5: -0.009022943090728219\n",
      "reward_6: 0.2817627635002129\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 546\n",
      "episode was finished at timestep: 84\n",
      "reward: 6.47071251894919\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.049235291613472836\n",
      "reward_2: 0.6367390861769422\n",
      "reward_3: 12.650000000000045\n",
      "reward_4: 0.00787255984181897\n",
      "reward_5: -0.00723112963870823\n",
      "reward_6: 0.2701285221576686\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 547\n",
      "episode was finished at timestep: 96\n",
      "reward: 5.185307537875508\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0018234623803032768\n",
      "reward_2: 0.7349663971689083\n",
      "reward_3: 13.550000000000058\n",
      "reward_4: -0.006485781186764825\n",
      "reward_5: 0.06668409833415355\n",
      "reward_6: 0.29079530739784276\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 548\n",
      "episode was finished at timestep: 143\n",
      "reward: 7.122174895667976\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.058745733234617445\n",
      "reward_2: 0.9453456705516828\n",
      "reward_3: 11.65000000000003\n",
      "reward_4: 0.02667667531288771\n",
      "reward_5: -0.006444572876850193\n",
      "reward_6: 0.2921416350603102\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 549\n",
      "episode was finished at timestep: 129\n",
      "reward: 9.227259220942086\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06045930253134833\n",
      "reward_2: 0.9696304633974842\n",
      "reward_3: 11.400000000000027\n",
      "reward_4: 0.01902305718943623\n",
      "reward_5: -0.0017666086398585652\n",
      "reward_6: 0.2578183623552328\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 550\n",
      "episode was finished at timestep: 105\n",
      "reward: 8.208011108375878\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07747733990351359\n",
      "reward_2: 0.8376837746226482\n",
      "reward_3: 11.200000000000024\n",
      "reward_4: 0.02534500279725961\n",
      "reward_5: -0.004871421745791101\n",
      "reward_6: 0.22968163752555903\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 551\n",
      "episode was finished at timestep: 51\n",
      "reward: 8.2209689877038\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10104214284155104\n",
      "reward_2: 0.8278835058352845\n",
      "reward_3: 12.400000000000041\n",
      "reward_4: 0.030222844982092455\n",
      "reward_5: -0.008478982036124568\n",
      "reward_6: 0.26190168702602445\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 552\n",
      "episode was finished at timestep: 102\n",
      "reward: 8.758729186643066\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0838697161939409\n",
      "reward_2: 0.884663695753088\n",
      "reward_3: 13.400000000000055\n",
      "reward_4: 0.04390967248718838\n",
      "reward_5: -0.01029724882443664\n",
      "reward_6: 0.2547831066846846\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 553\n",
      "episode was finished at timestep: 168\n",
      "reward: 8.707354767947525\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.14355601204766166\n",
      "reward_2: 0.867799685382327\n",
      "reward_3: 11.500000000000028\n",
      "reward_4: 0.04875145468809791\n",
      "reward_5: -0.008069165130390844\n",
      "reward_6: 0.23792546713352203\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 554\n",
      "episode was finished at timestep: 69\n",
      "reward: 9.355210990062606\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.05241604248682658\n",
      "reward_2: 0.9921214166126028\n",
      "reward_3: 11.450000000000028\n",
      "reward_4: 0.01348099133651587\n",
      "reward_5: -0.007827564924896535\n",
      "reward_6: 0.2642765822410581\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 555\n",
      "episode was finished at timestep: 28\n",
      "reward: 8.568378797867533\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0694383356306288\n",
      "reward_2: 0.8954071006438928\n",
      "reward_3: 13.200000000000053\n",
      "reward_4: 0.00871135301809943\n",
      "reward_5: -0.00014658042535321177\n",
      "reward_6: 0.2643794133663184\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 556\n",
      "episode was finished at timestep: 48\n",
      "reward: 8.540760216694874\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.16272570689519247\n",
      "reward_2: 0.8546177327009058\n",
      "reward_3: 12.000000000000036\n",
      "reward_4: 0.04230816379462766\n",
      "reward_5: -0.013895262791531356\n",
      "reward_6: 0.21492260062694535\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 557\n",
      "episode was finished at timestep: 214\n",
      "reward: 8.318577331102668\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08730094697740343\n",
      "reward_2: 0.8537498135112387\n",
      "reward_3: 13.250000000000053\n",
      "reward_4: 0.017330618320565774\n",
      "reward_5: -0.0028008196247685173\n",
      "reward_6: 0.26366708242893144\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 558\n",
      "episode was finished at timestep: 42\n",
      "reward: 8.849132238750084\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.084894773695204\n",
      "reward_2: 0.908623533553919\n",
      "reward_3: 13.350000000000055\n",
      "reward_4: 0.03064257104338438\n",
      "reward_5: -0.011178842092886044\n",
      "reward_6: 0.25950747036933963\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 559\n",
      "episode was finished at timestep: 166\n",
      "reward: 8.162474738102253\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.1144274804327223\n",
      "reward_2: 0.8643756208840708\n",
      "reward_3: 11.950000000000035\n",
      "reward_4: -0.018303335183351664\n",
      "reward_5: -0.0009757764268741198\n",
      "reward_6: 0.27885141515731837\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 560\n",
      "episode was finished at timestep: 200\n",
      "reward: 9.207020789266778\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.12348281542460124\n",
      "reward_2: 0.9765839039829618\n",
      "reward_3: 13.05000000000005\n",
      "reward_4: -0.0013255484845893762\n",
      "reward_5: -0.0014357874688699943\n",
      "reward_6: 0.28116691732406573\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 561\n",
      "episode was finished at timestep: 193\n",
      "reward: 9.207308099914803\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10225154161453247\n",
      "reward_2: 0.9944680749877775\n",
      "reward_3: 13.150000000000052\n",
      "reward_4: -0.015325982650710586\n",
      "reward_5: -0.0013883798051136154\n",
      "reward_6: 0.27155486607551615\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 562\n",
      "episode was finished at timestep: 79\n",
      "reward: 6.095372275763746\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.010175863901774088\n",
      "reward_2: 0.6302910610401475\n",
      "reward_3: 12.200000000000038\n",
      "reward_4: -0.03196813876424301\n",
      "reward_5: 0.048101479253019976\n",
      "reward_6: 0.26923661553859746\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 563\n",
      "episode was finished at timestep: 185\n",
      "reward: 9.394053365917252\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.11748306287659539\n",
      "reward_2: 0.9971729275036548\n",
      "reward_3: 11.450000000000028\n",
      "reward_4: 0.004885456930727088\n",
      "reward_5: -0.0009063195742031146\n",
      "reward_6: 0.2594828804731373\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 564\n",
      "episode was finished at timestep: 45\n",
      "reward: 8.36803038523723\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04794809818267822\n",
      "reward_2: 0.9186030054913973\n",
      "reward_3: 12.800000000000047\n",
      "reward_4: -0.035663896550653364\n",
      "reward_5: -0.0034542254203306774\n",
      "reward_6: 0.25831697428226463\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 565\n",
      "episode was finished at timestep: 1\n",
      "reward: 8.716151321210996\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04698532025019328\n",
      "reward_2: 0.9205053571539679\n",
      "reward_3: 12.450000000000042\n",
      "reward_4: 0.004677790041609029\n",
      "reward_5: -0.0077660968938069175\n",
      "reward_6: 0.27380692028999387\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 566\n",
      "episode was finished at timestep: 192\n",
      "reward: 8.53725888212886\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.05432490242852105\n",
      "reward_2: 0.887175975316943\n",
      "reward_3: 11.750000000000032\n",
      "reward_4: 0.01669060371688033\n",
      "reward_5: -0.007739561852616224\n",
      "reward_6: 0.2581742426157009\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 567\n",
      "episode was finished at timestep: 80\n",
      "reward: 8.501616016285936\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.05211267272631327\n",
      "reward_2: 0.8817241060245713\n",
      "reward_3: 12.600000000000044\n",
      "reward_4: 0.01633611407013788\n",
      "reward_5: -0.004973438236104973\n",
      "reward_6: 0.26831502103805493\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 568\n",
      "episode was finished at timestep: 2\n",
      "reward: 6.728317630795107\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07586000760396322\n",
      "reward_2: 0.9079775310843953\n",
      "reward_3: 12.150000000000038\n",
      "reward_4: 0.013721530597662622\n",
      "reward_5: -0.0026817958052893923\n",
      "reward_6: 0.27992692553997045\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 569\n",
      "episode was finished at timestep: 108\n",
      "reward: 8.756718281117701\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.03532452583312988\n",
      "reward_2: 0.9326310349425249\n",
      "reward_3: 13.250000000000053\n",
      "reward_4: 0.0011391657649546972\n",
      "reward_5: -0.0013956017415632496\n",
      "reward_6: 0.2508610846996304\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 570\n",
      "episode was finished at timestep: 67\n",
      "reward: 8.26147698366134\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.05375044478310479\n",
      "reward_2: 0.8525270714873479\n",
      "reward_3: 12.450000000000042\n",
      "reward_4: 0.01638613144191723\n",
      "reward_5: -0.002189191415091566\n",
      "reward_6: 0.2569501068592077\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 571\n",
      "episode was finished at timestep: 106\n",
      "reward: 9.081515223565805\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.05949096745914883\n",
      "reward_2: 0.9537841238059785\n",
      "reward_3: 12.200000000000038\n",
      "reward_4: 0.01819911643315237\n",
      "reward_5: -0.008142117801921837\n",
      "reward_6: 0.25267378532886464\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 572\n",
      "episode was finished at timestep: 51\n",
      "reward: 8.81826424412292\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.00837122533056471\n",
      "reward_2: 0.9290396644427175\n",
      "reward_3: 12.30000000000004\n",
      "reward_4: 0.021452720176479544\n",
      "reward_5: -0.0033625054335214345\n",
      "reward_6: 0.2076764472723015\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 573\n",
      "episode was finished at timestep: 40\n",
      "reward: 7.967632987427689\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.031145201126734415\n",
      "reward_2: 0.8281978283430241\n",
      "reward_3: 11.350000000000026\n",
      "reward_4: 0.0075845807276716925\n",
      "reward_5: -0.0046878951737730525\n",
      "reward_6: 0.2534030755758281\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 574\n",
      "episode was finished at timestep: 67\n",
      "reward: 8.413988290052473\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07831261489126418\n",
      "reward_2: 0.8668041388186556\n",
      "reward_3: 11.100000000000023\n",
      "reward_4: 0.021088516636037013\n",
      "reward_5: -0.008360935364379192\n",
      "reward_6: 0.23941536688804665\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 575\n",
      "episode was finished at timestep: 145\n",
      "reward: 8.09633010213206\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08281149003240797\n",
      "reward_2: 0.8348260691859004\n",
      "reward_3: 11.250000000000025\n",
      "reward_4: 0.014250674552276764\n",
      "reward_5: -0.011540478763598235\n",
      "reward_6: 0.23094514095783258\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 576\n",
      "episode was finished at timestep: 228\n",
      "reward: 8.025938984339437\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.037070031298531425\n",
      "reward_2: 0.8327250338607671\n",
      "reward_3: 12.000000000000036\n",
      "reward_4: 0.0061643025686856845\n",
      "reward_5: -0.00032181428239705194\n",
      "reward_6: 0.27647607588767975\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 577\n",
      "episode was finished at timestep: 185\n",
      "reward: 5.738213704788375\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0042110456360710995\n",
      "reward_2: 0.7480682854633975\n",
      "reward_3: 9.600000000000001\n",
      "reward_4: -0.014767262531815248\n",
      "reward_5: 0.5773567672481624\n",
      "reward_6: 0.29737979972362527\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 578\n",
      "episode was finished at timestep: 30\n",
      "reward: 8.29390286978023\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.056223776605394155\n",
      "reward_2: 0.8633897108953829\n",
      "reward_3: 12.450000000000042\n",
      "reward_4: 0.008895820296611418\n",
      "reward_5: -0.0029457629647411682\n",
      "reward_6: 0.2606806066036217\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 579\n",
      "episode was finished at timestep: 208\n",
      "reward: 7.958044203273678\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04321153826183743\n",
      "reward_2: 0.8249082356971226\n",
      "reward_3: 12.650000000000045\n",
      "reward_4: 0.007132901065280067\n",
      "reward_5: -0.004801835358996342\n",
      "reward_6: 0.26161873960494897\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 580\n",
      "episode was finished at timestep: 42\n",
      "reward: 7.965490244733469\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04867791864607069\n",
      "reward_2: 0.8241635446518518\n",
      "reward_3: 12.700000000000045\n",
      "reward_4: 0.007929596996032587\n",
      "reward_5: -0.0054626442923459235\n",
      "reward_6: 0.2638365038633351\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 581\n",
      "episode was finished at timestep: 106\n",
      "reward: 9.19883491434044\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06938549611303542\n",
      "reward_2: 0.9706723588997848\n",
      "reward_3: 12.550000000000043\n",
      "reward_4: 0.015644539043022262\n",
      "reward_5: -0.004545084118205148\n",
      "reward_6: 0.24178598546981878\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 582\n",
      "episode was finished at timestep: 190\n",
      "reward: 7.459166997105892\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.038493003447850546\n",
      "reward_2: 0.7654436070676265\n",
      "reward_3: 12.400000000000041\n",
      "reward_4: 0.006083394002915838\n",
      "reward_5: -0.0015237123734664238\n",
      "reward_6: 0.24832836413383563\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 583\n",
      "episode was finished at timestep: 92\n",
      "reward: 9.124517347075727\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10281330876880222\n",
      "reward_2: 0.955372558235377\n",
      "reward_3: 13.05000000000005\n",
      "reward_4: 0.01662047996899403\n",
      "reward_5: -0.005538800400515598\n",
      "reward_6: 0.24955853307247222\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 584\n",
      "episode was finished at timestep: 179\n",
      "reward: 7.449176684950441\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0619404759671953\n",
      "reward_2: 0.7604024617723298\n",
      "reward_3: 12.950000000000049\n",
      "reward_4: 0.005897794265312371\n",
      "reward_5: -0.004731680374397129\n",
      "reward_6: 0.25983917438983894\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 585\n",
      "episode was finished at timestep: 211\n",
      "reward: 8.143828349574981\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10481332739194234\n",
      "reward_2: 0.8478104846701271\n",
      "reward_3: 13.00000000000005\n",
      "reward_4: -0.001275807017187276\n",
      "reward_5: -2.9530233959936443e-05\n",
      "reward_6: 0.2650337978601468\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 586\n",
      "episode was finished at timestep: 120\n",
      "reward: 6.391508430588041\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10863111747635736\n",
      "reward_2: 0.6065723858045786\n",
      "reward_3: 11.800000000000033\n",
      "reward_4: 0.025256670806313934\n",
      "reward_5: -0.009924948590775766\n",
      "reward_6: 0.23659647548198615\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 587\n",
      "episode was finished at timestep: 73\n",
      "reward: 8.70560245651854\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.05345318979687161\n",
      "reward_2: 0.9203556521298648\n",
      "reward_3: 12.550000000000043\n",
      "reward_4: 0.0035062723773819473\n",
      "reward_5: -0.002611819494514833\n",
      "reward_6: 0.26219235682487496\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 588\n",
      "episode was finished at timestep: 32\n",
      "reward: 7.3886824246891365\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.05923441317346361\n",
      "reward_2: 0.744806627817028\n",
      "reward_3: 12.30000000000004\n",
      "reward_4: 0.0163400376970516\n",
      "reward_5: -0.00799845506827701\n",
      "reward_6: 0.24663314247131307\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 589\n",
      "episode was finished at timestep: 77\n",
      "reward: 6.998737799377711\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06392381853527493\n",
      "reward_2: 0.7002333496150269\n",
      "reward_3: 12.600000000000044\n",
      "reward_4: 0.011298696896687659\n",
      "reward_5: -0.003961423782064936\n",
      "reward_6: 0.24483903253078476\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 590\n",
      "episode was finished at timestep: 133\n",
      "reward: 7.324121879327025\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08368438482284546\n",
      "reward_2: 0.735829585308179\n",
      "reward_3: 12.800000000000047\n",
      "reward_4: 0.01076391737120801\n",
      "reward_5: -0.008525006693629322\n",
      "reward_6: 0.274507813096047\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 591\n",
      "episode was finished at timestep: 34\n",
      "reward: 8.3443773275818\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09236353172196282\n",
      "reward_2: 0.8589354036221465\n",
      "reward_3: 12.000000000000036\n",
      "reward_4: 0.018698796034794612\n",
      "reward_5: -0.003270631702699589\n",
      "reward_6: 0.2326108303070068\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 592\n",
      "episode was finished at timestep: 1\n",
      "reward: 9.047743451955153\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07602261238627964\n",
      "reward_2: 0.9602974354863143\n",
      "reward_3: 11.900000000000034\n",
      "reward_4: 0.0029265909158733903\n",
      "reward_5: -0.00829359799337285\n",
      "reward_6: 0.2726355596780773\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 593\n",
      "episode was finished at timestep: 142\n",
      "reward: 9.110639648151922\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06220614843898349\n",
      "reward_2: 0.9665134716323305\n",
      "reward_3: 13.250000000000053\n",
      "reward_4: 0.006356085747170965\n",
      "reward_5: -0.007851016389671747\n",
      "reward_6: 0.27156139039993354\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 594\n",
      "episode was finished at timestep: 150\n",
      "reward: 8.914968477886704\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07666287488407558\n",
      "reward_2: 0.9334369883715894\n",
      "reward_3: 12.850000000000048\n",
      "reward_4: 0.012184462049006584\n",
      "reward_5: -0.003819242438376591\n",
      "reward_6: 0.2754399087429047\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 595\n",
      "episode was finished at timestep: 77\n",
      "reward: 8.582624399655407\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.05530954996744792\n",
      "reward_2: 0.8998184577086679\n",
      "reward_3: 12.650000000000045\n",
      "reward_4: 0.008371034401749996\n",
      "reward_5: -0.006635215657856955\n",
      "reward_6: 0.2667474617958061\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 596\n",
      "episode was finished at timestep: 147\n",
      "reward: 9.027112816087744\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10018790894084506\n",
      "reward_2: 0.9547184662978351\n",
      "reward_3: 13.900000000000063\n",
      "reward_4: 0.0034832414737765304\n",
      "reward_5: -0.007006513327092871\n",
      "reward_6: 0.26646442496776634\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 597\n",
      "episode was finished at timestep: 42\n",
      "reward: 8.475558125267824\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.049251288175582886\n",
      "reward_2: 0.9007559065373627\n",
      "reward_3: 12.600000000000044\n",
      "reward_4: -0.004912811328761819\n",
      "reward_5: -0.0015873749311399621\n",
      "reward_6: 0.25946945035457536\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 598\n",
      "episode was finished at timestep: 114\n",
      "reward: 8.703701068189634\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07502969966994391\n",
      "reward_2: 0.9198441336654948\n",
      "reward_3: 13.450000000000056\n",
      "reward_4: -0.0004254723949833306\n",
      "reward_5: -0.005955705556424817\n",
      "reward_6: 0.27748445057869\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 599\n",
      "episode was finished at timestep: 154\n",
      "reward: 8.629447139329002\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09982949097951253\n",
      "reward_2: 0.8993449155342598\n",
      "reward_3: 12.100000000000037\n",
      "reward_4: 0.010879403807458346\n",
      "reward_5: -0.006617111827954503\n",
      "reward_6: 0.2528268721103658\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 600\n",
      "episode was finished at timestep: 171\n",
      "reward: 9.272640778207277\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.15500657161076864\n",
      "reward_2: 0.9610003025156775\n",
      "reward_3: 11.350000000000026\n",
      "reward_4: 0.022272742004598882\n",
      "reward_5: -0.001856170315111901\n",
      "reward_6: 0.2517926874160761\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 601\n",
      "episode was finished at timestep: 213\n",
      "reward: 9.019321024354825\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10289634201261733\n",
      "reward_2: 0.9521096822876544\n",
      "reward_3: 13.550000000000058\n",
      "reward_4: 0.0047177047753261545\n",
      "reward_5: -0.004458630519502312\n",
      "reward_6: 0.26445754969119917\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 602\n",
      "episode was finished at timestep: 36\n",
      "reward: 8.906115484484118\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.025891205337312487\n",
      "reward_2: 0.96301464997239\n",
      "reward_3: 12.850000000000048\n",
      "reward_4: -0.012153682178970086\n",
      "reward_5: -1.2453129115523136e-05\n",
      "reward_6: 0.2716356565952288\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 603\n",
      "episode was finished at timestep: 128\n",
      "reward: 7.630314823904045\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07903974056243897\n",
      "reward_2: 0.7779027624011651\n",
      "reward_3: 12.450000000000042\n",
      "reward_4: 0.008430646305409083\n",
      "reward_5: -0.0022836226827908017\n",
      "reward_6: 0.26123143637180346\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 604\n",
      "episode was finished at timestep: 199\n",
      "reward: 9.226742827589225\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06577827864223057\n",
      "reward_2: 0.9835241579101076\n",
      "reward_3: 13.250000000000053\n",
      "reward_4: 0.0036855856156419974\n",
      "reward_5: -0.006975216968606783\n",
      "reward_6: 0.2684951510429382\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 605\n",
      "episode was finished at timestep: 206\n",
      "reward: 7.4229211799181245\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.12250918745994568\n",
      "reward_2: 0.743194680855116\n",
      "reward_3: 12.150000000000038\n",
      "reward_4: 0.010722735358577325\n",
      "reward_5: -0.009254999237719256\n",
      "reward_6: 0.276707661986351\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 606\n",
      "episode was finished at timestep: 232\n",
      "reward: 8.953958441486238\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08776755465401544\n",
      "reward_2: 0.9393636768575717\n",
      "reward_3: 12.35000000000004\n",
      "reward_4: 0.011044604931425823\n",
      "reward_5: -0.006608177115556065\n",
      "reward_6: 0.26788614296913216\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 607\n",
      "episode was finished at timestep: 38\n",
      "reward: 9.357839151221473\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08347000413470798\n",
      "reward_2: 0.9970566917447815\n",
      "reward_3: 12.200000000000038\n",
      "reward_4: 0.005206173578093854\n",
      "reward_5: -0.009831519128238734\n",
      "reward_6: 0.2644710769653328\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 608\n",
      "episode was finished at timestep: 136\n",
      "reward: 9.732936987727822\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.2604525950219896\n",
      "reward_2: 0.9772021100569486\n",
      "reward_3: 10.95000000000002\n",
      "reward_4: 0.0520227734314193\n",
      "reward_5: -0.009618380616836694\n",
      "reward_6: 0.24684370541572576\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 609\n",
      "episode was finished at timestep: 127\n",
      "reward: 8.712394194171436\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04461709327167935\n",
      "reward_2: 0.9283461008031401\n",
      "reward_3: 13.100000000000051\n",
      "reward_4: -0.003997326267168262\n",
      "reward_5: -0.0021653052628071378\n",
      "reward_6: 0.27340554320812305\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 610\n",
      "episode was finished at timestep: 206\n",
      "reward: 8.309216212621694\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08111759887801276\n",
      "reward_2: 0.8755643818565388\n",
      "reward_3: 12.100000000000037\n",
      "reward_4: -0.0033186255905593496\n",
      "reward_5: -0.008792556369099458\n",
      "reward_6: 0.25731178665161203\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 611\n",
      "episode was finished at timestep: 240\n",
      "reward: 8.40748203334613\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07827636930677626\n",
      "reward_2: 0.8805843078504342\n",
      "reward_3: 12.250000000000039\n",
      "reward_4: 0.004937109304046885\n",
      "reward_5: -0.004217400070211023\n",
      "reward_6: 0.2476183935403825\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 612\n",
      "episode was finished at timestep: 204\n",
      "reward: 8.383587336177843\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.055788756741417776\n",
      "reward_2: 0.8784809322570126\n",
      "reward_3: 13.650000000000059\n",
      "reward_4: 0.004095761832461591\n",
      "reward_5: -0.0023527247823598905\n",
      "reward_6: 0.26771775150299093\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 613\n",
      "episode was finished at timestep: 96\n",
      "reward: 9.026215762326114\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.12701583372222053\n",
      "reward_2: 0.9390264950502359\n",
      "reward_3: 12.850000000000048\n",
      "reward_4: 0.016145297609695602\n",
      "reward_5: -0.0020713548984722034\n",
      "reward_6: 0.2581836088895796\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 614\n",
      "episode was finished at timestep: 188\n",
      "reward: 8.497978558899412\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.021916347079806858\n",
      "reward_2: 0.909022299482847\n",
      "reward_3: 14.100000000000065\n",
      "reward_4: -0.006379476718796156\n",
      "reward_5: -0.003170986762184095\n",
      "reward_6: 0.2562106164693828\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 615\n",
      "episode was finished at timestep: 57\n",
      "reward: 8.972279289703916\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10025671323140463\n",
      "reward_2: 0.9469576000038092\n",
      "reward_3: 13.05000000000005\n",
      "reward_4: 0.002899505773628164\n",
      "reward_5: -0.004910054182261448\n",
      "reward_6: 0.2763357844352726\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 616\n",
      "episode was finished at timestep: 171\n",
      "reward: 7.51894471276212\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.13937001493242052\n",
      "reward_2: 0.7484707815191187\n",
      "reward_3: 11.850000000000033\n",
      "reward_4: 0.019477338484570624\n",
      "reward_5: -0.0015640026583042753\n",
      "reward_6: 0.2359737404584885\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 617\n",
      "episode was finished at timestep: 253\n",
      "reward: 7.7284331029967515\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0306079281700982\n",
      "reward_2: 0.8109934392576186\n",
      "reward_3: 14.40000000000007\n",
      "reward_4: -0.006800242429947332\n",
      "reward_5: -0.0021937067319341232\n",
      "reward_6: 0.2645533069372178\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 618\n",
      "episode was finished at timestep: 242\n",
      "reward: 8.911685634326888\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09633443819151985\n",
      "reward_2: 0.9443306134720085\n",
      "reward_3: 13.250000000000053\n",
      "reward_4: 0.0006256508587476617\n",
      "reward_5: -0.009415001671717722\n",
      "reward_6: 0.26334941649436916\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 619\n",
      "episode was finished at timestep: 234\n",
      "reward: 9.297660162820929\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.11717323462168376\n",
      "reward_2: 0.9966893926587996\n",
      "reward_3: 12.600000000000044\n",
      "reward_4: -0.003142533845191906\n",
      "reward_5: -0.0028761582853782386\n",
      "reward_6: 0.23330821597576168\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 620\n",
      "episode was finished at timestep: 165\n",
      "reward: 8.669146873087804\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06601024203830295\n",
      "reward_2: 0.9224432432127638\n",
      "reward_3: 14.000000000000064\n",
      "reward_4: -0.005453538507657782\n",
      "reward_5: -0.003587213286585467\n",
      "reward_6: 0.26893954002857146\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 621\n",
      "episode was finished at timestep: 57\n",
      "reward: 8.457795839168742\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.11447999742296007\n",
      "reward_2: 0.8752838614721897\n",
      "reward_3: 13.75000000000006\n",
      "reward_4: 0.01047574224454749\n",
      "reward_5: -0.005180228661498631\n",
      "reward_6: 0.2605859073400496\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 622\n",
      "episode was finished at timestep: 225\n",
      "reward: 9.093613960961445\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08340864049063788\n",
      "reward_2: 0.9694734781494454\n",
      "reward_3: 14.000000000000064\n",
      "reward_4: -0.0018521700998759627\n",
      "reward_5: -0.0007779269683391969\n",
      "reward_6: 0.26814611637592334\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 623\n",
      "episode was finished at timestep: 2\n",
      "reward: 9.182848387238627\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08750944270028008\n",
      "reward_2: 0.9786943692098745\n",
      "reward_3: 14.100000000000065\n",
      "reward_4: -0.0014109185928531077\n",
      "reward_5: -0.0074431042769539605\n",
      "reward_6: 0.2826344438791272\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 624\n",
      "episode was finished at timestep: 44\n",
      "reward: 8.338187871589216\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.1247802217801412\n",
      "reward_2: 0.8680849748718075\n",
      "reward_3: 14.300000000000068\n",
      "reward_4: 0.0012493865903601886\n",
      "reward_5: -0.0037825586432433055\n",
      "reward_6: 0.2606086500883106\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 625\n",
      "episode was finished at timestep: 256\n",
      "reward: 6.20610647677629\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.01050950354999966\n",
      "reward_2: 0.6219878412760271\n",
      "reward_3: 14.600000000000072\n",
      "reward_4: -0.0043352972926811615\n",
      "reward_5: -0.006736897185310889\n",
      "reward_6: 0.2591668518781661\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 626\n",
      "episode was finished at timestep: 207\n",
      "reward: 8.524162695820468\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.1313697033458286\n",
      "reward_2: 0.863308471264545\n",
      "reward_3: 11.250000000000025\n",
      "reward_4: 0.03005689344721759\n",
      "reward_5: -0.0071406886262157816\n",
      "reward_6: 0.25151076340675327\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 627\n",
      "episode was finished at timestep: 62\n",
      "reward: 9.22356126821865\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.1276236328813765\n",
      "reward_2: 0.9724172660277397\n",
      "reward_3: 13.850000000000062\n",
      "reward_4: 0.008944660579986845\n",
      "reward_5: -0.009342113969076967\n",
      "reward_6: 0.2525376697778703\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 628\n",
      "episode was finished at timestep: 42\n",
      "reward: 6.445696315669624\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.00016418033175998265\n",
      "reward_2: 0.6106916743065224\n",
      "reward_3: 12.800000000000047\n",
      "reward_4: 0.0054672854674193165\n",
      "reward_5: 0.24479729057990507\n",
      "reward_6: 0.2700848605632782\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 629\n",
      "episode was finished at timestep: 107\n",
      "reward: 8.757537523038396\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.045646807220247054\n",
      "reward_2: 0.93250687836236\n",
      "reward_3: 14.45000000000007\n",
      "reward_4: -0.002131919260500581\n",
      "reward_5: -0.0015231798824952847\n",
      "reward_6: 0.2684875562191018\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 630\n",
      "episode was finished at timestep: 59\n",
      "reward: 6.286395094408603\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0004980352189805772\n",
      "reward_2: 0.6119770698696165\n",
      "reward_3: 13.950000000000063\n",
      "reward_4: 0.003942058361817686\n",
      "reward_5: 0.09110309457505963\n",
      "reward_6: 0.2665770092010503\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 631\n",
      "episode was finished at timestep: 234\n",
      "reward: 7.92544891720481\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04762130710813734\n",
      "reward_2: 0.8345856036120731\n",
      "reward_3: 13.500000000000057\n",
      "reward_4: -0.007799287892989639\n",
      "reward_5: -0.00023647753896725022\n",
      "reward_6: 0.2619735618829724\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 632\n",
      "episode was finished at timestep: 108\n",
      "reward: 8.002026576966635\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.031141668558120728\n",
      "reward_2: 0.8384861670620747\n",
      "reward_3: 14.200000000000067\n",
      "reward_4: 0.0006044705868494305\n",
      "reward_5: -0.005603565460045108\n",
      "reward_6: 0.26187003934383346\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 633\n",
      "episode was finished at timestep: 51\n",
      "reward: 9.240944370534066\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09764040576087105\n",
      "reward_2: 0.9808245798667043\n",
      "reward_3: 14.700000000000074\n",
      "reward_4: 0.003408619596737026\n",
      "reward_5: -0.002247049859622763\n",
      "reward_6: 0.26972541892528623\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 634\n",
      "episode was finished at timestep: 111\n",
      "reward: 8.912345645385052\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10620850324630737\n",
      "reward_2: 0.9323234144053636\n",
      "reward_3: 14.000000000000064\n",
      "reward_4: 0.012774886740343732\n",
      "reward_5: -0.00505242949836718\n",
      "reward_6: 0.24853649580478632\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 635\n",
      "episode was finished at timestep: 60\n",
      "reward: 9.303086240097633\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09942611787054274\n",
      "reward_2: 0.992964165391388\n",
      "reward_3: 14.250000000000068\n",
      "reward_4: 0.0012331068908507348\n",
      "reward_5: -0.005852620168278122\n",
      "reward_6: 0.25403456413745806\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 636\n",
      "episode was finished at timestep: 165\n",
      "reward: 8.914134218745234\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0788957675298055\n",
      "reward_2: 0.9237296555372563\n",
      "reward_3: 14.000000000000064\n",
      "reward_4: 0.02431593852284351\n",
      "reward_5: -0.007991214482596595\n",
      "reward_6: 0.25699824655056025\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 637\n",
      "episode was finished at timestep: 172\n",
      "reward: 8.830115474598704\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08669761220614115\n",
      "reward_2: 0.930112665380468\n",
      "reward_3: 13.600000000000058\n",
      "reward_4: 0.005760484800394749\n",
      "reward_5: -0.0006017194314715368\n",
      "reward_6: 0.25522104704380055\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 638\n",
      "episode was finished at timestep: 178\n",
      "reward: 8.227559118823725\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0843859142727322\n",
      "reward_2: 0.8329147401385232\n",
      "reward_3: 13.250000000000053\n",
      "reward_4: 0.026092020270628496\n",
      "reward_5: -0.001142392328927381\n",
      "reward_6: 0.2704948469400398\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 639\n",
      "episode was finished at timestep: 260\n",
      "reward: 6.478714202798245\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0036325812339782714\n",
      "reward_2: 0.6495071891689641\n",
      "reward_3: 15.000000000000078\n",
      "reward_4: 0.002103646559134802\n",
      "reward_5: -0.001190323531191003\n",
      "reward_6: 0.26138525927066725\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 640\n",
      "episode was finished at timestep: 258\n",
      "reward: 9.278040795653641\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09478180540932549\n",
      "reward_2: 0.9820737062272225\n",
      "reward_3: 13.100000000000051\n",
      "reward_4: 0.006924604067245923\n",
      "reward_5: -0.0009195642613428608\n",
      "reward_6: 0.2704454054832456\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 641\n",
      "episode was finished at timestep: 77\n",
      "reward: 7.632912077888973\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.013781828350490993\n",
      "reward_2: 0.8002738466434233\n",
      "reward_3: 14.550000000000072\n",
      "reward_4: -0.005779256589326849\n",
      "reward_5: -0.0046000116915233015\n",
      "reward_6: 0.26583354079723365\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 642\n",
      "episode was finished at timestep: 209\n",
      "reward: 6.223014405736102\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0036606901221805147\n",
      "reward_2: 0.6176238708668332\n",
      "reward_3: 14.550000000000072\n",
      "reward_4: 0.0023685018189486583\n",
      "reward_5: -0.0045883939993252906\n",
      "reward_6: 0.26938450837135297\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 643\n",
      "episode was finished at timestep: 125\n",
      "reward: 8.114825079500212\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.02460190521346198\n",
      "reward_2: 0.8572689554491004\n",
      "reward_3: 14.750000000000075\n",
      "reward_4: -0.004193911337086291\n",
      "reward_5: -0.003963159708173573\n",
      "reward_6: 0.2676193144321437\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 644\n",
      "episode was finished at timestep: 250\n",
      "reward: 8.093922073337259\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.05166854394806756\n",
      "reward_2: 0.8515226447208187\n",
      "reward_3: 13.600000000000058\n",
      "reward_4: -0.004419218947107879\n",
      "reward_5: -0.0008820526631253026\n",
      "reward_6: 0.2644948425292962\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 645\n",
      "episode was finished at timestep: 125\n",
      "reward: 9.17484610370859\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.12887457874086167\n",
      "reward_2: 0.9650615957801294\n",
      "reward_3: 14.100000000000065\n",
      "reward_4: 0.007555546849188772\n",
      "reward_5: -0.008397088253858816\n",
      "reward_6: 0.27155147218704156\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 646\n",
      "episode was finished at timestep: 149\n",
      "reward: 8.972564951146381\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07927948501374986\n",
      "reward_2: 0.9514067230859065\n",
      "reward_3: 14.200000000000067\n",
      "reward_4: 0.0008594293498977379\n",
      "reward_5: -0.002972858104751926\n",
      "reward_6: 0.2762357714176179\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 647\n",
      "episode was finished at timestep: 240\n",
      "reward: 6.82714742744738\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.053528644641240436\n",
      "reward_2: 0.9130059826591854\n",
      "reward_3: 15.050000000000079\n",
      "reward_4: 0.02330026488649395\n",
      "reward_5: -0.008908389276124614\n",
      "reward_6: 0.29007052505016284\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 648\n",
      "episode was finished at timestep: 160\n",
      "reward: 8.778608510416753\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10719800723923577\n",
      "reward_2: 0.9164851164193909\n",
      "reward_3: 14.600000000000072\n",
      "reward_4: 0.008290584350056064\n",
      "reward_5: -0.00010348090838263602\n",
      "reward_6: 0.2713617112636564\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 649\n",
      "episode was finished at timestep: 132\n",
      "reward: -80.0328941675609\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.29179773065778947\n",
      "reward_2: -10\n",
      "reward_3: 11.500000000000028\n",
      "reward_4: 0.02206098578321729\n",
      "reward_5: 0.1632568503819736\n",
      "reward_6: 0.33403003180027\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 650\n",
      "episode was finished at timestep: 62\n",
      "reward: 9.065046595870244\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08402888245052761\n",
      "reward_2: 0.9659756437348938\n",
      "reward_3: 14.45000000000007\n",
      "reward_4: -0.002598389531059837\n",
      "reward_5: -0.007224679891765362\n",
      "reward_6: 0.27929769301414464\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 651\n",
      "episode was finished at timestep: 183\n",
      "reward: 8.472332167748299\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0503328091568417\n",
      "reward_2: 0.8972121627069987\n",
      "reward_3: 14.150000000000066\n",
      "reward_4: -0.004162927190991752\n",
      "reward_5: -0.00439582528660812\n",
      "reward_6: 0.2801146330833435\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 652\n",
      "episode was finished at timestep: 187\n",
      "reward: 9.058499896820498\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08244130280282762\n",
      "reward_2: 0.9662899996071624\n",
      "reward_3: 13.850000000000062\n",
      "reward_4: -0.003597214974035836\n",
      "reward_5: -0.0010811361376906821\n",
      "reward_6: 0.2737507864236831\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 653\n",
      "episode was finished at timestep: 92\n",
      "reward: 8.977825301770721\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08532776633898417\n",
      "reward_2: 0.9461369011586637\n",
      "reward_3: 14.000000000000064\n",
      "reward_4: 0.00741553979075789\n",
      "reward_5: -0.0038788864342154264\n",
      "reward_6: 0.26609022760391265\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 654\n",
      "episode was finished at timestep: 11\n",
      "reward: 8.649449797120008\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08977090385225084\n",
      "reward_2: 0.9080747037432669\n",
      "reward_3: 14.500000000000071\n",
      "reward_4: 0.004376690492887434\n",
      "reward_5: -0.005389637157211169\n",
      "reward_6: 0.26352404320239964\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 655\n",
      "episode was finished at timestep: 216\n",
      "reward: 7.008776949664573\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04078733060095045\n",
      "reward_2: 0.67441343433012\n",
      "reward_3: 12.700000000000045\n",
      "reward_4: 0.0541175584362027\n",
      "reward_5: -0.005176544486611926\n",
      "reward_6: 0.14322488808631895\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 656\n",
      "episode was finished at timestep: 42\n",
      "reward: 6.519782655287068\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.05738569431834751\n",
      "reward_2: 0.8993022508674775\n",
      "reward_3: 14.350000000000069\n",
      "reward_4: -0.002568001914866471\n",
      "reward_5: -2.9198104344156187e-05\n",
      "reward_6: 0.28663883411884306\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 657\n",
      "episode was finished at timestep: 65\n",
      "reward: 7.419038733961415\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.007921628819571602\n",
      "reward_2: 0.7553990745077278\n",
      "reward_3: 15.650000000000087\n",
      "reward_4: 0.015154481116607315\n",
      "reward_5: -0.0007941439954723961\n",
      "reward_6: 0.24539613747596778\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 658\n",
      "episode was finished at timestep: 104\n",
      "reward: 9.264513155064797\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08567170765664843\n",
      "reward_2: 0.9864817125564184\n",
      "reward_3: 14.950000000000077\n",
      "reward_4: 0.0022649919501427007\n",
      "reward_5: -0.005218119700680409\n",
      "reward_6: 0.272092597723007\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 659\n",
      "episode was finished at timestep: 178\n",
      "reward: 8.591155630842376\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10931013623873392\n",
      "reward_2: 0.8977604928847956\n",
      "reward_3: 14.800000000000075\n",
      "reward_4: 0.004550288486581593\n",
      "reward_5: -0.005119081589708448\n",
      "reward_6: 0.266504991889\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 660\n",
      "episode was finished at timestep: 99\n",
      "reward: 9.31624906497006\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0932382669713762\n",
      "reward_2: 0.9874622687580384\n",
      "reward_3: 14.500000000000071\n",
      "reward_4: 0.0062469885565042205\n",
      "reward_5: -0.0008789238871539595\n",
      "reward_6: 0.27228233003616276\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 661\n",
      "episode was finished at timestep: 153\n",
      "reward: 9.110898698234736\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08398053182495965\n",
      "reward_2: 0.9684357379249178\n",
      "reward_3: 15.400000000000084\n",
      "reward_4: 0.0008121340886083317\n",
      "reward_5: -0.0038880341746100554\n",
      "reward_6: 0.2747698911428459\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 662\n",
      "episode was finished at timestep: 26\n",
      "reward: 7.952436329914727\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.051425725883907744\n",
      "reward_2: 0.828309515124008\n",
      "reward_3: 15.350000000000083\n",
      "reward_4: 0.001193122744393662\n",
      "reward_5: -0.006727303584501006\n",
      "reward_6: 0.26967013800144135\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 663\n",
      "episode was finished at timestep: 230\n",
      "reward: 9.033160469123043\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08711978395779928\n",
      "reward_2: 0.9535316871019569\n",
      "reward_3: 14.40000000000007\n",
      "reward_4: 0.007698313008909139\n",
      "reward_5: -0.003432882382566049\n",
      "reward_6: 0.2577135666608815\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 664\n",
      "episode was finished at timestep: 166\n",
      "reward: 9.368851747998594\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09413762953546312\n",
      "reward_2: 0.9964674117092652\n",
      "reward_3: 15.450000000000085\n",
      "reward_4: 0.004058126612175243\n",
      "reward_5: -0.003941372915219432\n",
      "reward_6: 0.2723911848068251\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 665\n",
      "episode was finished at timestep: 194\n",
      "reward: 8.965997479711081\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0660478201177385\n",
      "reward_2: 0.9490804350529629\n",
      "reward_3: 15.400000000000084\n",
      "reward_4: 0.005189160703028506\n",
      "reward_5: -0.006760810290394066\n",
      "reward_6: 0.2705003705024712\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 666\n",
      "episode was finished at timestep: 209\n",
      "reward: 9.181387022717312\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09167622460259331\n",
      "reward_2: 0.9704912284820404\n",
      "reward_3: 15.050000000000079\n",
      "reward_4: 0.008189873731315203\n",
      "reward_5: -0.00015675140714558702\n",
      "reward_6: 0.25841206514835247\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 667\n",
      "episode was finished at timestep: 165\n",
      "reward: 9.110603329947367\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07650228142738343\n",
      "reward_2: 0.9726974511733883\n",
      "reward_3: 14.800000000000075\n",
      "reward_4: -0.0018577733472268675\n",
      "reward_5: -0.006890504169849502\n",
      "reward_6: 0.27230079674720764\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 668\n",
      "episode was finished at timestep: 144\n",
      "reward: 8.790719939210268\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07503725224071078\n",
      "reward_2: 0.9315092823140599\n",
      "reward_3: 14.550000000000072\n",
      "reward_4: -3.326694778223782e-05\n",
      "reward_5: -0.0075180211810003785\n",
      "reward_6: 0.2694525852203363\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 669\n",
      "episode was finished at timestep: 175\n",
      "reward: 9.033084954937804\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08419660793410408\n",
      "reward_2: 0.9558254174446559\n",
      "reward_3: 14.650000000000073\n",
      "reward_4: 0.0037530184544125687\n",
      "reward_5: -0.0008251652631704095\n",
      "reward_6: 0.2711326917409893\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 670\n",
      "episode was finished at timestep: 218\n",
      "reward: 8.496865758584738\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.03673306769794888\n",
      "reward_2: 0.8976564751773429\n",
      "reward_3: 14.650000000000073\n",
      "reward_4: 0.0013817533702054163\n",
      "reward_5: -0.002813358091184526\n",
      "reward_6: 0.2686868872642526\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 671\n",
      "episode was finished at timestep: 214\n",
      "reward: 7.111990463036427\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09146274195777046\n",
      "reward_2: 0.7103575055556288\n",
      "reward_3: 15.350000000000083\n",
      "reward_4: 0.008052906837289698\n",
      "reward_5: -0.006046228715352579\n",
      "reward_6: 0.27724398398399397\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 672\n",
      "episode was finished at timestep: 322\n",
      "reward: 9.595559662722156\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0844630519549052\n",
      "reward_2: 0.9977797334260543\n",
      "reward_3: 16.350000000000097\n",
      "reward_4: 0.031803798458527835\n",
      "reward_5: -0.003949519689923164\n",
      "reward_6: 0.27619787538051654\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 673\n",
      "episode was finished at timestep: 72\n",
      "reward: 8.441537717125177\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.039108943276935156\n",
      "reward_2: 0.8885090931356183\n",
      "reward_3: 15.700000000000088\n",
      "reward_4: 0.0030620049116728866\n",
      "reward_5: -0.005050416374139507\n",
      "reward_6: 0.27281707251071907\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 674\n",
      "episode was finished at timestep: 57\n",
      "reward: 8.85299319061532\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.051958884795506796\n",
      "reward_2: 0.9368626961335298\n",
      "reward_3: 16.100000000000094\n",
      "reward_4: 0.00400556599879053\n",
      "reward_5: -0.0032925637308393856\n",
      "reward_6: 0.2752341058254236\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 675\n",
      "episode was finished at timestep: 207\n",
      "reward: 9.325073004895886\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06914097136921353\n",
      "reward_2: 0.9934744414256211\n",
      "reward_3: 15.750000000000089\n",
      "reward_4: 0.003734300643276498\n",
      "reward_5: -0.005707072140526748\n",
      "reward_6: 0.2818691691160202\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 676\n",
      "episode was finished at timestep: 141\n",
      "reward: 9.057474261918959\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08783557348781162\n",
      "reward_2: 0.9633489582501923\n",
      "reward_3: 15.750000000000089\n",
      "reward_4: -0.0020264910646609737\n",
      "reward_5: -0.003486133863360171\n",
      "reward_6: 0.2804450848102563\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 677\n",
      "episode was finished at timestep: 115\n",
      "reward: 9.17485905845108\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06850923233562045\n",
      "reward_2: 0.972823754094917\n",
      "reward_3: 15.80000000000009\n",
      "reward_4: 0.005595035957772154\n",
      "reward_5: -0.004062844204072036\n",
      "reward_6: 0.2809556832313531\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 678\n",
      "episode was finished at timestep: 202\n",
      "reward: 8.188852488290701\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.1354617284403907\n",
      "reward_2: 0.8400580766595216\n",
      "reward_3: 11.850000000000033\n",
      "reward_4: 0.008524535271909457\n",
      "reward_5: -0.0019736426239951753\n",
      "reward_6: 0.2651235070228576\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 679\n",
      "episode was finished at timestep: 70\n",
      "reward: 9.014071265922373\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06814784871207344\n",
      "reward_2: 0.9552339213017346\n",
      "reward_3: 15.750000000000089\n",
      "reward_4: 0.0024496058088516294\n",
      "reward_5: -0.0013787549384821555\n",
      "reward_6: 0.28373395526409195\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 680\n",
      "episode was finished at timestep: 33\n",
      "reward: 7.870218576029398\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.040875819656583996\n",
      "reward_2: 0.8126566461311036\n",
      "reward_3: 15.350000000000083\n",
      "reward_4: 0.00570184483574792\n",
      "reward_5: -0.0028038894011925683\n",
      "reward_6: 0.2832320513725286\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 681\n",
      "episode was finished at timestep: 40\n",
      "reward: 9.088234664344503\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08624165852864583\n",
      "reward_2: 0.9663801641928004\n",
      "reward_3: 15.300000000000082\n",
      "reward_4: -7.834570180165201e-06\n",
      "reward_5: -0.005048207616406704\n",
      "reward_6: 0.2740225764513018\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 682\n",
      "episode was finished at timestep: 175\n",
      "reward: 8.984601925639335\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06525888972812229\n",
      "reward_2: 0.9564235799541816\n",
      "reward_3: 15.10000000000008\n",
      "reward_4: -0.0016220751695935577\n",
      "reward_5: -0.0018149664285001422\n",
      "reward_6: 0.28073263072967514\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 683\n",
      "episode was finished at timestep: 145\n",
      "reward: 8.660321991115474\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.061767645676930744\n",
      "reward_2: 0.9167921154990916\n",
      "reward_3: 15.550000000000086\n",
      "reward_4: -0.0013694403746877981\n",
      "reward_5: -0.006284590893500664\n",
      "reward_6: 0.27938420200348024\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 684\n",
      "episode was finished at timestep: 220\n",
      "reward: 8.939281163787896\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06313577890396119\n",
      "reward_2: 0.9495506510705027\n",
      "reward_3: 15.450000000000085\n",
      "reward_4: 0.0004825396746723243\n",
      "reward_5: -0.004538341508335483\n",
      "reward_6: 0.2783582004308701\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 685\n",
      "episode was finished at timestep: 213\n",
      "reward: 8.050335040689305\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.027247718307707045\n",
      "reward_2: 0.8404892575920684\n",
      "reward_3: 15.500000000000085\n",
      "reward_4: 0.0033543810640665585\n",
      "reward_5: -0.0059477728777141674\n",
      "reward_6: 0.276219319343566\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 686\n",
      "episode was finished at timestep: 173\n",
      "reward: 7.3585112481349135\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.1532486014895969\n",
      "reward_2: 0.7394343341423256\n",
      "reward_3: 15.050000000000079\n",
      "reward_4: 0.0007101170693344728\n",
      "reward_5: -0.005368501427315545\n",
      "reward_6: 0.28746887171268454\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 687\n",
      "episode was finished at timestep: 204\n",
      "reward: 9.031685861770736\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07859909137090047\n",
      "reward_2: 0.9604445996749702\n",
      "reward_3: 15.10000000000008\n",
      "reward_4: -0.001381147962671605\n",
      "reward_5: -0.006290463515239726\n",
      "reward_6: 0.28485628688335385\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 688\n",
      "episode was finished at timestep: 234\n",
      "reward: 8.685521033270799\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06928691003057692\n",
      "reward_2: 0.9170430219801513\n",
      "reward_3: 15.300000000000082\n",
      "reward_4: 0.00012186422988889945\n",
      "reward_5: -0.0013498747919975073\n",
      "reward_6: 0.2782249083518976\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 689\n",
      "episode was finished at timestep: 208\n",
      "reward: 9.114548673676715\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07169314954015944\n",
      "reward_2: 0.9681634123146061\n",
      "reward_3: 15.900000000000091\n",
      "reward_4: 0.002011581179288555\n",
      "reward_5: -0.000853117457216257\n",
      "reward_6: 0.28018869364261656\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 690\n",
      "episode was finished at timestep: 284\n",
      "reward: 8.901135645768926\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.058535832166671756\n",
      "reward_2: 0.9438200857028844\n",
      "reward_3: 15.400000000000084\n",
      "reward_4: 0.001649390396006254\n",
      "reward_5: -0.000924134959697298\n",
      "reward_6: 0.27771480643749324\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 691\n",
      "episode was finished at timestep: 260\n",
      "reward: 9.257712490766156\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0726050873597463\n",
      "reward_2: 0.9881145106848663\n",
      "reward_3: 15.750000000000089\n",
      "reward_4: -0.00017345156364328317\n",
      "reward_5: -0.0032676661381555523\n",
      "reward_6: 0.28274659657478285\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 692\n",
      "episode was finished at timestep: 198\n",
      "reward: 9.207265905468471\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09450405571195815\n",
      "reward_2: 0.9808339865781355\n",
      "reward_3: 13.950000000000063\n",
      "reward_4: -0.0022710006926057245\n",
      "reward_5: -0.00043538011832886523\n",
      "reward_6: 0.2828333427906039\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 693\n",
      "episode was finished at timestep: 156\n",
      "reward: 8.584210407263923\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06754869421323141\n",
      "reward_2: 0.9040980391471297\n",
      "reward_3: 14.950000000000077\n",
      "reward_4: 0.0011481186343914374\n",
      "reward_5: -0.0005161063240251452\n",
      "reward_6: 0.2732152237892147\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 694\n",
      "episode was finished at timestep: 211\n",
      "reward: 9.3175415496024\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08302049901750352\n",
      "reward_2: 0.9969310276670382\n",
      "reward_3: 15.300000000000082\n",
      "reward_4: -0.001243165446061596\n",
      "reward_5: -0.007043344790148372\n",
      "reward_6: 0.2740214976072315\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 695\n",
      "episode was finished at timestep: 242\n",
      "reward: 9.280450707465608\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07284242113431295\n",
      "reward_2: 0.9935578227711611\n",
      "reward_3: 15.200000000000081\n",
      "reward_4: -0.0019218503291877197\n",
      "reward_5: -0.0031199502640333774\n",
      "reward_6: 0.27561379039287515\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 696\n",
      "episode was finished at timestep: 212\n",
      "reward: 9.062222578909552\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08001103864775763\n",
      "reward_2: 0.9608550091514104\n",
      "reward_3: 15.500000000000085\n",
      "reward_4: 0.002823615303629907\n",
      "reward_5: -0.005138011272109348\n",
      "reward_6: 0.2758538892269131\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 697\n",
      "episode was finished at timestep: 10\n",
      "reward: 9.31138552473793\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10851639840337965\n",
      "reward_2: 0.9884411588458771\n",
      "reward_3: 15.200000000000081\n",
      "reward_4: 0.00429896323942188\n",
      "reward_5: -0.0037750272102413146\n",
      "reward_6: 0.26269651019573204\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 698\n",
      "episode was finished at timestep: 50\n",
      "reward: 8.433382974833517\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06125047008196513\n",
      "reward_2: 0.8797003161133571\n",
      "reward_3: 15.350000000000083\n",
      "reward_4: 0.008709464158922771\n",
      "reward_5: -0.0063539487739507905\n",
      "reward_6: 0.26916154468059605\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 699\n",
      "episode was finished at timestep: 220\n",
      "reward: 8.667428877853396\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07658010654979282\n",
      "reward_2: 0.9119737685166506\n",
      "reward_3: 15.10000000000008\n",
      "reward_4: 0.0028931811520762096\n",
      "reward_5: -0.0027231579747812873\n",
      "reward_6: 0.27262299859523675\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 700\n",
      "episode was finished at timestep: 299\n",
      "reward: 8.13212949901283\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06968195372157626\n",
      "reward_2: 0.8318256504395997\n",
      "reward_3: 15.650000000000087\n",
      "reward_4: 0.01833750694899635\n",
      "reward_5: -0.003644419274885043\n",
      "reward_6: 0.2627000387907036\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 701\n",
      "episode was finished at timestep: 244\n",
      "reward: 8.497711186080258\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.05449417365921868\n",
      "reward_2: 0.899189884218981\n",
      "reward_3: 14.900000000000077\n",
      "reward_4: -0.0032563859329791\n",
      "reward_5: -0.001545254979330224\n",
      "reward_6: 0.2753076144456865\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 702\n",
      "episode was finished at timestep: 251\n",
      "reward: 8.959325278471171\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08266703883806864\n",
      "reward_2: 0.9522862127926809\n",
      "reward_3: 15.000000000000078\n",
      "reward_4: -0.0026104684701462586\n",
      "reward_5: -0.0021095413670054815\n",
      "reward_6: 0.27936182641982976\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 703\n",
      "episode was finished at timestep: 311\n",
      "reward: 8.961112582441505\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08514990806579589\n",
      "reward_2: 0.9489594195115787\n",
      "reward_3: 16.100000000000094\n",
      "reward_4: 0.0009869798493807025\n",
      "reward_5: -0.005573250795384629\n",
      "reward_6: 0.27981806361675277\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 704\n",
      "episode was finished at timestep: 19\n",
      "reward: 6.294058946419689\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.02857693764898512\n",
      "reward_2: 0.6334473631347668\n",
      "reward_3: 15.85000000000009\n",
      "reward_4: -0.0071058421615374815\n",
      "reward_5: -0.0028671887901127254\n",
      "reward_6: 0.2555036964416496\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 705\n",
      "episode was finished at timestep: 35\n",
      "reward: 9.063104252827294\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.058069196012285024\n",
      "reward_2: 0.968904108460196\n",
      "reward_3: 15.050000000000079\n",
      "reward_4: -0.00028844834677158813\n",
      "reward_5: -0.005333410143436742\n",
      "reward_6: 0.25943651938438417\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 706\n",
      "episode was finished at timestep: 293\n",
      "reward: 8.03783744194039\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07660456167327033\n",
      "reward_2: 0.8355096110467247\n",
      "reward_3: 14.900000000000077\n",
      "reward_4: 0.0008421943715367775\n",
      "reward_5: -0.006754219125520441\n",
      "reward_6: 0.2751859893798818\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 707\n",
      "episode was finished at timestep: 25\n",
      "reward: 8.839812553997268\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10802971522013347\n",
      "reward_2: 0.9351101392308131\n",
      "reward_3: 15.550000000000086\n",
      "reward_4: -0.0028393862085351884\n",
      "reward_5: -0.0004544314989714119\n",
      "reward_6: 0.2719979127645491\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 708\n",
      "episode was finished at timestep: 44\n",
      "reward: 7.0809646888527045\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0528499444325765\n",
      "reward_2: 0.9733131256716024\n",
      "reward_3: 16.150000000000095\n",
      "reward_4: -0.005617040900333308\n",
      "reward_5: -0.004364341201019546\n",
      "reward_6: 0.28875707411766005\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 709\n",
      "episode was finished at timestep: 32\n",
      "reward: 7.964632900237528\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.05175841649373372\n",
      "reward_2: 0.8233072873395143\n",
      "reward_3: 15.300000000000082\n",
      "reward_4: 0.006929009622549387\n",
      "reward_5: -0.0010853088714698107\n",
      "reward_6: 0.27002941691875504\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 710\n",
      "episode was finished at timestep: 53\n",
      "reward: 9.054993282744743\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06085237132178412\n",
      "reward_2: 0.9727356445399213\n",
      "reward_3: 15.950000000000092\n",
      "reward_4: -0.008168714368856484\n",
      "reward_5: -0.005268808373321102\n",
      "reward_6: 0.2807476117610933\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 711\n",
      "episode was finished at timestep: 302\n",
      "reward: 8.841329580692666\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.05781858563423157\n",
      "reward_2: 0.9395667409536653\n",
      "reward_3: 16.150000000000095\n",
      "reward_4: -0.002452271327063329\n",
      "reward_5: -0.001111025165950134\n",
      "reward_6: 0.2855529298782351\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 712\n",
      "episode was finished at timestep: 182\n",
      "reward: 8.778772946534943\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.027532882822884453\n",
      "reward_2: 0.931626128054116\n",
      "reward_3: 15.400000000000084\n",
      "reward_4: 0.00279605214697483\n",
      "reward_5: -0.004034071177206044\n",
      "reward_6: 0.27784335994720355\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 713\n",
      "episode was finished at timestep: 22\n",
      "reward: 7.171782269677945\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.05004055102666219\n",
      "reward_2: 0.9809685344714778\n",
      "reward_3: 15.400000000000084\n",
      "reward_4: -0.0019476857639017452\n",
      "reward_5: -0.0002158790226067945\n",
      "reward_6: 0.2877374746799479\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 714\n",
      "episode was finished at timestep: 278\n",
      "reward: 8.959529163055883\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.03877469764815437\n",
      "reward_2: 0.9662848108538696\n",
      "reward_3: 15.350000000000083\n",
      "reward_4: -0.01102640288678657\n",
      "reward_5: -0.0019922550842567926\n",
      "reward_6: 0.27863279008865494\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 28.2     |\n",
      "|    ep_rew_mean     | 228      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 37       |\n",
      "|    time_elapsed    | 75       |\n",
      "|    total_timesteps | 2820     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -593     |\n",
      "|    critic_loss     | 828      |\n",
      "|    ent_coef        | 0.083    |\n",
      "|    ent_coef_loss   | 8.79     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 3506219  |\n",
      "---------------------------------\n",
      "episode: 715\n",
      "episode was finished at timestep: 14\n",
      "reward: 8.761307071391874\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0005074130164252387\n",
      "reward_2: 0.9417437837931054\n",
      "reward_3: 14.750000000000075\n",
      "reward_4: -0.005617902226867671\n",
      "reward_5: -0.004803896810860427\n",
      "reward_6: 0.2756446620225912\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 716\n",
      "episode was finished at timestep: 151\n",
      "reward: -78.42133606052194\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0003374172581566705\n",
      "reward_2: -10\n",
      "reward_3: 11.100000000000023\n",
      "reward_4: 0.04647026777155617\n",
      "reward_5: -0.002582204775401446\n",
      "reward_6: 0.2083414193391796\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 717\n",
      "episode was finished at timestep: 127\n",
      "reward: 6.5914054335782675\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0584177209271325\n",
      "reward_2: 0.9156153133472014\n",
      "reward_3: 15.300000000000082\n",
      "reward_4: -0.009990603672993642\n",
      "reward_5: -0.0007795195149046918\n",
      "reward_6: 0.2867295547723774\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 718\n",
      "episode was finished at timestep: 268\n",
      "reward: 9.22305531163576\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0718738145298428\n",
      "reward_2: 0.9790511441729481\n",
      "reward_3: 15.400000000000084\n",
      "reward_4: 0.004951691849525588\n",
      "reward_5: -0.005088239025889034\n",
      "reward_6: 0.2821937146186827\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 719\n",
      "episode was finished at timestep: 213\n",
      "reward: 7.097998622379967\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.057895106739468044\n",
      "reward_2: 0.9731200821641591\n",
      "reward_3: 15.400000000000084\n",
      "reward_4: -0.0036757292260375606\n",
      "reward_5: -0.005065034650451139\n",
      "reward_6: 0.2875603934526446\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 720\n",
      "episode was finished at timestep: 232\n",
      "reward: 8.684662562191832\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04534741573863559\n",
      "reward_2: 0.9314598825722602\n",
      "reward_3: 14.850000000000076\n",
      "reward_4: -0.009809110791913867\n",
      "reward_5: -0.005771871529083346\n",
      "reward_6: 0.26990084373950907\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 721\n",
      "episode was finished at timestep: 167\n",
      "reward: 7.82525090757184\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.003237210379706489\n",
      "reward_2: 0.8361249062972934\n",
      "reward_3: 14.500000000000071\n",
      "reward_4: -0.01825402413946364\n",
      "reward_5: 0.04067216293773678\n",
      "reward_6: 0.24291556441783835\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 722\n",
      "episode was finished at timestep: 192\n",
      "reward: 7.4953942894689405\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09856359097692702\n",
      "reward_2: 0.9959755336000775\n",
      "reward_3: 14.40000000000007\n",
      "reward_4: 0.013193050130477389\n",
      "reward_5: -0.00013170134910716057\n",
      "reward_6: 0.321693729996681\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 723\n",
      "episode was finished at timestep: 91\n",
      "reward: 8.819048099314921\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.001622596714231703\n",
      "reward_2: 0.9608472230980535\n",
      "reward_3: 15.550000000000086\n",
      "reward_4: -0.016535515891261243\n",
      "reward_5: 0.011610120050979944\n",
      "reward_6: 0.2524935849905017\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 724\n",
      "episode was finished at timestep: 245\n",
      "reward: 6.604990137726713\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04481657147407532\n",
      "reward_2: 0.9093041366881657\n",
      "reward_3: 15.050000000000079\n",
      "reward_4: -0.00027510393429309944\n",
      "reward_5: -0.0003481589471237593\n",
      "reward_6: 0.2862827965021143\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 725\n",
      "episode was finished at timestep: 264\n",
      "reward: 6.690377698553958\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.038745764229032725\n",
      "reward_2: 0.921478411347082\n",
      "reward_3: 14.850000000000076\n",
      "reward_4: -0.0011607227892633887\n",
      "reward_5: -0.004817016330654766\n",
      "reward_6: 0.29192744219303113\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 726\n",
      "episode was finished at timestep: 17\n",
      "reward: 8.935776868285345\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08547742565472921\n",
      "reward_2: 0.9534529908147455\n",
      "reward_3: 15.400000000000084\n",
      "reward_4: -0.007238206436788488\n",
      "reward_5: -0.0025663588273031244\n",
      "reward_6: 0.2810941931009292\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 727\n",
      "episode was finished at timestep: 178\n",
      "reward: 8.785930456133446\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04798715114593506\n",
      "reward_2: 0.943280879530065\n",
      "reward_3: 16.350000000000097\n",
      "reward_4: -0.009618641019351486\n",
      "reward_5: -0.003934588650031993\n",
      "reward_6: 0.27039998555183453\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 728\n",
      "episode was finished at timestep: 265\n",
      "reward: 8.748210115786536\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0541468878587087\n",
      "reward_2: 0.9310721698490706\n",
      "reward_3: 14.850000000000076\n",
      "reward_4: -0.004354577708102738\n",
      "reward_5: -0.0026465012949103083\n",
      "reward_6: 0.2809889920949944\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 729\n",
      "episode was finished at timestep: 196\n",
      "reward: 8.028422953023863\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04365216361151801\n",
      "reward_2: 0.8479930689399193\n",
      "reward_3: 15.80000000000009\n",
      "reward_4: -0.006593961674522149\n",
      "reward_5: -0.002166196682165259\n",
      "reward_6: 0.2536374613046658\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 730\n",
      "episode was finished at timestep: 229\n",
      "reward: 9.0337151408509\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06961898936165703\n",
      "reward_2: 0.9571955472709235\n",
      "reward_3: 15.350000000000083\n",
      "reward_4: 0.003109388723169957\n",
      "reward_5: -0.005612592742179837\n",
      "reward_6: 0.2852225896120081\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 731\n",
      "episode was finished at timestep: 134\n",
      "reward: 8.467356698440222\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.1162480976846483\n",
      "reward_2: 0.8682054055143776\n",
      "reward_3: 14.700000000000074\n",
      "reward_4: 0.01791712449566347\n",
      "reward_5: -0.006796188985439026\n",
      "reward_6: 0.26696454966068284\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 732\n",
      "episode was finished at timestep: 256\n",
      "reward: 8.729780403901547\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10504107144143847\n",
      "reward_2: 0.9068133563174919\n",
      "reward_3: 14.950000000000077\n",
      "reward_4: 0.012525062639899432\n",
      "reward_5: -0.006117544119804089\n",
      "reward_6: 0.2741561915874491\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 733\n",
      "episode was finished at timestep: 237\n",
      "reward: 8.726802919616121\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.05081378486421373\n",
      "reward_2: 0.9310957056067583\n",
      "reward_3: 14.650000000000073\n",
      "reward_4: -0.0067538829351222775\n",
      "reward_5: -0.002465281262000474\n",
      "reward_6: 0.2817665013074869\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 734\n",
      "episode was finished at timestep: 234\n",
      "reward: 8.613865648740894\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07704491151703728\n",
      "reward_2: 0.8867795664316743\n",
      "reward_3: 14.150000000000066\n",
      "reward_4: 0.020971061421990102\n",
      "reward_5: -0.0029674731251686146\n",
      "reward_6: 0.27589652085304284\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 735\n",
      "episode was finished at timestep: 281\n",
      "reward: 8.793465869230578\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08170712325308058\n",
      "reward_2: 0.8935742142247092\n",
      "reward_3: 14.100000000000065\n",
      "reward_4: 0.03515723020784691\n",
      "reward_5: -0.004461797644037328\n",
      "reward_6: 0.2844889881610865\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 736\n",
      "episode was finished at timestep: 92\n",
      "reward: 6.773807519581877\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.060166246361202665\n",
      "reward_2: 0.9225046047891958\n",
      "reward_3: 14.45000000000007\n",
      "reward_4: 0.005508730162036386\n",
      "reward_5: -0.006276185533151945\n",
      "reward_6: 0.29388411247730284\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 737\n",
      "episode was finished at timestep: 161\n",
      "reward: 8.938400752273834\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04747462603780958\n",
      "reward_2: 0.951374527073634\n",
      "reward_3: 14.050000000000065\n",
      "reward_4: -0.000740745894977124\n",
      "reward_5: -0.0005744357059455751\n",
      "reward_6: 0.2845569791793814\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 738\n",
      "episode was finished at timestep: 315\n",
      "reward: 8.29263371645501\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09643638134002686\n",
      "reward_2: 0.865808858522977\n",
      "reward_3: 16.300000000000097\n",
      "reward_4: -0.0024838614477887687\n",
      "reward_5: -0.0001857250906989331\n",
      "reward_6: 0.2876097502708431\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 739\n",
      "episode was finished at timestep: 75\n",
      "reward: -80.33942453160458\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.22907188534736633\n",
      "reward_2: -10\n",
      "reward_3: 15.15000000000008\n",
      "reward_4: 0.015136149916748422\n",
      "reward_5: -0.005860424950257699\n",
      "reward_6: 0.31425480866432276\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 740\n",
      "episode was finished at timestep: 86\n",
      "reward: 5.955703979012933\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.03713968462414212\n",
      "reward_2: 0.8359851228883471\n",
      "reward_3: 16.250000000000096\n",
      "reward_4: -0.006548041148386119\n",
      "reward_5: -0.0031837017480243666\n",
      "reward_6: 0.28408467555046035\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 741\n",
      "episode was finished at timestep: 63\n",
      "reward: 6.681536792122774\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04904707670211792\n",
      "reward_2: 0.6581037112334178\n",
      "reward_3: 15.10000000000008\n",
      "reward_4: 0.01623044257255657\n",
      "reward_5: -0.00305312964099033\n",
      "reward_6: 0.2388562812805185\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 742\n",
      "episode was finished at timestep: 105\n",
      "reward: 7.175089053153545\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06524491839938694\n",
      "reward_2: 0.9717302909929562\n",
      "reward_3: 15.650000000000087\n",
      "reward_4: 0.006083862774560202\n",
      "reward_5: -0.0047162062645998756\n",
      "reward_6: 0.28996044421196\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 743\n",
      "episode was finished at timestep: 72\n",
      "reward: 8.04701020153644\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10747311645083957\n",
      "reward_2: 0.8105148983266899\n",
      "reward_3: 16.200000000000095\n",
      "reward_4: 0.02989843695804325\n",
      "reward_5: -0.0032664595179358715\n",
      "reward_6: 0.2173368623256695\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 744\n",
      "episode was finished at timestep: 45\n",
      "reward: 7.291297931403587\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04400808347596063\n",
      "reward_2: 0.7363268931009475\n",
      "reward_3: 15.85000000000009\n",
      "reward_4: 0.011601938459309338\n",
      "reward_5: -0.0020058225534413054\n",
      "reward_6: 0.26375168466567944\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 745\n",
      "episode was finished at timestep: 22\n",
      "reward: 6.789224669673205\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.036481996377309166\n",
      "reward_2: 0.9297227681512581\n",
      "reward_3: 15.700000000000088\n",
      "reward_4: 0.0033972566495276625\n",
      "reward_5: -0.0033859233412600292\n",
      "reward_6: 0.2890750648975371\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 746\n",
      "episode was finished at timestep: 49\n",
      "reward: 7.2261234610735885\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.037296997838550144\n",
      "reward_2: 0.7454248580615533\n",
      "reward_3: 16.000000000000092\n",
      "reward_4: -0.004120768643076502\n",
      "reward_5: -0.006419648336162235\n",
      "reward_6: 0.2626800628900532\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 747\n",
      "episode was finished at timestep: 122\n",
      "reward: 7.901870447029689\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0034224828084309894\n",
      "reward_2: 0.8413169508946297\n",
      "reward_3: 14.800000000000075\n",
      "reward_4: -0.023794635042821994\n",
      "reward_5: 0.10114900116119614\n",
      "reward_6: 0.2619920685291295\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 748\n",
      "episode was finished at timestep: 223\n",
      "reward: 9.240981895418626\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08337061338954502\n",
      "reward_2: 0.9910533831437878\n",
      "reward_3: 14.850000000000076\n",
      "reward_4: -0.005425893148296837\n",
      "reward_5: -0.004036925469558857\n",
      "reward_6: 0.2746482875347136\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 749\n",
      "episode was finished at timestep: 293\n",
      "reward: 7.674082595534843\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.048148836029900444\n",
      "reward_2: 0.7956861882698096\n",
      "reward_3: 14.850000000000076\n",
      "reward_4: -0.0007749444375099302\n",
      "reward_5: -0.007136137223173004\n",
      "reward_6: 0.2717999460697186\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 750\n",
      "episode was finished at timestep: 282\n",
      "reward: 6.945739436602082\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.03811978764004177\n",
      "reward_2: 0.6957311044224579\n",
      "reward_3: 15.300000000000082\n",
      "reward_4: 0.00817646790078939\n",
      "reward_5: -0.001651593290662845\n",
      "reward_6: 0.2759706636667252\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 751\n",
      "episode was finished at timestep: 278\n",
      "reward: 8.596061428622496\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0033455451329549154\n",
      "reward_2: 0.9058275981896177\n",
      "reward_3: 14.500000000000071\n",
      "reward_4: 0.008726221903647796\n",
      "reward_5: -0.0028012989543260147\n",
      "reward_6: 0.2771532883644109\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 752\n",
      "episode was finished at timestep: 98\n",
      "reward: 6.945382178607755\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.05880203578207228\n",
      "reward_2: 0.9560330983315299\n",
      "reward_3: 14.100000000000065\n",
      "reward_4: -0.006000345045222559\n",
      "reward_5: -0.0019692173156384976\n",
      "reward_6: 0.28640733385086103\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 753\n",
      "episode was finished at timestep: 127\n",
      "reward: 9.31602476082657\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07933848831388686\n",
      "reward_2: 0.9998874164335956\n",
      "reward_3: 15.000000000000078\n",
      "reward_4: -0.006275983795249118\n",
      "reward_5: -0.004432258091197146\n",
      "reward_6: 0.2902270694971084\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 754\n",
      "episode was finished at timestep: 11\n",
      "reward: 7.268218909431166\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.05597350001335144\n",
      "reward_2: 0.990106465773351\n",
      "reward_3: 15.650000000000087\n",
      "reward_4: 0.00015293676852223825\n",
      "reward_5: -0.003202492736767937\n",
      "reward_6: 0.29128601515293073\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 755\n",
      "episode was finished at timestep: 30\n",
      "reward: 8.400187337681803\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08530678086810642\n",
      "reward_2: 0.8873046882026365\n",
      "reward_3: 14.950000000000077\n",
      "reward_4: -0.008347388082741816\n",
      "reward_5: -0.003225025125508196\n",
      "reward_6: 0.2844538476467139\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 756\n",
      "episode was finished at timestep: 52\n",
      "reward: 7.919263112674958\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.153748087088267\n",
      "reward_2: 0.820135366836188\n",
      "reward_3: 15.500000000000085\n",
      "reward_4: -0.010034818593910871\n",
      "reward_5: -0.00011024881518260088\n",
      "reward_6: 0.28275422179698917\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 757\n",
      "episode was finished at timestep: 118\n",
      "reward: 8.604321691154883\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07473324603504605\n",
      "reward_2: 0.9177037596149695\n",
      "reward_3: 15.500000000000085\n",
      "reward_4: -0.011079335216348199\n",
      "reward_5: -0.004858567969663715\n",
      "reward_6: 0.27938495123386375\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 758\n",
      "episode was finished at timestep: 42\n",
      "reward: 8.694105578476485\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.13016822404331632\n",
      "reward_2: 0.9073459303736566\n",
      "reward_3: 15.900000000000091\n",
      "reward_4: 0.002852013899195498\n",
      "reward_5: -0.0036386046826253943\n",
      "reward_6: 0.2838724049329754\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 759\n",
      "episode was finished at timestep: 130\n",
      "reward: 6.300816210847033\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.16272676057285732\n",
      "reward_2: 0.8546138101410528\n",
      "reward_3: 15.700000000000088\n",
      "reward_4: -0.0012863450295654388\n",
      "reward_5: -0.0046423692813704065\n",
      "reward_6: 0.31401876533031425\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 760\n",
      "episode was finished at timestep: 55\n",
      "reward: 7.154129386801626\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10321124460962083\n",
      "reward_2: 0.9630004436235797\n",
      "reward_3: 15.80000000000009\n",
      "reward_4: 0.006857340190100132\n",
      "reward_5: -0.0032304705631717684\n",
      "reward_6: 0.29317967557907065\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 761\n",
      "episode was finished at timestep: 116\n",
      "reward: 8.629339104176784\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08316934307416281\n",
      "reward_2: 0.9087825872572178\n",
      "reward_3: 15.200000000000081\n",
      "reward_4: 0.0010111329016805825\n",
      "reward_5: -0.002438312300128942\n",
      "reward_6: 0.26823164546489775\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 762\n",
      "episode was finished at timestep: 100\n",
      "reward: 8.244390648945409\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.03768177893426683\n",
      "reward_2: 0.8591865594738929\n",
      "reward_3: 16.350000000000097\n",
      "reward_4: 0.007140935646308293\n",
      "reward_5: -0.005003219995001018\n",
      "reward_6: 0.278912129044534\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 763\n",
      "episode was finished at timestep: 177\n",
      "reward: 7.9068204197927585\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.15611844725079008\n",
      "reward_2: 0.8110992730069739\n",
      "reward_3: 16.100000000000094\n",
      "reward_4: -0.0030580407708674785\n",
      "reward_5: -0.0036653548738097897\n",
      "reward_6: 0.28789080286026025\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 764\n",
      "episode was finished at timestep: 187\n",
      "reward: 8.907557581564713\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08890259199672275\n",
      "reward_2: 0.9432649511104799\n",
      "reward_3: 15.750000000000089\n",
      "reward_4: -0.0006495867401244481\n",
      "reward_5: -0.003766110051949904\n",
      "reward_6: 0.2793981846570964\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 765\n",
      "episode was finished at timestep: 81\n",
      "reward: 6.227900902355139\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10362181067466736\n",
      "reward_2: 0.857353918578547\n",
      "reward_3: 14.900000000000077\n",
      "reward_4: -0.004494358901812205\n",
      "reward_5: -0.0031692759556393685\n",
      "reward_6: 0.30258522355556605\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 766\n",
      "episode was finished at timestep: 1\n",
      "reward: 7.364602933529329\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.16165511939260696\n",
      "reward_2: 0.9957248361125626\n",
      "reward_3: 15.550000000000086\n",
      "reward_4: -0.00890211858017949\n",
      "reward_5: -0.0008701334390597282\n",
      "reward_6: 0.3071628739833837\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 767\n",
      "episode was finished at timestep: 285\n",
      "reward: 6.893696257300032\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.1418480290306939\n",
      "reward_2: 0.6483995394488711\n",
      "reward_3: 14.45000000000007\n",
      "reward_4: 0.0495281951166055\n",
      "reward_5: -0.014570900410414941\n",
      "reward_6: 0.1810705854892738\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 768\n",
      "episode was finished at timestep: 298\n",
      "reward: 6.38566122512387\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08876620597309537\n",
      "reward_2: 0.8795713069585307\n",
      "reward_3: 15.750000000000089\n",
      "reward_4: -0.0035015110264549777\n",
      "reward_5: -0.005814483845839883\n",
      "reward_6: 0.29205113554000806\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 769\n",
      "episode was finished at timestep: 30\n",
      "reward: 6.707444258563136\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.024943690167533027\n",
      "reward_2: 0.6781457969456176\n",
      "reward_3: 15.950000000000092\n",
      "reward_4: 0.0035880645738365045\n",
      "reward_5: -0.006415374144233847\n",
      "reward_6: 0.23291838371753715\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 770\n",
      "episode was finished at timestep: 1\n",
      "reward: 8.428491363093176\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.21735058691766526\n",
      "reward_2: 0.8755243468179816\n",
      "reward_3: 15.300000000000082\n",
      "reward_4: -0.010777420844676725\n",
      "reward_5: -4.892620187900339e-05\n",
      "reward_6: 0.29117429459095034\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 771\n",
      "episode was finished at timestep: 7\n",
      "reward: 9.409412329433144\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.15031901399294537\n",
      "reward_2: 0.9950207493466108\n",
      "reward_3: 16.300000000000097\n",
      "reward_4: 0.006210842429939305\n",
      "reward_5: -0.003195149275601376\n",
      "reward_6: 0.25026239717006593\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 772\n",
      "episode was finished at timestep: 25\n",
      "reward: 5.97445972459053\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06384633183479309\n",
      "reward_2: 0.8218585811442987\n",
      "reward_3: 15.750000000000089\n",
      "reward_4: 0.006252784940215008\n",
      "reward_5: -0.004846439461938464\n",
      "reward_6: 0.28846890354156685\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 773\n",
      "episode was finished at timestep: 156\n",
      "reward: 7.315070238922899\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.053642609384324816\n",
      "reward_2: 0.9984742015484176\n",
      "reward_3: 16.6500000000001\n",
      "reward_4: -0.0027671860211916054\n",
      "reward_5: -0.004448390132687408\n",
      "reward_6: 0.29799989545345307\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 774\n",
      "episode was finished at timestep: 69\n",
      "reward: 8.316637452773517\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.13241302702162\n",
      "reward_2: 0.8581563090796213\n",
      "reward_3: 15.500000000000085\n",
      "reward_4: 0.004239525767825398\n",
      "reward_5: -0.0010097321056518874\n",
      "reward_6: 0.2840008124113077\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 775\n",
      "episode was finished at timestep: 139\n",
      "reward: 6.348008185129898\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09578582512007819\n",
      "reward_2: 0.8656503311245807\n",
      "reward_3: 16.300000000000097\n",
      "reward_4: 0.004736299079172852\n",
      "reward_5: -0.005878031276629988\n",
      "reward_6: 0.2928340163230889\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 776\n",
      "episode was finished at timestep: 56\n",
      "reward: 7.09074425549549\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.11212080981996324\n",
      "reward_2: 0.9629540101917599\n",
      "reward_3: 15.85000000000009\n",
      "reward_4: -0.0029242102587285503\n",
      "reward_5: -0.0009892226670238813\n",
      "reward_6: 0.2972609355449666\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 777\n",
      "episode was finished at timestep: 84\n",
      "reward: 6.767782734514541\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10608663029140897\n",
      "reward_2: 0.9243931238786018\n",
      "reward_3: 16.000000000000092\n",
      "reward_4: -0.003813506994223275\n",
      "reward_5: -0.0006921990248602109\n",
      "reward_6: 0.29561803483963\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 778\n",
      "episode was finished at timestep: 198\n",
      "reward: 6.5849087182156865\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09275976551903618\n",
      "reward_2: 0.9057357868214584\n",
      "reward_3: 16.4500000000001\n",
      "reward_4: -0.006779496396147238\n",
      "reward_5: -0.003823883516863565\n",
      "reward_6: 0.302129179477691\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 779\n",
      "episode was finished at timestep: 30\n",
      "reward: 7.106837426314941\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10083516240119934\n",
      "reward_2: 0.9642509414473664\n",
      "reward_3: 15.700000000000088\n",
      "reward_4: -0.003515157501019104\n",
      "reward_5: -0.001624368482895259\n",
      "reward_6: 0.31964702749252394\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 780\n",
      "episode was finished at timestep: 138\n",
      "reward: 7.584316284184075\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04077434407340156\n",
      "reward_2: 0.785542013387831\n",
      "reward_3: 17.35000000000011\n",
      "reward_4: -0.002545900835765309\n",
      "reward_5: -0.0007526065282842609\n",
      "reward_6: 0.2780123128890992\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 781\n",
      "episode was finished at timestep: 12\n",
      "reward: 7.276415940728864\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.002623728248808119\n",
      "reward_2: 0.7394532902163815\n",
      "reward_3: 15.950000000000092\n",
      "reward_4: 0.0008099680982067525\n",
      "reward_5: 0.09953538931125921\n",
      "reward_6: 0.25527154648303985\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 782\n",
      "episode was finished at timestep: 184\n",
      "reward: 5.074989997999317\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0004157582918802897\n",
      "reward_2: 0.6869024699449133\n",
      "reward_3: 15.400000000000084\n",
      "reward_4: 0.009142533414700438\n",
      "reward_5: 0.21817404469297633\n",
      "reward_6: 0.28681835138797884\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 783\n",
      "episode was finished at timestep: 122\n",
      "reward: 7.566644433038217\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.028395247459411622\n",
      "reward_2: 0.7860120334684148\n",
      "reward_3: 17.25000000000011\n",
      "reward_4: -0.0027926270408859468\n",
      "reward_5: -0.0015503751475707853\n",
      "reward_6: 0.2717443093061448\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 784\n",
      "episode was finished at timestep: 59\n",
      "reward: 5.371202223156285\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0002336316638522678\n",
      "reward_2: 0.6637926263954388\n",
      "reward_3: 11.150000000000023\n",
      "reward_4: 0.032734837362447845\n",
      "reward_5: 0.4857162522965386\n",
      "reward_6: 0.31201322579383817\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 785\n",
      "episode was finished at timestep: 106\n",
      "reward: 9.101736265764012\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06875451736980015\n",
      "reward_2: 0.9521536792495342\n",
      "reward_3: 15.650000000000087\n",
      "reward_4: 0.018501348414901884\n",
      "reward_5: -0.00758956846100555\n",
      "reward_6: 0.27324442887306233\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 786\n",
      "episode was finished at timestep: 88\n",
      "reward: 6.596393168212429\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.12983917792638142\n",
      "reward_2: 0.6516501603747401\n",
      "reward_3: 17.100000000000108\n",
      "reward_4: -0.004536229819640028\n",
      "reward_5: -0.004185642125869767\n",
      "reward_6: 0.2915481879711169\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 787\n",
      "episode was finished at timestep: 210\n",
      "reward: 9.104491277007748\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07284513711929322\n",
      "reward_2: 0.9632517417993469\n",
      "reward_3: 18.00000000000012\n",
      "reward_4: 0.0064640817881098656\n",
      "reward_5: -0.0016537991453679031\n",
      "reward_6: 0.2731733503341677\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 788\n",
      "episode was finished at timestep: 160\n",
      "reward: 7.161947265074994\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.008759178717931112\n",
      "reward_2: 0.9077096178800625\n",
      "reward_3: 14.000000000000064\n",
      "reward_4: 0.050508540452856465\n",
      "reward_5: 0.21990553357901763\n",
      "reward_6: 0.28318897688388833\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 789\n",
      "episode was finished at timestep: 107\n",
      "reward: 6.727366290919927\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.05574199557304382\n",
      "reward_2: 0.9149321628870245\n",
      "reward_3: 16.850000000000104\n",
      "reward_4: 0.006562961366253859\n",
      "reward_5: -0.0033414335499378704\n",
      "reward_6: 0.30075806820392714\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 790\n",
      "episode was finished at timestep: 253\n",
      "reward: 7.154213044164624\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04035942157109578\n",
      "reward_2: 0.978641545806469\n",
      "reward_3: 15.85000000000009\n",
      "reward_4: -0.0010942916639096723\n",
      "reward_5: -0.002551177074439792\n",
      "reward_6: 0.2939134331941601\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 791\n",
      "episode was finished at timestep: 251\n",
      "reward: 6.067428337105358\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0681794868575202\n",
      "reward_2: 0.8402615153003874\n",
      "reward_3: 14.500000000000071\n",
      "reward_4: -0.001406222945209521\n",
      "reward_5: -0.0026986817873375204\n",
      "reward_6: 0.2891718598604197\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 792\n",
      "episode was finished at timestep: 116\n",
      "reward: 6.82207406732326\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.039447925488154095\n",
      "reward_2: 0.9347592957845251\n",
      "reward_3: 17.450000000000113\n",
      "reward_4: 0.0014961838918320326\n",
      "reward_5: -0.0039006295277654126\n",
      "reward_6: 0.29415626728534694\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 793\n",
      "episode was finished at timestep: 293\n",
      "reward: 8.196811507253607\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04701696634292603\n",
      "reward_2: 0.8536457233585291\n",
      "reward_3: 17.700000000000117\n",
      "reward_4: 0.005087604246724311\n",
      "reward_5: -0.002852652331439742\n",
      "reward_6: 0.28042057240009277\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 794\n",
      "episode was finished at timestep: 216\n",
      "reward: 7.632212627264935\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.027553557025061712\n",
      "reward_2: 0.7834410467447894\n",
      "reward_3: 19.000000000000135\n",
      "reward_4: 0.007391011498861105\n",
      "reward_5: -0.0004462971559910045\n",
      "reward_6: 0.2759155681133265\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 795\n",
      "episode was finished at timestep: 315\n",
      "reward: 9.12875678233194\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09848854475551182\n",
      "reward_2: 0.9669108887986118\n",
      "reward_3: 17.35000000000011\n",
      "reward_4: 0.0016908933845289197\n",
      "reward_5: -0.003093981064931602\n",
      "reward_6: 0.28223462784290265\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 796\n",
      "episode was finished at timestep: 265\n",
      "reward: 8.435878143789365\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0714182992776235\n",
      "reward_2: 0.8875766776477739\n",
      "reward_3: 17.800000000000118\n",
      "reward_4: -0.0027915165774471972\n",
      "reward_5: -0.002604099646016067\n",
      "reward_6: 0.2864093222618108\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 797\n",
      "episode was finished at timestep: 357\n",
      "reward: 6.961503545866387\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.03941086133321126\n",
      "reward_2: 0.7004992856590295\n",
      "reward_3: 17.95000000000012\n",
      "reward_4: 0.00535441491298684\n",
      "reward_5: -0.0033391329663218744\n",
      "reward_6: 0.27620887959003415\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 798\n",
      "episode was finished at timestep: 329\n",
      "reward: 6.910127906571386\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04571559296713935\n",
      "reward_2: 0.6960675140649468\n",
      "reward_3: 18.70000000000013\n",
      "reward_4: 0.0018767208115347954\n",
      "reward_5: -0.0012342091390421454\n",
      "reward_6: 0.27959931039810215\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 799\n",
      "episode was finished at timestep: 200\n",
      "reward: 8.417661481822952\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07294250395562914\n",
      "reward_2: 0.87613743381259\n",
      "reward_3: 14.050000000000065\n",
      "reward_4: 0.007935805822728952\n",
      "reward_5: -0.0017751086024091478\n",
      "reward_6: 0.2720348360538476\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 800\n",
      "episode was finished at timestep: 200\n",
      "reward: 7.551078324415452\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04643903109762404\n",
      "reward_2: 0.7739862375775629\n",
      "reward_3: 18.100000000000122\n",
      "reward_4: 0.004149795129805085\n",
      "reward_5: -0.004537856426798825\n",
      "reward_6: 0.28167555475234984\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 801\n",
      "episode was finished at timestep: 148\n",
      "reward: 7.099849520788412\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0005986849466959635\n",
      "reward_2: 0.685370618629791\n",
      "reward_3: 15.450000000000085\n",
      "reward_4: 0.01914555845013723\n",
      "reward_5: 0.18521405271033775\n",
      "reward_6: 0.2770447363853449\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 802\n",
      "episode was finished at timestep: 196\n",
      "reward: 9.04620522629438\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.042599889967176646\n",
      "reward_2: 0.9630759888183409\n",
      "reward_3: 14.650000000000073\n",
      "reward_4: 0.0022249522739977577\n",
      "reward_5: -0.0036206050285529775\n",
      "reward_6: 0.2828650792837143\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 803\n",
      "episode was finished at timestep: 186\n",
      "reward: 6.638308939863387\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04549330472946167\n",
      "reward_2: 0.9061351514705549\n",
      "reward_3: 15.15000000000008\n",
      "reward_4: 0.0076011614207449445\n",
      "reward_5: -0.004428277544278932\n",
      "reward_6: 0.2853334095478063\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 804\n",
      "episode was finished at timestep: 27\n",
      "reward: 7.237298721082152\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0489698158370124\n",
      "reward_2: 0.729759736137227\n",
      "reward_3: 18.250000000000124\n",
      "reward_4: 0.010136276629534677\n",
      "reward_5: -0.001106125140537865\n",
      "reward_6: 0.2678335949182511\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 805\n",
      "episode was finished at timestep: 364\n",
      "reward: 7.080737614490187\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06556177536646525\n",
      "reward_2: 0.6988024932621644\n",
      "reward_3: 18.75000000000013\n",
      "reward_4: 0.019439472913605583\n",
      "reward_5: -0.0023202530982962583\n",
      "reward_6: 0.26906036281585755\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 806\n",
      "episode was finished at timestep: 88\n",
      "reward: 9.164617771557277\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08351552552647061\n",
      "reward_2: 0.9679779112527565\n",
      "reward_3: 15.900000000000091\n",
      "reward_4: 0.008923661063077048\n",
      "reward_5: -0.007377252461605366\n",
      "reward_6: 0.2711469199657437\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 807\n",
      "episode was finished at timestep: 125\n",
      "reward: 7.775241189064528\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0397589557700687\n",
      "reward_2: 0.7996906310159145\n",
      "reward_3: 18.850000000000133\n",
      "reward_4: 0.007317275957038873\n",
      "reward_5: -0.004057178498205734\n",
      "reward_6: 0.28096282267570416\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 808\n",
      "episode was finished at timestep: 101\n",
      "reward: 7.687620294752071\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.029656628767649334\n",
      "reward_2: 0.8026342397794665\n",
      "reward_3: 18.200000000000124\n",
      "reward_4: -0.005023944063168386\n",
      "reward_5: -0.0021073580326936773\n",
      "reward_6: 0.2767619916200643\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 809\n",
      "episode was finished at timestep: 232\n",
      "reward: 9.327210871115104\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0963672935962677\n",
      "reward_2: 0.9936647589037936\n",
      "reward_3: 16.750000000000103\n",
      "reward_4: 0.00039982514322588257\n",
      "reward_5: -0.0014539088930508371\n",
      "reward_6: 0.2775474807024001\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 810\n",
      "episode was finished at timestep: 171\n",
      "reward: 7.379648537098563\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.03611169854799907\n",
      "reward_2: 0.7559115824550027\n",
      "reward_3: 17.700000000000117\n",
      "reward_4: 0.0031652350329106583\n",
      "reward_5: -0.006106202014591134\n",
      "reward_6: 0.2746685006618491\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 811\n",
      "episode was finished at timestep: 210\n",
      "reward: 4.295058570682895\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.013159296247694227\n",
      "reward_2: 0.6211226716949373\n",
      "reward_3: 18.900000000000134\n",
      "reward_4: 0.0026087633603178516\n",
      "reward_5: -0.0035817662580776973\n",
      "reward_6: 0.2931095602512367\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 812\n",
      "episode was finished at timestep: 28\n",
      "reward: 8.439967835786703\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09669589466518826\n",
      "reward_2: 0.8861140079107331\n",
      "reward_3: 16.050000000000093\n",
      "reward_4: -0.003733254357676401\n",
      "reward_5: -0.003976843126074077\n",
      "reward_6: 0.286062755823135\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 813\n",
      "episode was finished at timestep: 57\n",
      "reward: 5.768228102642869\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10270584887928433\n",
      "reward_2: 0.789892395115688\n",
      "reward_3: 15.80000000000009\n",
      "reward_4: 0.006875815933771037\n",
      "reward_5: -0.006817597817844027\n",
      "reward_6: 0.2960874965190896\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 814\n",
      "episode was finished at timestep: 5\n",
      "reward: 6.528111031353064\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0779940062099033\n",
      "reward_2: 0.8994190850771056\n",
      "reward_3: 16.350000000000097\n",
      "reward_4: -0.004560179282294712\n",
      "reward_5: -0.004838755436020511\n",
      "reward_6: 0.29390453422069474\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 815\n",
      "episode was finished at timestep: 72\n",
      "reward: 5.2019361109777265\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.015245805846320258\n",
      "reward_2: 0.7318107977979764\n",
      "reward_3: 18.400000000000126\n",
      "reward_4: 0.006157066681405751\n",
      "reward_5: -6.948592617443221e-05\n",
      "reward_6: 0.2805635418891901\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 816\n",
      "episode was finished at timestep: 71\n",
      "reward: 8.235706233527798\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08662528660562303\n",
      "reward_2: 0.8530312948578256\n",
      "reward_3: 17.550000000000114\n",
      "reward_4: 0.005116727052434129\n",
      "reward_5: -0.0008195215422748703\n",
      "reward_6: 0.2823762931823728\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 817\n",
      "episode was finished at timestep: 271\n",
      "reward: 8.981542312796538\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09596875177489386\n",
      "reward_2: 0.9506919350329287\n",
      "reward_3: 15.500000000000085\n",
      "reward_4: -0.0010164642619672293\n",
      "reward_5: -0.0011343481615907554\n",
      "reward_6: 0.2872374763488774\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 818\n",
      "episode was finished at timestep: 39\n",
      "reward: 8.99326776204893\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06304484142197503\n",
      "reward_2: 0.9552392046552278\n",
      "reward_3: 16.6500000000001\n",
      "reward_4: 0.0007500581568409359\n",
      "reward_5: -0.00522649842747794\n",
      "reward_6: 0.285315316557884\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 819\n",
      "episode was finished at timestep: 29\n",
      "reward: 9.244915269022368\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07965643604596456\n",
      "reward_2: 0.9834188971974374\n",
      "reward_3: 16.400000000000098\n",
      "reward_4: 0.0018594841487282565\n",
      "reward_5: -0.0055256514569266574\n",
      "reward_6: 0.2863707669973383\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 820\n",
      "episode was finished at timestep: 340\n",
      "reward: 9.015183875053275\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07638449801339044\n",
      "reward_2: 0.9589283728941368\n",
      "reward_3: 17.85000000000012\n",
      "reward_4: -0.0007772224321736587\n",
      "reward_5: -0.002499561572507858\n",
      "reward_6: 0.27370973491668693\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 821\n",
      "episode was finished at timestep: 102\n",
      "reward: 7.289273930252039\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07053864730728997\n",
      "reward_2: 0.9866169318262903\n",
      "reward_3: 17.20000000000011\n",
      "reward_4: 0.004946767950427784\n",
      "reward_5: -0.004707398129306265\n",
      "reward_6: 0.28863974952697713\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 822\n",
      "episode was finished at timestep: 180\n",
      "reward: 8.826603893306306\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08125874532593622\n",
      "reward_2: 0.9361321311912961\n",
      "reward_3: 16.4500000000001\n",
      "reward_4: -2.8671799608588344e-05\n",
      "reward_5: -0.005829978666739185\n",
      "reward_6: 0.26015411818027556\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 823\n",
      "episode was finished at timestep: 94\n",
      "reward: 8.789832502949377\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10795898172590468\n",
      "reward_2: 0.9275190143011176\n",
      "reward_3: 16.100000000000094\n",
      "reward_4: -0.00497418492554317\n",
      "reward_5: -0.00032296246511881086\n",
      "reward_6: 0.29969118201732725\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 824\n",
      "episode was finished at timestep: 291\n",
      "reward: 8.07529205163414\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06762511862648858\n",
      "reward_2: 0.8442339555209634\n",
      "reward_3: 16.700000000000102\n",
      "reward_4: -0.001885843867851662\n",
      "reward_5: -0.0031301857036802735\n",
      "reward_6: 0.2697855588197712\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 825\n",
      "episode was finished at timestep: 157\n",
      "reward: 8.443680890147832\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06336104604932997\n",
      "reward_2: 0.8853108270806918\n",
      "reward_3: 18.55000000000013\n",
      "reward_4: 0.0016666720924548883\n",
      "reward_5: -5.952369455641815e-06\n",
      "reward_6: 0.2820324697494515\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 826\n",
      "episode was finished at timestep: 145\n",
      "reward: 7.605202403132217\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.03919428454505073\n",
      "reward_2: 0.7854164535791469\n",
      "reward_3: 17.600000000000115\n",
      "reward_4: 0.0007919835248499396\n",
      "reward_5: -0.0025633684864955577\n",
      "reward_6: 0.2765573235750196\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 827\n",
      "episode was finished at timestep: 224\n",
      "reward: 6.002817649367272\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06723072793748644\n",
      "reward_2: 0.8300268771764993\n",
      "reward_3: 17.35000000000011\n",
      "reward_4: -1.6251691392881183e-05\n",
      "reward_5: -0.003123503201047484\n",
      "reward_6: 0.29631208741664883\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 828\n",
      "episode was finished at timestep: 196\n",
      "reward: 8.6869091424336\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07008294529385037\n",
      "reward_2: 0.9189375959664167\n",
      "reward_3: 18.400000000000126\n",
      "reward_4: -0.0012889315379115375\n",
      "reward_5: -0.0026079061752287912\n",
      "reward_6: 0.27579145455360343\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 829\n",
      "episode was finished at timestep: 262\n",
      "reward: 9.090077056085159\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0714577317237854\n",
      "reward_2: 0.9710319199056723\n",
      "reward_3: 17.750000000000117\n",
      "reward_4: -0.0029313931205047082\n",
      "reward_5: -0.002894819735897158\n",
      "reward_6: 0.2743432631492616\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 830\n",
      "episode was finished at timestep: 211\n",
      "reward: 8.815805760045624\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09104972746637133\n",
      "reward_2: 0.9335438069733847\n",
      "reward_3: 16.5000000000001\n",
      "reward_4: -0.0016054556196613134\n",
      "reward_5: -0.0031188182876920934\n",
      "reward_6: 0.27016804003715644\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 831\n",
      "episode was finished at timestep: 169\n",
      "reward: 8.874482284285707\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09479703505833943\n",
      "reward_2: 0.9388651397192366\n",
      "reward_3: 18.400000000000126\n",
      "reward_4: -0.0021927463649028312\n",
      "reward_5: -0.0007563623960573788\n",
      "reward_6: 0.28460913145542155\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 832\n",
      "episode was finished at timestep: 185\n",
      "reward: 8.391009444916865\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06064617964956495\n",
      "reward_2: 0.8788939559528789\n",
      "reward_3: 19.000000000000135\n",
      "reward_4: 0.0020919785200456432\n",
      "reward_5: -0.000904598807773264\n",
      "reward_6: 0.2808470549583444\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 833\n",
      "episode was finished at timestep: 39\n",
      "reward: 9.108110898025618\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07584361831347147\n",
      "reward_2: 0.9747719584582063\n",
      "reward_3: 17.30000000000011\n",
      "reward_4: -0.002761437414149839\n",
      "reward_5: -0.0039452161832448\n",
      "reward_6: 0.25782166087627445\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 834\n",
      "episode was finished at timestep: 223\n",
      "reward: 8.98925320644632\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06204190916485257\n",
      "reward_2: 0.9529790621848123\n",
      "reward_3: 19.150000000000137\n",
      "reward_4: 0.002979558557649682\n",
      "reward_5: -0.0009681215756463265\n",
      "reward_6: 0.277957119584084\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 835\n",
      "episode was finished at timestep: 85\n",
      "reward: 9.229157418355799\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07362009618017408\n",
      "reward_2: 0.9837806995663699\n",
      "reward_3: 18.500000000000128\n",
      "reward_4: 0.00016233887277152803\n",
      "reward_5: -0.0023856880654623326\n",
      "reward_6: 0.28391203606128734\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 836\n",
      "episode was finished at timestep: 140\n",
      "reward: 7.507728997344527\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.031992172532611426\n",
      "reward_2: 0.7709536325694455\n",
      "reward_3: 18.500000000000128\n",
      "reward_4: 0.0035158810885823756\n",
      "reward_5: -0.0012888308100979628\n",
      "reward_6: 0.2788028796911246\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 837\n",
      "episode was finished at timestep: 30\n",
      "reward: 8.549682505477165\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08535977668232388\n",
      "reward_2: 0.9006164463737726\n",
      "reward_3: 18.00000000000012\n",
      "reward_4: -0.003131593225507743\n",
      "reward_5: -0.0033677376313982895\n",
      "reward_6: 0.2854116412401202\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 838\n",
      "episode was finished at timestep: 33\n",
      "reward: 8.937415401519353\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07362138430277507\n",
      "reward_2: 0.9496585121329749\n",
      "reward_3: 18.200000000000124\n",
      "reward_4: -8.867937009469528e-05\n",
      "reward_5: -0.003063703134665611\n",
      "reward_6: 0.2678723915815344\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 839\n",
      "episode was finished at timestep: 20\n",
      "reward: 8.456084476500113\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06533640954229566\n",
      "reward_2: 0.8874866213121472\n",
      "reward_3: 18.60000000000013\n",
      "reward_4: 0.0014927154683336142\n",
      "reward_5: -0.003819781563831981\n",
      "reward_6: 0.28025315427780195\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 840\n",
      "episode was finished at timestep: 245\n",
      "reward: 8.634570801829604\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.05761844913164774\n",
      "reward_2: 0.9095721964786613\n",
      "reward_3: 18.350000000000126\n",
      "reward_4: 0.0030356710507203387\n",
      "reward_5: -0.0029301733340897584\n",
      "reward_6: 0.2765729191303251\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 841\n",
      "episode was finished at timestep: 182\n",
      "reward: 8.070976677218768\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04899011850357056\n",
      "reward_2: 0.8409018592919942\n",
      "reward_3: 18.55000000000013\n",
      "reward_4: 0.0024852556121714997\n",
      "reward_5: -0.003985272873869524\n",
      "reward_6: 0.2764015790224079\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 842\n",
      "episode was finished at timestep: 269\n",
      "reward: 7.949651978451167\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04869760870933533\n",
      "reward_2: 0.8265271133611227\n",
      "reward_3: 18.100000000000122\n",
      "reward_4: 0.001355645585378653\n",
      "reward_5: -0.0010877405096213267\n",
      "reward_6: 0.27656670534610783\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 843\n",
      "episode was finished at timestep: 258\n",
      "reward: 8.688187646233178\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.05472165677282545\n",
      "reward_2: 0.917976578879266\n",
      "reward_3: 17.95000000000012\n",
      "reward_4: 0.0021255413931389453\n",
      "reward_5: -0.001073215687764891\n",
      "reward_6: 0.2713289096355441\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 844\n",
      "episode was finished at timestep: 235\n",
      "reward: 8.65405036242204\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.059692529837290446\n",
      "reward_2: 0.9130053399738459\n",
      "reward_3: 18.75000000000013\n",
      "reward_4: 0.0025082961197742293\n",
      "reward_5: -0.0017401853166990832\n",
      "reward_6: 0.2694889291524887\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 845\n",
      "episode was finished at timestep: 261\n",
      "reward: 9.099253893294463\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09038766821225484\n",
      "reward_2: 0.9630509089770506\n",
      "reward_3: 17.90000000000012\n",
      "reward_4: 0.0032143676985239723\n",
      "reward_5: -0.00466262481003111\n",
      "reward_6: 0.2810199698209773\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 846\n",
      "episode was finished at timestep: 290\n",
      "reward: 8.204763446396239\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06469618346956041\n",
      "reward_2: 0.8572474555086862\n",
      "reward_3: 18.60000000000013\n",
      "reward_4: 0.0024905123753511307\n",
      "reward_5: -0.004322157488033677\n",
      "reward_6: 0.264005677342414\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 847\n",
      "episode was finished at timestep: 354\n",
      "reward: 8.203623417016813\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07442106339666578\n",
      "reward_2: 0.8533026261514307\n",
      "reward_3: 18.950000000000134\n",
      "reward_4: 0.004288859103548504\n",
      "reward_5: -0.0036033329428376486\n",
      "reward_6: 0.26954713785648354\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 848\n",
      "episode was finished at timestep: 275\n",
      "reward: 9.064022223178423\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.11307189795706007\n",
      "reward_2: 0.9519629564546633\n",
      "reward_3: 19.000000000000135\n",
      "reward_4: 0.006182884799947743\n",
      "reward_5: -0.005113511614015564\n",
      "reward_6: 0.2883637734651562\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 849\n",
      "episode was finished at timestep: 318\n",
      "reward: 5.887652149563543\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04269131686952379\n",
      "reward_2: 0.8137139850843018\n",
      "reward_3: 18.900000000000134\n",
      "reward_4: 0.005608566134635282\n",
      "reward_5: -0.002378228333111328\n",
      "reward_6: 0.29023865127563375\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 850\n",
      "episode was finished at timestep: 100\n",
      "reward: 7.757028009657603\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08499558568000794\n",
      "reward_2: 0.7513980900188295\n",
      "reward_3: 16.250000000000096\n",
      "reward_4: 0.048470058970710855\n",
      "reward_5: -0.01083900985315971\n",
      "reward_6: 0.2817595752477654\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 851\n",
      "episode was finished at timestep: 86\n",
      "reward: 8.14383353376057\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.043774139218860204\n",
      "reward_2: 0.8493291813057493\n",
      "reward_3: 17.85000000000012\n",
      "reward_4: 0.006256641943659673\n",
      "reward_5: -0.004107590232477184\n",
      "reward_6: 0.2571003987789151\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 852\n",
      "episode was finished at timestep: 227\n",
      "reward: 7.415372409382768\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.03034257690111796\n",
      "reward_2: 0.7555560921764456\n",
      "reward_3: 18.400000000000126\n",
      "reward_4: 0.009268768323555747\n",
      "reward_5: -0.0014276787931906418\n",
      "reward_6: 0.26540529394149703\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 853\n",
      "episode was finished at timestep: 301\n",
      "reward: 8.363431486973273\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.076702524556054\n",
      "reward_2: 0.8897985345128309\n",
      "reward_3: 19.550000000000143\n",
      "reward_4: -0.01408490486085924\n",
      "reward_5: -0.0031209986387600234\n",
      "reward_6: 0.2815342571735384\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 854\n",
      "episode was finished at timestep: 353\n",
      "reward: 7.0898097461793945\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.023551946216159397\n",
      "reward_2: 0.7148399407422963\n",
      "reward_3: 18.60000000000013\n",
      "reward_4: 0.008836298277408616\n",
      "reward_5: -0.0028046254409418952\n",
      "reward_6: 0.2771725132465377\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 855\n",
      "episode was finished at timestep: 6\n",
      "reward: 8.576035729589043\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.05583454966545105\n",
      "reward_2: 0.8983479958632763\n",
      "reward_3: 19.000000000000135\n",
      "reward_4: 0.007383530444785577\n",
      "reward_5: -0.00451912847403797\n",
      "reward_6: 0.2763347645998011\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 856\n",
      "episode was finished at timestep: 359\n",
      "reward: 8.56119397249639\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06554528342352973\n",
      "reward_2: 0.8981464699264631\n",
      "reward_3: 18.250000000000124\n",
      "reward_4: 0.0049339334578174035\n",
      "reward_5: -0.005190258014365767\n",
      "reward_6: 0.27376238667964947\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 857\n",
      "episode was finished at timestep: 47\n",
      "reward: 6.3992330689696315\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.05769325693448384\n",
      "reward_2: 0.874495141296274\n",
      "reward_3: 19.30000000000014\n",
      "reward_4: 0.007488443514318703\n",
      "reward_5: -0.002146920599540062\n",
      "reward_6: 0.28524472081661323\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 858\n",
      "episode was finished at timestep: 121\n",
      "reward: 8.349163345415676\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07965839372740852\n",
      "reward_2: 0.8681523234526818\n",
      "reward_3: 19.45000000000014\n",
      "reward_4: 0.004945388432195159\n",
      "reward_5: -0.001995185085326649\n",
      "reward_6: 0.2841251083612444\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 859\n",
      "episode was finished at timestep: 125\n",
      "reward: 8.529673593235522\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.05336186554696825\n",
      "reward_2: 0.8928302736774734\n",
      "reward_3: 19.25000000000014\n",
      "reward_4: 0.006947620233849534\n",
      "reward_5: -0.002509198290432006\n",
      "reward_6: 0.2780311080217358\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 860\n",
      "episode was finished at timestep: 9\n",
      "reward: 8.957628310509966\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10282114677959019\n",
      "reward_2: 0.9404293316277847\n",
      "reward_3: 19.150000000000137\n",
      "reward_4: 0.005027008573992191\n",
      "reward_5: -0.003024159054697388\n",
      "reward_6: 0.2916272678375239\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 861\n",
      "episode was finished at timestep: 84\n",
      "reward: 6.686288767934001\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0702785160806444\n",
      "reward_2: 0.9035826381404721\n",
      "reward_3: 19.000000000000135\n",
      "reward_4: 0.01137574497506975\n",
      "reward_5: -0.0007211707411264238\n",
      "reward_6: 0.29453102433681444\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 862\n",
      "episode was finished at timestep: 91\n",
      "reward: 7.733580681425087\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.12179446617762248\n",
      "reward_2: 0.7906600478288516\n",
      "reward_3: 19.30000000000014\n",
      "reward_4: -0.00048319908754692166\n",
      "reward_5: -0.00041472139368667154\n",
      "reward_6: 0.28821281337738025\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 863\n",
      "episode was finished at timestep: 181\n",
      "reward: 9.011939364019604\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0577086607615153\n",
      "reward_2: 0.9569720510485411\n",
      "reward_3: 19.30000000000014\n",
      "reward_4: 0.003891432419759582\n",
      "reward_5: -0.0015599602497420762\n",
      "reward_6: 0.26630946242809317\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 864\n",
      "episode was finished at timestep: 13\n",
      "reward: 8.805109276283968\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.11992930703692967\n",
      "reward_2: 0.9177845964570215\n",
      "reward_3: 18.400000000000126\n",
      "reward_4: 0.00723542929821761\n",
      "reward_5: -0.003033631783253199\n",
      "reward_6: 0.2856000616550447\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 865\n",
      "episode was finished at timestep: 343\n",
      "reward: 7.014755764155406\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10212805204921299\n",
      "reward_2: 0.6904631016338657\n",
      "reward_3: 19.25000000000014\n",
      "reward_4: 0.011638592145709623\n",
      "reward_5: -0.0009202912760720494\n",
      "reward_6: 0.2941677864789959\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 866\n",
      "episode was finished at timestep: 190\n",
      "reward: 7.1108855177300025\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0021109329329596625\n",
      "reward_2: 0.6550631702113356\n",
      "reward_3: 10.550000000000015\n",
      "reward_4: 0.00877805367867154\n",
      "reward_5: 0.5357115705158172\n",
      "reward_6: 0.26514842236042\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 867\n",
      "episode was finished at timestep: 67\n",
      "reward: 8.859535178911022\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06413027577930026\n",
      "reward_2: 0.9302354077116135\n",
      "reward_3: 19.050000000000136\n",
      "reward_4: 0.010149580881624303\n",
      "reward_5: -0.0021848237294140203\n",
      "reward_6: 0.27196981811523335\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 868\n",
      "episode was finished at timestep: 184\n",
      "reward: 8.84357262228401\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.056769765747918026\n",
      "reward_2: 0.9349128216756506\n",
      "reward_3: 18.400000000000126\n",
      "reward_4: 0.004607107707767852\n",
      "reward_5: -0.0012311963017712201\n",
      "reward_6: 0.2694212844371805\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 869\n",
      "episode was finished at timestep: 338\n",
      "reward: 9.370628940461891\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09062822924719917\n",
      "reward_2: 0.9905335645228437\n",
      "reward_3: 19.45000000000014\n",
      "reward_4: 0.009071633285114587\n",
      "reward_5: -0.003602562073801489\n",
      "reward_6: 0.28416835749149316\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 870\n",
      "episode was finished at timestep: 77\n",
      "reward: 8.662504305864314\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10990740723080106\n",
      "reward_2: 0.9134086002463615\n",
      "reward_3: 19.45000000000014\n",
      "reward_4: -0.004963140472620182\n",
      "reward_5: -0.0034490967354624757\n",
      "reward_6: 0.2858889838457108\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 871\n",
      "episode was finished at timestep: 138\n",
      "reward: 6.3750454238390715\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.05224489437209235\n",
      "reward_2: 0.8684905951414738\n",
      "reward_3: 19.500000000000142\n",
      "reward_4: 0.010486616542276152\n",
      "reward_5: -0.003516598569517626\n",
      "reward_6: 0.2918994345664977\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 872\n",
      "episode was finished at timestep: 131\n",
      "reward: 7.480160097848633\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10352638628747728\n",
      "reward_2: 0.9976575462832995\n",
      "reward_3: 19.650000000000144\n",
      "reward_4: 0.01181409677649654\n",
      "reward_5: -0.003835993414496504\n",
      "reward_6: 0.30207656049728393\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 873\n",
      "episode was finished at timestep: 94\n",
      "reward: 8.250035065969884\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.03383809063169691\n",
      "reward_2: 0.8596470020085027\n",
      "reward_3: 19.150000000000137\n",
      "reward_4: 0.01015533906703567\n",
      "reward_5: -0.0033910574494451376\n",
      "reward_6: 0.2586159708499909\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 874\n",
      "episode was finished at timestep: 367\n",
      "reward: 9.202219950151996\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07052438259124756\n",
      "reward_2: 0.9799981570717691\n",
      "reward_3: 18.55000000000013\n",
      "reward_4: 0.002813365426184191\n",
      "reward_5: -0.004978947058930198\n",
      "reward_6: 0.27170900130271847\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 875\n",
      "episode was finished at timestep: 378\n",
      "reward: 9.316965393021547\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08184833857748243\n",
      "reward_2: 0.9894669149764139\n",
      "reward_3: 18.950000000000134\n",
      "reward_4: 0.006223419242664363\n",
      "reward_5: -0.0054827868449779755\n",
      "reward_6: 0.27255050086974986\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 876\n",
      "episode was finished at timestep: 246\n",
      "reward: 8.785520688374717\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06580135424931845\n",
      "reward_2: 0.9257066903276165\n",
      "reward_3: 19.500000000000142\n",
      "reward_4: 0.004791980310354092\n",
      "reward_5: -0.0021340172082619326\n",
      "reward_6: 0.275263986229896\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 877\n",
      "episode was finished at timestep: 307\n",
      "reward: 5.887239391915674\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08259779545995924\n",
      "reward_2: 0.8174348875561407\n",
      "reward_3: 16.250000000000096\n",
      "reward_4: -0.0033770338470311854\n",
      "reward_5: -0.007019025548538712\n",
      "reward_6: 0.2970311256647108\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 878\n",
      "episode was finished at timestep: 1\n",
      "reward: 7.118869111228588\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06744300590621101\n",
      "reward_2: 0.9770383591600591\n",
      "reward_3: 19.100000000000136\n",
      "reward_4: -0.009219958012233036\n",
      "reward_5: -0.00030059411336367246\n",
      "reward_6: 0.30663282358646493\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 879\n",
      "episode was finished at timestep: 87\n",
      "reward: 8.597128642775408\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.05796982712215847\n",
      "reward_2: 0.9043463290836223\n",
      "reward_3: 19.050000000000136\n",
      "reward_4: 0.005276956300489104\n",
      "reward_5: -0.004055373327274244\n",
      "reward_6: 0.26368790590763114\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 880\n",
      "episode was finished at timestep: 226\n",
      "reward: 9.16068789842841\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08145945204628838\n",
      "reward_2: 0.9710401778071731\n",
      "reward_3: 18.65000000000013\n",
      "reward_4: 0.005256061816328099\n",
      "reward_5: -0.006690611642557087\n",
      "reward_6: 0.2730624743700031\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 881\n",
      "episode was finished at timestep: 77\n",
      "reward: 8.27301486384786\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.05583478742175632\n",
      "reward_2: 0.8591690677308798\n",
      "reward_3: 19.35000000000014\n",
      "reward_4: 0.0076705444496560915\n",
      "reward_5: -0.0014297190580011925\n",
      "reward_6: 0.2813128980398182\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 882\n",
      "episode was finished at timestep: 300\n",
      "reward: 6.075420781945601\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.05707622634039985\n",
      "reward_2: 0.8288141953513719\n",
      "reward_3: 19.900000000000148\n",
      "reward_4: 0.012405471166444783\n",
      "reward_5: -9.106740831548166e-05\n",
      "reward_6: 0.28602495753765\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 883\n",
      "episode was finished at timestep: 156\n",
      "reward: 6.227339265182183\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.1496436960167355\n",
      "reward_2: 0.6176409657215283\n",
      "reward_3: 18.05000000000012\n",
      "reward_4: -0.0037969700860162447\n",
      "reward_5: -0.001621332467518144\n",
      "reward_6: 0.16615826988220217\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 884\n",
      "episode was finished at timestep: 153\n",
      "reward: -79.42035252712584\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.14586865637037488\n",
      "reward_2: -10\n",
      "reward_3: 13.100000000000051\n",
      "reward_4: 0.10009133859619539\n",
      "reward_5: 0.3175204154194373\n",
      "reward_6: 0.3137810256481177\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 885\n",
      "episode was finished at timestep: 329\n",
      "reward: 8.046422671694904\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0913034717241923\n",
      "reward_2: 0.8433632659844958\n",
      "reward_3: 19.100000000000136\n",
      "reward_4: -0.0027152134716499176\n",
      "reward_5: -0.004535547077041831\n",
      "reward_6: 0.23192366027832034\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 886\n",
      "episode was finished at timestep: 294\n",
      "reward: 9.130175434655863\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06890937752193875\n",
      "reward_2: 0.9655476220984308\n",
      "reward_3: 19.650000000000144\n",
      "reward_4: 0.008083857720994417\n",
      "reward_5: -0.003153539690789368\n",
      "reward_6: 0.27274775826931064\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 887\n",
      "episode was finished at timestep: 30\n",
      "reward: 9.20428636052633\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -2.85241338941786e-05\n",
      "reward_2: 0.9631022282214936\n",
      "reward_3: 17.750000000000117\n",
      "reward_4: 0.010641661318272213\n",
      "reward_5: 0.15552569938794783\n",
      "reward_6: 0.2564714022874828\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 888\n",
      "episode was finished at timestep: 299\n",
      "reward: 7.203760439876764\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.027875603569878473\n",
      "reward_2: 0.7325415295133159\n",
      "reward_3: 19.25000000000014\n",
      "reward_4: 0.0046955011163582585\n",
      "reward_5: -0.0016592874409353678\n",
      "reward_6: 0.2770812120437611\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 889\n",
      "episode was finished at timestep: 253\n",
      "reward: 8.61391203341838\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0582490066687266\n",
      "reward_2: 0.8989049115074504\n",
      "reward_3: 19.750000000000146\n",
      "reward_4: 0.010552754684560739\n",
      "reward_5: -0.00334852764694548\n",
      "reward_6: 0.2807168915271754\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 890\n",
      "episode was finished at timestep: 256\n",
      "reward: 6.488604766465651\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.008950207630793254\n",
      "reward_2: 0.6337599623602799\n",
      "reward_3: 19.750000000000146\n",
      "reward_4: 0.016911573074602018\n",
      "reward_5: -5.672559246730676e-05\n",
      "reward_6: 0.27170566761493775\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 891\n",
      "episode was finished at timestep: 174\n",
      "reward: 6.698395785466246\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.01861229803827074\n",
      "reward_2: 0.6596411110880245\n",
      "reward_3: 20.15000000000015\n",
      "reward_4: 0.015739659996709038\n",
      "reward_5: -0.0009497612151646943\n",
      "reward_6: 0.2750004132986058\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 892\n",
      "episode was finished at timestep: 91\n",
      "reward: 8.994138793615786\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08478212224112616\n",
      "reward_2: 0.9490102449175872\n",
      "reward_3: 18.65000000000013\n",
      "reward_4: 0.004148210629896027\n",
      "reward_5: -0.001175241390775028\n",
      "reward_6: 0.28277760171890287\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 893\n",
      "episode was finished at timestep: 27\n",
      "reward: 6.1375814167806\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06010627349217733\n",
      "reward_2: 0.8402189041873396\n",
      "reward_3: 19.650000000000144\n",
      "reward_4: 0.007917460798645238\n",
      "reward_5: -0.0017962031922830117\n",
      "reward_6: 0.2915604265928272\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 894\n",
      "episode was finished at timestep: 46\n",
      "reward: 9.22379447421808\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07656351062986586\n",
      "reward_2: 0.9791499926718886\n",
      "reward_3: 19.550000000000143\n",
      "reward_4: 0.0035235542858718816\n",
      "reward_5: -0.0005390813392997036\n",
      "reward_6: 0.283775002598764\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 895\n",
      "episode was finished at timestep: 256\n",
      "reward: 7.076941966126426\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.13311258024639552\n",
      "reward_2: 0.7117594067837201\n",
      "reward_3: 18.60000000000013\n",
      "reward_4: -0.0009553182650699909\n",
      "reward_5: -0.0007869094435855336\n",
      "reward_6: 0.25570358717441544\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 896\n",
      "episode was finished at timestep: 251\n",
      "reward: -78.40631126342917\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.12176399827003478\n",
      "reward_2: -10\n",
      "reward_3: 16.700000000000102\n",
      "reward_4: 0.02705733349442468\n",
      "reward_5: 0.08345058686907501\n",
      "reward_6: 0.16978881680965519\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 897\n",
      "episode was finished at timestep: 262\n",
      "reward: 8.624818353237073\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.12605924142731562\n",
      "reward_2: 0.9068694142434912\n",
      "reward_3: 19.30000000000014\n",
      "reward_4: -0.005494936873021601\n",
      "reward_5: -0.003643715514227826\n",
      "reward_6: 0.2888336750268943\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 898\n",
      "episode was finished at timestep: 284\n",
      "reward: 8.00194367084502\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08541241818004185\n",
      "reward_2: 0.8253091684452002\n",
      "reward_3: 18.65000000000013\n",
      "reward_4: 0.006992936231498845\n",
      "reward_5: -0.001203862452536697\n",
      "reward_6: 0.2568316110372545\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 899\n",
      "episode was finished at timestep: 319\n",
      "reward: 8.73655030537689\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.006964825259314643\n",
      "reward_2: 0.9182043358077514\n",
      "reward_3: 17.750000000000117\n",
      "reward_4: 0.008753602465160383\n",
      "reward_5: 0.08089135334078605\n",
      "reward_6: 0.24459360444545653\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 900\n",
      "episode was finished at timestep: 360\n",
      "reward: 8.548806243810619\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.01645275486840142\n",
      "reward_2: 0.8952992901984282\n",
      "reward_3: 19.900000000000148\n",
      "reward_4: 0.012645157012722593\n",
      "reward_5: -0.0029248728163685437\n",
      "reward_6: 0.2690694507360457\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 901\n",
      "episode was finished at timestep: 355\n",
      "reward: 9.125416673291495\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08980664478407965\n",
      "reward_2: 0.97688999081688\n",
      "reward_3: 20.10000000000015\n",
      "reward_4: -0.006210368679979439\n",
      "reward_5: -0.00254643034685967\n",
      "reward_6: 0.270039481759071\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 902\n",
      "episode was finished at timestep: 353\n",
      "reward: 8.177221081365378\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.056018715434604224\n",
      "reward_2: 0.8513800407184513\n",
      "reward_3: 19.050000000000136\n",
      "reward_4: 0.004704499887070739\n",
      "reward_5: -0.0021247891012018036\n",
      "reward_6: 0.2721108301877978\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 903\n",
      "episode was finished at timestep: 205\n",
      "reward: 8.108435563271827\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.051637470722198486\n",
      "reward_2: 0.8395317988545138\n",
      "reward_3: 17.85000000000012\n",
      "reward_4: 0.007226843061572623\n",
      "reward_5: -0.0019325568276390944\n",
      "reward_6: 0.28228151404857627\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 904\n",
      "episode was finished at timestep: 221\n",
      "reward: 8.578996380680369\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.122228385342492\n",
      "reward_2: 0.8993668506509314\n",
      "reward_3: 18.70000000000013\n",
      "reward_4: 0.00022680521144323505\n",
      "reward_5: -0.002320126252445694\n",
      "reward_6: 0.2598455413579932\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 905\n",
      "episode was finished at timestep: 333\n",
      "reward: 9.331767542958083\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07849326663547092\n",
      "reward_2: 0.9929839416854767\n",
      "reward_3: 17.600000000000115\n",
      "reward_4: 0.003386444526043846\n",
      "reward_5: -0.004027819647271969\n",
      "reward_6: 0.2839923396110535\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 906\n",
      "episode was finished at timestep: 131\n",
      "reward: 9.014887705475173\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0626092321342892\n",
      "reward_2: 0.9576420946448738\n",
      "reward_3: 17.700000000000117\n",
      "reward_4: 0.0011380571746585134\n",
      "reward_5: -0.003702131097462195\n",
      "reward_6: 0.28337938988208733\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 907\n",
      "episode was finished at timestep: 236\n",
      "reward: 8.654076135988985\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.05559678673744202\n",
      "reward_2: 0.9125927169577276\n",
      "reward_3: 18.400000000000126\n",
      "reward_4: 0.0026162678755446223\n",
      "reward_5: -0.0005367393987773046\n",
      "reward_6: 0.27489087665081013\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 908\n",
      "episode was finished at timestep: 299\n",
      "reward: 9.385326083854267\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0753429565164778\n",
      "reward_2: 0.9954219521174827\n",
      "reward_3: 18.250000000000124\n",
      "reward_4: 0.008881879017244784\n",
      "reward_5: -0.004587090958984419\n",
      "reward_6: 0.27770623588562016\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 909\n",
      "episode was finished at timestep: 232\n",
      "reward: 9.354705222622833\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07345104482438829\n",
      "reward_2: 0.9926735147482747\n",
      "reward_3: 19.35000000000014\n",
      "reward_4: 0.007385401567589583\n",
      "reward_5: -0.0021008034652793364\n",
      "reward_6: 0.28030365073680885\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 910\n",
      "episode was finished at timestep: 351\n",
      "reward: 9.342928201810832\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0826828956604004\n",
      "reward_2: 0.9857287977107081\n",
      "reward_3: 20.300000000000153\n",
      "reward_4: 0.012475692355914418\n",
      "reward_5: -0.003666320274794188\n",
      "reward_6: 0.2755690392255785\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 911\n",
      "episode was finished at timestep: 1\n",
      "reward: 7.356281129787793\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.11100020805994669\n",
      "reward_2: 0.9953357575333224\n",
      "reward_3: 19.100000000000136\n",
      "reward_4: -0.003218842920004903\n",
      "reward_5: -0.0023887995486846355\n",
      "reward_6: 0.3081877377033244\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 912\n",
      "episode was finished at timestep: 80\n",
      "reward: 8.9348552568551\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09082259270879957\n",
      "reward_2: 0.9471460532371776\n",
      "reward_3: 19.100000000000136\n",
      "reward_4: -0.0014520179267361755\n",
      "reward_5: -0.0039614388840180466\n",
      "reward_6: 0.2798951538801202\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 913\n",
      "episode was finished at timestep: 29\n",
      "reward: 9.18565291720688\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10574018491639031\n",
      "reward_2: 0.9774510155549393\n",
      "reward_3: 19.000000000000135\n",
      "reward_4: -0.0022531564668761914\n",
      "reward_5: -0.0048203850394242425\n",
      "reward_6: 0.2806169112920759\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 914\n",
      "episode was finished at timestep: 112\n",
      "reward: 8.94994982566569\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08474630051188999\n",
      "reward_2: 0.9479616353644644\n",
      "reward_3: 20.05000000000015\n",
      "reward_4: -6.287934860878864e-05\n",
      "reward_5: -0.0010833153594166588\n",
      "reward_6: 0.28042345905303934\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 915\n",
      "episode was finished at timestep: 169\n",
      "reward: 9.311495645871416\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10007930397987366\n",
      "reward_2: 0.9940038389890351\n",
      "reward_3: 19.000000000000135\n",
      "reward_4: -0.0030520189853558578\n",
      "reward_5: -0.004045432153217139\n",
      "reward_6: 0.2853138806819925\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 916\n",
      "episode was finished at timestep: 255\n",
      "reward: 9.264587353060136\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08147444658809239\n",
      "reward_2: 0.9819828068885077\n",
      "reward_3: 20.65000000000016\n",
      "reward_4: 0.0053139572183066265\n",
      "reward_5: -0.002336943623577407\n",
      "reward_6: 0.28432240390777497\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 917\n",
      "episode was finished at timestep: 211\n",
      "reward: 9.235399228536085\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.15558600690629748\n",
      "reward_2: 0.98106374110963\n",
      "reward_3: 18.900000000000134\n",
      "reward_4: -0.005777577210506593\n",
      "reward_5: -0.002797719106504104\n",
      "reward_6: 0.277801629543305\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 918\n",
      "episode was finished at timestep: 79\n",
      "reward: -78.04023188891458\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.2704217255115509\n",
      "reward_2: -10\n",
      "reward_3: 12.050000000000036\n",
      "reward_4: 0.035758000665220634\n",
      "reward_5: 0.22737113623483332\n",
      "reward_6: 0.17430457735061766\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 919\n",
      "episode was finished at timestep: 266\n",
      "reward: 9.255199979814005\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07497711777687073\n",
      "reward_2: 0.988074735958859\n",
      "reward_3: 20.250000000000153\n",
      "reward_4: -0.000925682961616161\n",
      "reward_5: -0.002861612040179177\n",
      "reward_6: 0.2831920500993731\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 920\n",
      "episode was finished at timestep: 252\n",
      "reward: 5.543880063671432\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.14368030495113795\n",
      "reward_2: 0.7359387414939592\n",
      "reward_3: 17.800000000000118\n",
      "reward_4: 0.024788667928539353\n",
      "reward_5: -0.0032090738289737666\n",
      "reward_6: 0.3152162238359457\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 921\n",
      "episode was finished at timestep: 241\n",
      "reward: 7.6754091906123545\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10613458355267842\n",
      "reward_2: 0.7881469322180622\n",
      "reward_3: 19.25000000000014\n",
      "reward_4: -0.003080467174944346\n",
      "reward_5: -0.004537016522291873\n",
      "reward_6: 0.29071323657035786\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 922\n",
      "episode was finished at timestep: 298\n",
      "reward: 8.293243878541322\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.12630347410837808\n",
      "reward_2: 0.8526434034178237\n",
      "reward_3: 20.10000000000015\n",
      "reward_4: 0.006341353223628516\n",
      "reward_5: -0.0022039313095677453\n",
      "reward_6: 0.2945862826108949\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 923\n",
      "episode was finished at timestep: 238\n",
      "reward: 5.283314983421624\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08598447309599982\n",
      "reward_2: 0.7384256841068655\n",
      "reward_3: 19.100000000000136\n",
      "reward_4: -0.0008839506851400358\n",
      "reward_5: -0.003626824061219125\n",
      "reward_6: 0.2980768003463735\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 924\n",
      "episode was finished at timestep: 211\n",
      "reward: 8.289650203452847\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.159408876630995\n",
      "reward_2: 0.8659872986078738\n",
      "reward_3: 20.200000000000152\n",
      "reward_4: -0.00908947052790424\n",
      "reward_5: -0.0001632231417098969\n",
      "reward_6: 0.2725285919904715\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 925\n",
      "episode was finished at timestep: 353\n",
      "reward: 9.192728784812507\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0897530092133416\n",
      "reward_2: 0.9677417746840671\n",
      "reward_3: 18.65000000000013\n",
      "reward_4: 0.014912102796079267\n",
      "reward_5: -0.0009822770099390254\n",
      "reward_6: 0.2402403661012662\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 926\n",
      "episode was finished at timestep: 379\n",
      "reward: 7.68097257094913\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.15364623533354865\n",
      "reward_2: 0.7801387791971223\n",
      "reward_3: 20.200000000000152\n",
      "reward_4: -3.8217237114679394e-06\n",
      "reward_5: -0.0024310481214550113\n",
      "reward_6: 0.2859843906164167\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 927\n",
      "episode was finished at timestep: 9\n",
      "reward: 7.6324947938223\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07798224422666762\n",
      "reward_2: 0.7778747414251922\n",
      "reward_3: 19.40000000000014\n",
      "reward_4: 0.0109574894982444\n",
      "reward_5: -0.0055002878800051985\n",
      "reward_6: 0.24676832342147803\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 928\n",
      "episode was finished at timestep: 133\n",
      "reward: 7.475831164659164\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09393763277265761\n",
      "reward_2: 0.7693276354475144\n",
      "reward_3: 20.200000000000152\n",
      "reward_4: -0.00680878654340944\n",
      "reward_5: -0.0017933936545115141\n",
      "reward_6: 0.28084280097484504\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 929\n",
      "episode was finished at timestep: 140\n",
      "reward: 7.173603303060369\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.11672731306817796\n",
      "reward_2: 0.7261377153560024\n",
      "reward_3: 20.200000000000152\n",
      "reward_4: -0.003799430696354875\n",
      "reward_5: -0.00435463453624673\n",
      "reward_6: 0.2798310139179241\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 930\n",
      "episode was finished at timestep: 355\n",
      "reward: 7.1703084840611595\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0895256135198805\n",
      "reward_2: 0.7135022380311956\n",
      "reward_3: 20.550000000000157\n",
      "reward_4: 0.014131146228191654\n",
      "reward_5: -0.0021195214936055844\n",
      "reward_6: 0.25909531795978546\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 931\n",
      "episode was finished at timestep: 202\n",
      "reward: 7.852512003325057\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06274627645810445\n",
      "reward_2: 0.8262727379200605\n",
      "reward_3: 20.450000000000156\n",
      "reward_4: -0.01278300732760897\n",
      "reward_5: -0.0029863573332879886\n",
      "reward_6: 0.28210757279396115\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 932\n",
      "episode was finished at timestep: 66\n",
      "reward: 8.252347682245869\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.05401810871230232\n",
      "reward_2: 0.875309651359587\n",
      "reward_3: 20.80000000000016\n",
      "reward_4: -0.01094654727177712\n",
      "reward_5: -0.00020752726234067134\n",
      "reward_6: 0.28085893476009416\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 933\n",
      "episode was finished at timestep: 360\n",
      "reward: 9.371859900894036\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07969941629303826\n",
      "reward_2: 0.998442438704495\n",
      "reward_3: 20.75000000000016\n",
      "reward_4: 0.0025307431863816985\n",
      "reward_5: -0.002345921622232202\n",
      "reward_6: 0.2839542844295502\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 934\n",
      "episode was finished at timestep: 298\n",
      "reward: 7.722096263793807\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10103509889708626\n",
      "reward_2: 0.8059894307808074\n",
      "reward_3: 19.35000000000014\n",
      "reward_4: -0.0122393350380635\n",
      "reward_5: -0.0031695877891586123\n",
      "reward_6: 0.27164998674392826\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 935\n",
      "episode was finished at timestep: 310\n",
      "reward: 8.861472976197009\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09909503989749485\n",
      "reward_2: 0.9333591109219181\n",
      "reward_3: 20.85000000000016\n",
      "reward_4: 0.0006911833092301833\n",
      "reward_5: -0.000796166836326151\n",
      "reward_6: 0.28799174928665194\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 936\n",
      "episode was finished at timestep: 351\n",
      "reward: 6.350032259143872\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.002145438061820136\n",
      "reward_2: 0.8458099616077703\n",
      "reward_3: 20.15000000000015\n",
      "reward_4: 0.03118067743318747\n",
      "reward_5: 0.04167240238609201\n",
      "reward_6: 0.29189351582527134\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 937\n",
      "episode was finished at timestep: 371\n",
      "reward: 8.909077894718976\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09735550747977363\n",
      "reward_2: 0.9328241670807648\n",
      "reward_3: 22.000000000000178\n",
      "reward_4: 0.007878228521690574\n",
      "reward_5: -0.0034763860764715085\n",
      "reward_6: 0.2866462751626969\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 938\n",
      "episode was finished at timestep: 390\n",
      "reward: 9.295239832579021\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.05699618127610948\n",
      "reward_2: 0.9957584669532835\n",
      "reward_3: 21.000000000000163\n",
      "reward_4: -0.0007454979523849658\n",
      "reward_5: -0.0014089745341195226\n",
      "reward_6: 0.27674887382984226\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 939\n",
      "episode was finished at timestep: 111\n",
      "reward: 7.9232327937389035\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.1387492855389913\n",
      "reward_2: 0.813335071519521\n",
      "reward_3: 19.550000000000143\n",
      "reward_4: -0.0016380297930446374\n",
      "reward_5: -0.0037596269278420635\n",
      "reward_6: 0.29206013464927727\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 940\n",
      "episode was finished at timestep: 316\n",
      "reward: 8.171039544243275\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.11175473199950324\n",
      "reward_2: 0.8422528327656661\n",
      "reward_3: 19.900000000000148\n",
      "reward_4: 0.004376500657698301\n",
      "reward_5: -0.0037295514439691147\n",
      "reward_6: 0.28732636296749103\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 941\n",
      "episode was finished at timestep: 375\n",
      "reward: 7.6064547472952\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.1298905372619629\n",
      "reward_2: 0.7671771643149017\n",
      "reward_3: 20.450000000000156\n",
      "reward_4: 0.006559367118626085\n",
      "reward_5: -0.0033102261804549707\n",
      "reward_6: 0.287255518078804\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 942\n",
      "episode was finished at timestep: 388\n",
      "reward: 8.38200901101561\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.11605251895056831\n",
      "reward_2: 0.8711049866510783\n",
      "reward_3: 20.350000000000154\n",
      "reward_4: 0.0014782864648302052\n",
      "reward_5: -0.003112568131480605\n",
      "reward_6: 0.28568954193592133\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 943\n",
      "episode was finished at timestep: 331\n",
      "reward: 7.832505050718253\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.05484682189093696\n",
      "reward_2: 0.8270540977403169\n",
      "reward_3: 21.050000000000164\n",
      "reward_4: -0.014612973233854803\n",
      "reward_5: -1.928643678634027e-05\n",
      "reward_6: 0.27534185254573895\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 944\n",
      "episode was finished at timestep: 300\n",
      "reward: 8.974265965985776\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08846415546205309\n",
      "reward_2: 0.9452254589976958\n",
      "reward_3: 20.00000000000015\n",
      "reward_4: 0.0048528224543697715\n",
      "reward_5: -0.0011145810460986875\n",
      "reward_6: 0.2836234732866286\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 945\n",
      "episode was finished at timestep: 312\n",
      "reward: 8.44834373407128\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04415905674298604\n",
      "reward_2: 0.9178960671942548\n",
      "reward_3: 21.150000000000166\n",
      "reward_4: -0.02670819367303423\n",
      "reward_5: -0.0035346652783450356\n",
      "reward_6: 0.27539635443687505\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 946\n",
      "episode was finished at timestep: 325\n",
      "reward: 8.57073469218434\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09805570708380805\n",
      "reward_2: 0.8925650856937455\n",
      "reward_3: 21.250000000000167\n",
      "reward_4: 0.005909355998751948\n",
      "reward_5: -0.00287807629563801\n",
      "reward_6: 0.28492819452285756\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 947\n",
      "episode was finished at timestep: 207\n",
      "reward: 8.94883134758262\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06093515290154351\n",
      "reward_2: 0.9461437681942755\n",
      "reward_3: 21.000000000000163\n",
      "reward_4: 0.004650031107924661\n",
      "reward_5: -0.001503284209180104\n",
      "reward_6: 0.2802490844726562\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 948\n",
      "episode was finished at timestep: 364\n",
      "reward: 9.066770858545375\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.12324012981520759\n",
      "reward_2: 0.9569631518528029\n",
      "reward_3: 19.850000000000147\n",
      "reward_4: 0.00027428378318504086\n",
      "reward_5: -0.0020436919576994226\n",
      "reward_6: 0.2850282689332966\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 949\n",
      "episode was finished at timestep: 371\n",
      "reward: 6.389539303927176\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09716652101940579\n",
      "reward_2: 0.6151759543501987\n",
      "reward_3: 19.35000000000014\n",
      "reward_4: 0.013781237447048084\n",
      "reward_5: -0.001177912485714927\n",
      "reward_6: 0.2593131610155105\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 950\n",
      "episode was finished at timestep: 13\n",
      "reward: 9.266969444986682\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08312189910146925\n",
      "reward_2: 0.9795304068931252\n",
      "reward_3: 21.200000000000166\n",
      "reward_4: 0.008604668984450115\n",
      "reward_5: -0.003047443284769121\n",
      "reward_6: 0.2789877154827122\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 951\n",
      "episode was finished at timestep: 173\n",
      "reward: 8.228891784822254\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.12776756352848476\n",
      "reward_2: 0.8473887500587246\n",
      "reward_3: 19.650000000000144\n",
      "reward_4: 0.004269690795162262\n",
      "reward_5: -0.0013226789160808512\n",
      "reward_6: 0.2865593733787546\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 952\n",
      "episode was finished at timestep: 103\n",
      "reward: 9.204482696604611\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08492078251308866\n",
      "reward_2: 0.9813207596918387\n",
      "reward_3: 21.55000000000017\n",
      "reward_4: -0.0020728064033811223\n",
      "reward_5: -0.0005531465359540041\n",
      "reward_6: 0.2832581009864811\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 953\n",
      "episode was finished at timestep: 55\n",
      "reward: 8.39502531387374\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07460666630003188\n",
      "reward_2: 0.9067371168040325\n",
      "reward_3: 20.80000000000016\n",
      "reward_4: -0.026630661466438\n",
      "reward_5: -0.0018742954222420376\n",
      "reward_6: 0.278667966961861\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 954\n",
      "episode was finished at timestep: 263\n",
      "reward: 7.002021810707658\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08770634068383111\n",
      "reward_2: 0.7315279111956453\n",
      "reward_3: 20.400000000000155\n",
      "reward_4: -0.02639892509600415\n",
      "reward_5: -0.004013313056594233\n",
      "reward_6: 0.27457689428329235\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 955\n",
      "episode was finished at timestep: 103\n",
      "reward: 8.052111257789548\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.006793799002965292\n",
      "reward_2: 0.884130934973491\n",
      "reward_3: 18.70000000000013\n",
      "reward_4: -0.03930408929363651\n",
      "reward_5: 0.02843173175157586\n",
      "reward_6: 0.269365226268767\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 956\n",
      "episode was finished at timestep: 234\n",
      "reward: 7.2904330697347275\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.14061106310950386\n",
      "reward_2: 0.7384600755693758\n",
      "reward_3: 17.050000000000107\n",
      "reward_4: -0.005084150223752176\n",
      "reward_5: -0.004918893066391542\n",
      "reward_6: 0.28546016359329296\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 957\n",
      "episode was finished at timestep: 235\n",
      "reward: 7.777243721403148\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.1198842724164327\n",
      "reward_2: 0.799911481184467\n",
      "reward_3: 19.25000000000014\n",
      "reward_4: -0.0034447152537991597\n",
      "reward_5: -0.002448853283977215\n",
      "reward_6: 0.2855075081586842\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 958\n",
      "episode was finished at timestep: 359\n",
      "reward: 8.273621244948105\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.14497343831592135\n",
      "reward_2: 0.8500259771422712\n",
      "reward_3: 18.70000000000013\n",
      "reward_4: 0.0054784231593335165\n",
      "reward_5: -0.0028050022472656385\n",
      "reward_6: 0.2849242731332772\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 959\n",
      "episode was finished at timestep: 122\n",
      "reward: 8.414581429237009\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0011081231964959039\n",
      "reward_2: 0.921273938982577\n",
      "reward_3: 19.40000000000014\n",
      "reward_4: -0.03278829428925306\n",
      "reward_5: 0.0673858689892499\n",
      "reward_6: 0.23783185923099626\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 960\n",
      "episode was finished at timestep: 38\n",
      "reward: 8.173043548715267\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.03382657501432631\n",
      "reward_2: 0.8480653664244191\n",
      "reward_3: 17.450000000000113\n",
      "reward_4: 0.01292531469594195\n",
      "reward_5: -0.004414398892345398\n",
      "reward_6: 0.25337925696373\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 961\n",
      "episode was finished at timestep: 231\n",
      "reward: 8.53994289762942\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10715226266119215\n",
      "reward_2: 0.8880070680125556\n",
      "reward_3: 20.400000000000155\n",
      "reward_4: 0.005111574083913694\n",
      "reward_5: -0.00035041824067706765\n",
      "reward_6: 0.28547191643714986\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 962\n",
      "episode was finished at timestep: 281\n",
      "reward: 8.408112942626314\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09589784608946907\n",
      "reward_2: 0.9190007982459912\n",
      "reward_3: 20.85000000000016\n",
      "reward_4: -0.03129614585786953\n",
      "reward_5: -0.0015355676403036255\n",
      "reward_6: 0.20933344507217422\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 963\n",
      "episode was finished at timestep: 322\n",
      "reward: 9.065696844526654\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.16500534878836737\n",
      "reward_2: 0.9386488059553966\n",
      "reward_3: 21.100000000000165\n",
      "reward_4: 0.01458461170746574\n",
      "reward_5: -0.002224149944391603\n",
      "reward_6: 0.2742349710464467\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 964\n",
      "episode was finished at timestep: 301\n",
      "reward: 4.9171267303720825\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.010409330659442478\n",
      "reward_2: 0.7392852741471141\n",
      "reward_3: 19.650000000000144\n",
      "reward_4: -0.03951704408337491\n",
      "reward_5: 0.03298471141211342\n",
      "reward_6: 0.29378550910949697\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 965\n",
      "episode was finished at timestep: 209\n",
      "reward: 9.098465937462315\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07827040751775106\n",
      "reward_2: 0.9590981795593045\n",
      "reward_3: 20.15000000000015\n",
      "reward_4: 0.008235604289370712\n",
      "reward_5: -0.00014570407179258875\n",
      "reward_6: 0.2789842965602879\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 966\n",
      "episode was finished at timestep: 207\n",
      "reward: -77.77018157098456\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.001688712173038059\n",
      "reward_2: -10\n",
      "reward_3: 14.850000000000076\n",
      "reward_4: 0.067601961590359\n",
      "reward_5: 0.4551518153298094\n",
      "reward_6: 0.23355963313579486\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 967\n",
      "episode was finished at timestep: 133\n",
      "reward: 8.024101835292917\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.107257080078125\n",
      "reward_2: 0.8176528055713437\n",
      "reward_3: 18.100000000000122\n",
      "reward_4: 0.012022809089384481\n",
      "reward_5: -0.005103708426599359\n",
      "reward_6: 0.2821302130222324\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 968\n",
      "episode was finished at timestep: 40\n",
      "reward: 6.828678897886583\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0033104525672064886\n",
      "reward_2: 0.8412293737499141\n",
      "reward_3: 11.65000000000003\n",
      "reward_4: 0.04048121983151447\n",
      "reward_5: 0.4892100158559603\n",
      "reward_6: 0.28754125261306773\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 969\n",
      "episode was finished at timestep: 317\n",
      "reward: 8.836640543041817\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08889196846220228\n",
      "reward_2: 0.9355560584577958\n",
      "reward_3: 21.850000000000176\n",
      "reward_4: -0.0029104644520676006\n",
      "reward_5: -0.0017373605882112268\n",
      "reward_6: 0.2854078497886663\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 970\n",
      "episode was finished at timestep: 50\n",
      "reward: 8.998515599155043\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09103862974378797\n",
      "reward_2: 0.94340269688721\n",
      "reward_3: 22.350000000000183\n",
      "reward_4: 0.008728724340365375\n",
      "reward_5: -0.0007387114416445683\n",
      "reward_6: 0.2881843110322959\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 971\n",
      "episode was finished at timestep: 295\n",
      "reward: 7.785751439315474\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.12573838101492987\n",
      "reward_2: 0.7857927494122652\n",
      "reward_3: 20.70000000000016\n",
      "reward_4: 0.010597812216964542\n",
      "reward_5: -0.0018351883143404044\n",
      "reward_6: 0.2879637535810471\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 972\n",
      "episode was finished at timestep: 243\n",
      "reward: 7.084853025724009\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.00012153519524468315\n",
      "reward_2: 0.6571384087017508\n",
      "reward_3: 14.500000000000071\n",
      "reward_4: 0.017955291155245162\n",
      "reward_5: 0.4160659692403216\n",
      "reward_6: 0.2662256594896316\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 973\n",
      "episode was finished at timestep: 107\n",
      "reward: 5.121164432089012\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.005594948265287611\n",
      "reward_2: 0.6964241927203128\n",
      "reward_3: 18.00000000000012\n",
      "reward_4: 0.0121857206967546\n",
      "reward_5: 0.1675560054012987\n",
      "reward_6: 0.2879240676164624\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 974\n",
      "episode was finished at timestep: 232\n",
      "reward: 9.023357351591084\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.10430717137124804\n",
      "reward_2: 0.9498774756778332\n",
      "reward_3: 21.40000000000017\n",
      "reward_4: 0.003853329900138931\n",
      "reward_5: -0.0019771637649159384\n",
      "reward_6: 0.28832756602764165\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 975\n",
      "episode was finished at timestep: 349\n",
      "reward: 4.5098929038580975\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.09308085044225058\n",
      "reward_2: 0.6532380852146034\n",
      "reward_3: 17.95000000000012\n",
      "reward_4: -0.012386968158268417\n",
      "reward_5: -0.0050247126993818135\n",
      "reward_6: 0.2926344963312153\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 976\n",
      "episode was finished at timestep: 148\n",
      "reward: 8.850858218245648\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.0977194282743666\n",
      "reward_2: 0.9271605510682603\n",
      "reward_3: 18.850000000000133\n",
      "reward_4: 0.005751254915649184\n",
      "reward_5: -0.002562189485052476\n",
      "reward_6: 0.28989319825172455\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 977\n",
      "episode was finished at timestep: 209\n",
      "reward: 5.7453402745333975\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.008030564917458429\n",
      "reward_2: 0.7234089013168656\n",
      "reward_3: 12.650000000000045\n",
      "reward_4: 0.028207254643360925\n",
      "reward_5: 0.44454735431113157\n",
      "reward_6: 0.2942075707912447\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 978\n",
      "episode was finished at timestep: 216\n",
      "reward: -78.43897445698148\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.1438233474890391\n",
      "reward_2: -10\n",
      "reward_3: 21.800000000000175\n",
      "reward_4: 0.021959900558878045\n",
      "reward_5: -0.0005557679267553794\n",
      "reward_6: 0.23917209231853542\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 979\n",
      "episode was finished at timestep: 214\n",
      "reward: -80.48301375979162\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.016358400053448147\n",
      "reward_2: -10\n",
      "reward_3: 14.40000000000007\n",
      "reward_4: 0.003791314162127861\n",
      "reward_5: 0.2019260459064231\n",
      "reward_6: 0.2664512809514995\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 980\n",
      "episode was finished at timestep: 66\n",
      "reward: 7.110939112238036\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.14445926149686178\n",
      "reward_2: 0.6961072617332893\n",
      "reward_3: 20.400000000000155\n",
      "reward_4: 0.012700502264763429\n",
      "reward_5: -0.001089359436416378\n",
      "reward_6: 0.2943870981931688\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 981\n",
      "episode was finished at timestep: 214\n",
      "reward: 8.315907756505279\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.02648202511999342\n",
      "reward_2: 0.9054862467387579\n",
      "reward_3: 19.750000000000146\n",
      "reward_4: -0.01871115145313411\n",
      "reward_5: -0.0012187606659152786\n",
      "reward_6: 0.19381039643287667\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 982\n",
      "episode was finished at timestep: 247\n",
      "reward: 6.330663404003785\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.12258870138062371\n",
      "reward_2: 0.8571196576282162\n",
      "reward_3: 21.45000000000017\n",
      "reward_4: 0.006836328687382575\n",
      "reward_5: -0.0016028843518646123\n",
      "reward_6: 0.29516969645023483\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 983\n",
      "episode was finished at timestep: 69\n",
      "reward: 7.9704359575886965\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.04327976703643799\n",
      "reward_2: 0.8138532008996385\n",
      "reward_3: 20.85000000000016\n",
      "reward_4: 0.016696090999481612\n",
      "reward_5: -0.0008595818612763632\n",
      "reward_6: 0.2808414372205733\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 984\n",
      "episode was finished at timestep: 371\n",
      "reward: 8.529899347607802\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0010992493894365098\n",
      "reward_2: 0.8709900504860446\n",
      "reward_3: 18.60000000000013\n",
      "reward_4: 0.019524239728573322\n",
      "reward_5: 0.1279215850651839\n",
      "reward_6: 0.2764826902151113\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 985\n",
      "episode was finished at timestep: 57\n",
      "reward: 8.751780105077774\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08359632624520195\n",
      "reward_2: 0.9204555965438672\n",
      "reward_3: 20.400000000000155\n",
      "reward_4: 0.0023504657363582738\n",
      "reward_5: -0.0037915712730927234\n",
      "reward_6: 0.28680685186386157\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 986\n",
      "episode was finished at timestep: 154\n",
      "reward: 5.939120595072233\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.00014534195264180502\n",
      "reward_2: 0.7937923409188049\n",
      "reward_3: 18.950000000000134\n",
      "reward_4: 0.02138782343397807\n",
      "reward_5: 0.13626119496732608\n",
      "reward_6: 0.2790367605686187\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 987\n",
      "episode was finished at timestep: 7\n",
      "reward: 8.28418995218858\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.12610822783576117\n",
      "reward_2: 0.8372666151908309\n",
      "reward_3: 23.6500000000002\n",
      "reward_4: 0.02053280572369914\n",
      "reward_5: -0.0015528099654639267\n",
      "reward_6: 0.29408583366870955\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 988\n",
      "episode was finished at timestep: 324\n",
      "reward: 4.884781930334286\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0025815149148305256\n",
      "reward_2: 0.6372575306663831\n",
      "reward_3: 17.650000000000116\n",
      "reward_4: 0.029817336886869727\n",
      "reward_5: 0.26686722975353966\n",
      "reward_6: 0.2815439417362212\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 989\n",
      "episode was finished at timestep: 51\n",
      "reward: 7.0750890384414955\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0035002953476376\n",
      "reward_2: 0.6642346845482032\n",
      "reward_3: 16.400000000000098\n",
      "reward_4: 0.02006001423443422\n",
      "reward_5: 0.3269274730825286\n",
      "reward_6: 0.27511760377883865\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 990\n",
      "episode was finished at timestep: 272\n",
      "reward: 5.08542522045934\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0031233410040537517\n",
      "reward_2: 0.6805276383951477\n",
      "reward_3: 19.200000000000138\n",
      "reward_4: 0.019591725693184542\n",
      "reward_5: 0.19759893348573906\n",
      "reward_6: 0.28743471527099673\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 991\n",
      "episode was finished at timestep: 142\n",
      "reward: 6.66349749363986\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.055212756660249496\n",
      "reward_2: 0.9027733639465756\n",
      "reward_3: 22.20000000000018\n",
      "reward_4: 0.01209419566044602\n",
      "reward_5: -0.00030500608139512054\n",
      "reward_6: 0.2866892662048336\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 992\n",
      "episode was finished at timestep: 319\n",
      "reward: 4.921774222421528\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.002411246962017483\n",
      "reward_2: 0.6547104836271703\n",
      "reward_3: 16.350000000000097\n",
      "reward_4: 0.01725962821422243\n",
      "reward_5: 0.26578845046588717\n",
      "reward_6: 0.2804561241865159\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 993\n",
      "episode was finished at timestep: 80\n",
      "reward: 8.965270520428021\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.06906968951225281\n",
      "reward_2: 0.9396927046198158\n",
      "reward_3: 21.600000000000172\n",
      "reward_4: 0.011707542020625824\n",
      "reward_5: -0.00051454419770162\n",
      "reward_6: 0.28263340198993636\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 994\n",
      "episode was finished at timestep: 11\n",
      "reward: 9.340919520660243\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07204566929075452\n",
      "reward_2: 0.9867790899137464\n",
      "reward_3: 22.05000000000018\n",
      "reward_4: 0.010568584893272686\n",
      "reward_5: -0.0004272923793263791\n",
      "reward_6: 0.2875797452926637\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 995\n",
      "episode was finished at timestep: 350\n",
      "reward: 5.346850683158573\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.07134668363465203\n",
      "reward_2: 0.6978870204293771\n",
      "reward_3: 19.000000000000135\n",
      "reward_4: 0.05162592053979395\n",
      "reward_5: -0.007166556664519064\n",
      "reward_6: 0.28403369510173837\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 996\n",
      "episode was finished at timestep: 245\n",
      "reward: 7.589892348478149\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.043315144379933675\n",
      "reward_2: 0.7867938901070267\n",
      "reward_3: 19.700000000000145\n",
      "reward_4: -0.0034354944761892624\n",
      "reward_5: -0.000730055897888704\n",
      "reward_6: 0.27781342828273803\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 997\n",
      "episode was finished at timestep: 221\n",
      "reward: 7.445067720898645\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08315046495861478\n",
      "reward_2: 0.9982691188421835\n",
      "reward_3: 20.80000000000016\n",
      "reward_4: 0.010473423103970276\n",
      "reward_5: -0.00041044749603322825\n",
      "reward_6: 0.28961403453350065\n",
      "reward_7: -1\n",
      "========================================\n",
      "\n",
      "episode: 998\n",
      "episode was finished at timestep: 159\n",
      "reward: 8.27552534032848\n",
      "========================================\n",
      "reward details\n",
      "reward_1: -0.0027944849597083196\n",
      "reward_2: 0.8692668655277476\n",
      "reward_3: 19.95000000000015\n",
      "reward_4: 0.0036919548506541846\n",
      "reward_5: 0.019480873860896135\n",
      "reward_6: 0.27250838840007885\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n",
      "episode: 999\n",
      "episode was finished at timestep: 265\n",
      "reward: 9.45763777494345\n",
      "========================================\n",
      "reward details\n",
      "reward_1: 0.08022502859433492\n",
      "reward_2: 0.9993577282561213\n",
      "reward_3: 20.75000000000016\n",
      "reward_4: 0.011573015090964417\n",
      "reward_5: -0.0006171059019161855\n",
      "reward_6: 0.2878172388076783\n",
      "reward_7: 1\n",
      "========================================\n",
      "\n"
>>>>>>> Stashed changes
     ]
    }
   ],
   "source": [
    "importlib.reload(TT8d)\n",
    "\n",
    "maximum_eps = 1000\n",
    "maximum_timestep = 30000\n",
    "\n",
    "best_reward = 0\n",
    "\n",
    "result_filename = get_filename()\n",
    "with open(f'./results/{result_filename}.txt', 'w') as file:\n",
    "    for eps in range(maximum_eps):\n",
    "        obs = env.reset()\n",
    "        model.learn(total_timesteps=maximum_timestep, log_interval=100)\n",
    "        for k in range(maximum_timestep):\n",
    "            action, _states = model.predict(obs, deterministic=True)\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            env.render()\n",
    "            if done:\n",
    "                log = f\"episode: {eps}\\nepisode was finished at timestep: {k}\\nreward: {reward}\\n========================================\\n\" + \\\n",
    "                f\"reward details\\n\" + \\\n",
    "                f\"reward_1: {info['reward_detail'][0]}\\n\" + \\\n",
    "                f\"reward_2: {info['reward_detail'][1]}\\n\" + \\\n",
    "                f\"reward_3: {info['reward_detail'][2]}\\n\" + \\\n",
    "                f\"reward_4: {info['reward_detail'][3]}\\n\" + \\\n",
    "                f\"reward_5: {info['reward_detail'][4]}\\n\" + \\\n",
    "                f\"reward_6: {info['reward_detail'][5]}\\n\" + \\\n",
<<<<<<< Updated upstream
=======
    "                f\"reward_7: {info['reward_detail'][6]}\\n\" + \\\n",
>>>>>>> Stashed changes
    "                \"========================================\\n\"\n",
    "                print(log)\n",
    "                file.write(f'{log}\\n')\n",
    "\n",
    "                break\n",
    "        # 이번 학습 결과가 기존 학습 결과보다 좋다면 저장\n",
    "        if reward > best_reward:\n",
    "            best_reward = reward\n",
    "            model.save(f'./model/{result_filename}')\n",
    "\n",
    "model.save(f'./model/{result_filename}_last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 시연\n",
    "학습이 마무리된 후, 아래의 셀을 실행시켜 모델 학습 결과를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SACPolicy(\n",
      "  (actor): Actor(\n",
      "    (features_extractor): FlattenExtractor(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    )\n",
      "    (latent_pi): Sequential(\n",
      "      (0): Linear(in_features=11, out_features=256, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (mu): Linear(in_features=256, out_features=4, bias=True)\n",
      "    (log_std): Linear(in_features=256, out_features=4, bias=True)\n",
      "  )\n",
      "  (critic): ContinuousCritic(\n",
      "    (features_extractor): FlattenExtractor(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    )\n",
      "    (qf0): Sequential(\n",
      "      (0): Linear(in_features=15, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=128, out_features=1, bias=True)\n",
      "    )\n",
      "    (qf1): Sequential(\n",
      "      (0): Linear(in_features=15, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=128, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (critic_target): ContinuousCritic(\n",
      "    (features_extractor): FlattenExtractor(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    )\n",
      "    (qf0): Sequential(\n",
      "      (0): Linear(in_features=15, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=128, out_features=1, bias=True)\n",
      "    )\n",
      "    (qf1): Sequential(\n",
      "      (0): Linear(in_features=15, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=128, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "\n",
    "for k in range(3000):\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    #print(action)\n",
    "    env.render()\n",
    "    if done:\n",
    "      obs = env.reset()\n",
    "\n",
    "print(model.policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TT8d.TiltrotorTransitionTraining()\n",
    "model = SAC.load(r'./model/train_result_2023-07-13_224219.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5)\n",
    "obs = env.reset()\n",
    "\n",
    "for k in range(1000):\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    #print(action)\n",
    "    env.render()\n",
    "    if done:\n",
    "      obs = env.reset()\n",
    "\n",
    "print(model.policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
